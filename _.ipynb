{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T08:43:51.458201464Z",
     "start_time": "2023-09-19T08:43:48.244012830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n",
      "2023-12-11 08:10:48.712594: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-11 08:10:48.741232: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 08:10:49.802436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from environments.pickplace_environment_residual import ResPickOrPlaceEnvWithoutLangReward\n",
    "from tasks.letter import PutLetterOontheBowl,PutLetterontheBowlUnseen,PutLetterontheBowl,PutLetterontheBowlUnseenLetters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from agents.LLMRL import LLMSAC,GuideSAC\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'task': 'PutLetterontheBowl', 'model': 'RL', 'seed': 0, 'success': [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1], 'steps': [1, 2, 1, 1, 1, 1, 5, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 5, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 5, 1, 1, 1, 1, 1, 5, 1, 1]}, {'task': 'PutLetterontheBowl', 'model': 'RL', 'seed': 1, 'success': [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], 'steps': [1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 5, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 5, 1, 5, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 4, 1]}, {'task': 'PutLetterontheBowl', 'model': 'RL', 'seed': 2, 'success': [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'steps': [3, 1, 5, 5, 5, 5, 5, 2, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 2, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5]}, {'task': 'PutLetterontheBowl', 'model': 'RL', 'seed': 3, 'success': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'steps': [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 5, 1, 1, 5, 1, 3, 4, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 2, 1, 3]}, {'task': 'PutLetterontheBowl', 'model': 'Baseline', 'seed': None, 'success': [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], 'steps': [5, 2, 5, 5, 2, 5, 5, 2, 5, 2, 2, 5, 5, 5, 5, 2, 4, 2, 2, 5, 2, 2, 5, 2, 2, 2, 5, 5, 2, 5, 2, 2, 5, 5, 5, 4, 2, 2, 2, 5, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2]}]\n",
      "seed:  0 succes_rate 0.84 mean_length 1.66\n",
      "seed:  1 succes_rate 0.86 mean_length 1.66\n",
      "seed:  2 succes_rate 0.18 mean_length 4.38\n",
      "seed:  3 succes_rate 0.96 mean_length 1.48\n",
      "seed:  4 succes_rate 0.6 mean_length 3.28\n",
      "mean_steps 2.6 std_steps 0.08485281374238578\n",
      "mean_success_rate 0.9133333333333334 std_success_rate 0.033993463423951875\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"test/PutLetterontheBowl_eval_model.pkl\",\"rb\") as f:\n",
    "    res = pickle.load(f)\n",
    "print(res)\n",
    "f.close()\n",
    "\n",
    "for i in range(len(res)):\n",
    "    print(\"seed: \",i,\"succes_rate\",np.mean(res[i]['success']),\"mean_length\",np.mean(res[i]['steps']))\n",
    "steps = [2.66,2.66,2.48]\n",
    "success_rate = [0.88,0.9,0.96]\n",
    "mean_steps = np.mean(steps)\n",
    "std_steps = np.std(steps)\n",
    "mean_success_rate = np.mean(success_rate)\n",
    "std_success_rate = np.std(success_rate)\n",
    "print(\"mean_steps\",mean_steps,\"std_steps\",std_steps)\n",
    "print(\"mean_success_rate\",mean_success_rate,\"std_success_rate\",std_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'task': 'PutLetterontheBowlUnseen', 'model': 'RL', 'seed': 0, 'success': [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'steps': [1, 5, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 5, 1, 1, 5, 1, 1, 1, 1, 1, 5, 1, 1, 1, 5, 1, 2, 1, 1, 1, 1, 1, 1]}, {'task': 'PutLetterontheBowlUnseen', 'model': 'RL', 'seed': 1, 'success': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], 'steps': [1, 1, 5, 1, 3, 1, 1, 1, 5, 5, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 5, 5, 1, 1, 1, 2, 1, 1, 1, 5, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 5, 2, 1, 1]}, {'task': 'PutLetterontheBowlUnseen', 'model': 'RL', 'seed': 2, 'success': [0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0], 'steps': [5, 1, 5, 3, 5, 5, 2, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 1, 5, 5, 1, 5, 5, 5, 1, 5, 1, 5, 5, 5, 5, 5]}, {'task': 'PutLetterontheBowlUnseen', 'model': 'RL', 'seed': 3, 'success': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1], 'steps': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 5, 1, 1, 5, 1, 5, 1, 5, 1, 1, 5, 1, 2, 1, 1, 1, 1, 5, 1, 1, 1, 2, 5, 1, 1, 1, 5, 1, 1, 1, 1, 3]}, {'task': 'PutLetterontheBowlUnseen', 'model': 'Baseline', 'seed': None, 'success': [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], 'steps': [5, 2, 5, 5, 2, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 5, 5, 2, 5, 2, 2, 5, 5, 5, 3, 2, 2, 2, 5, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2]}]\n",
      "seed:  0 succes_rate 0.88 mean_length 1.58\n",
      "seed:  1 succes_rate 0.8 mean_length 1.88\n",
      "seed:  2 succes_rate 0.22 mean_length 4.24\n",
      "seed:  3 succes_rate 0.86 mean_length 1.8\n",
      "seed:  4 succes_rate 0.58 mean_length 3.28\n",
      "mean_steps 2.7533333333333334 std_steps 0.12684198393626955\n",
      "mean_success_rate 0.8466666666666667 std_success_rate 0.03399346342395188\n"
     ]
    }
   ],
   "source": [
    "with open(\"test/PutLetterontheBowlUnseen_eval_model.pkl\",\"rb\") as f:\n",
    "    res = pickle.load(f)\n",
    "print(res)\n",
    "f.close()\n",
    "for i in range(len(res)):\n",
    "    print(\"seed: \",i,\"succes_rate\",np.mean(res[i]['success']),\"mean_length\",np.mean(res[i]['steps']))\n",
    "steps = [2.58,2.88,2.8]\n",
    "success_rate = [0.88,0.8,0.86]\n",
    "mean_steps = np.mean(steps)\n",
    "std_steps = np.std(steps)\n",
    "mean_success_rate = np.mean(success_rate)\n",
    "std_success_rate = np.std(success_rate)\n",
    "print(\"mean_steps\",mean_steps,\"std_steps\",std_steps)\n",
    "print(\"mean_success_rate\",mean_success_rate,\"std_success_rate\",std_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from reward.detector import VILD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/marunyu/Data/study/DELFT/master_thesis/RA/reward/detector.py:24: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.saved_model.load` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 08:10:59.268051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.269670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.269774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.271221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.271349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.271433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.271604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.271839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.272072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 08:10:59.272154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./reward/image_path_v2/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 08:11:00.050288: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, -3656277332278636594), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 3469475840, 1751076529146052892)]\n"
     ]
    }
   ],
   "source": [
    "vild = VILD()\n",
    "print(vild.session.list_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_bbox_category(found_obj,scores,category):\n",
    "    scores = scores[:,1:]\n",
    "    unoccupied_cata = np.arange(len(category))\n",
    "    unoccupied_obj = np.arange(len(found_obj))\n",
    "    new_found_obj = []\n",
    "    while len(unoccupied_cata) > 0 and len(unoccupied_obj) > 0:\n",
    "        mask = np.zeros_like(scores)\n",
    "        mask[np.ix_(unoccupied_obj,unoccupied_cata)] = 1\n",
    "        cur_score =  np.where(mask,scores,0)\n",
    "        # get max score position\n",
    "        max_idx = np.unravel_index(np.argmax(cur_score, axis=None), cur_score.shape)\n",
    "        obj = found_obj[max_idx[0]]\n",
    "        bbox = obj[2]\n",
    "        w,h = bbox[2]-bbox[0],bbox[3]-bbox[1]\n",
    "        area = w*h\n",
    "        if area > 6000 or w>100 or h>100:\n",
    "            unoccupied_obj = unoccupied_obj[unoccupied_obj!=max_idx[0]]\n",
    "            continue\n",
    "        else:\n",
    "            obj = (category[max_idx[1]],found_obj[max_idx[0]][1],found_obj[max_idx[0]][2],scores[max_idx[0],max_idx[1]])\n",
    "            new_found_obj.append(obj)\n",
    "            # remove the row and column\n",
    "            # print('remove',max_idx,cur_score[max_idx[0],max_idx[1]])\n",
    "            unoccupied_obj = unoccupied_obj[unoccupied_obj!=max_idx[0]]\n",
    "            unoccupied_cata = unoccupied_cata[unoccupied_cata!=max_idx[1]]\n",
    "    return new_found_obj\n",
    "def visuallizre_res(img,found_obj,scores):\n",
    "    for obj in found_obj:\n",
    "        if obj[0].split(\" \")[1] == \"bowl\":\n",
    "            rec_color =(0, 255, 0)\n",
    "        else:\n",
    "            rec_color =(0, 0, 255)\n",
    "        y_min,x_min,y_max,x_max = obj[2]\n",
    "        img = cv2.rectangle(img,(x_min, y_min), (x_max, y_max),rec_color , 2,)\n",
    "        img = cv2.putText(img, obj[0], (x_min, (y_min+y_max)//2), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    # plot matrix score_all\n",
    "    plt.imshow(scores, cmap='viridis')  # 'cmap' parameter defines the colormap\n",
    "    plt.colorbar() \n",
    "    m,n = scores.shape\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            text = plt.text(j, i, f'{scores[i, j]:.2f}',\n",
    "                            ha=\"center\", va=\"center\", color=\"w\")\n",
    "    plt.show()\n",
    "    for obj in found_obj:\n",
    "        print(obj)\n",
    "\n",
    "\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61619cc93f8c4b7a9763d477305675bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='seed', max=10), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_image(seed=1)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "env = ResPickOrPlaceEnvWithoutLangReward(\n",
    "                                        task= PutLetterontheBowl,\n",
    "                                        image_obs=True,\n",
    "                                        residual=True,\n",
    "                                        observation_noise=5,\n",
    "                                        render=False,\n",
    "                                        multi_discrete=False,\n",
    "                                        scale_action=True,\n",
    "                                        ee=\"suction\",\n",
    "                                        scale_obs=True,\n",
    "                                        neglect_steps=False,\n",
    "                                        one_hot_action = True)\n",
    "def show_image(seed=1):\n",
    "    np.random.seed(seed)\n",
    "    env.reset()\n",
    "    img = env.get_image()\n",
    "\n",
    "    image_path = \"tmp/images/PutLetterOontheBowl_step0_seed{}.png\".format(seed)\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(image_path, image)\n",
    "    catagory = env.task.local_config['pick']\n",
    "    for i in catagory:\n",
    "        i += \" block\" \n",
    "    catagory += env.task.local_config['place']\n",
    "    # catagory = [\n",
    "    #     \"yellow bowl\",\"green bowl\",\"blue bowl\",\n",
    "    #     \"yellow o shape block\",\"blue o shape block\", \"green o shape block\"]\n",
    "    found_obj,scores,image_det = vild.vild_detect(image_path,catagory,verbose= False)\n",
    "    # found_obj = match_bbox_category(found_obj,scores,catagory)\n",
    "    \n",
    "                        \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    visuallizre_res(img,found_obj,scores)\n",
    "    \n",
    "ipywidgets.interact(show_image, seed=(0, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/marunyu/Data/study/DELFT/master_thesis/RA/venv/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:590: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 12.05GB > 4.58GB\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model =LLMSAC.load(\"tmp/llmsac_imgatten_withnoise15.0fixedPutLetterontheBowl_model_arch/rl_model_65000_steps.zip\")\n",
    "model =LLMSAC.load(\"tmp/llmsac_imgatten_withnoise_PutLetterontheBowlseed0_model/rl_model_65000_steps.zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) UHD Graphics (TGL GT1)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 23.0.4-0ubuntu1~22.04.1\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 23.0.4-0ubuntu1~22.04.1\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) UHD Graphics (TGL GT1)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    }
   ],
   "source": [
    "env = ResPickOrPlaceEnvWithoutLangReward(\n",
    "                                        task= PutLetterontheBowl,#PutLetterontheBowlUnseenLetters\n",
    "                                         image_obs=True,\n",
    "                                         residual=True,\n",
    "                                         observation_noise=0,\n",
    "                                         render=True,\n",
    "                                         multi_discrete=False,\n",
    "                                         scale_action=True,\n",
    "                                         ee=\"suction\",\n",
    "                                         scale_obs=True,\n",
    "                                         neglect_steps=False,\n",
    "                                      one_hot_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "torch.Size([1, 12])\n",
      "[ 0.01661882  0.27081615  0.58166593  0.9897944   0.36141363  0.763705\n",
      "  0.77801377  0.9699061  -0.03999704]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.048214431920928946, -0.41696417298023225, -0.03689519299566746]\n",
      "pick_success 0\n",
      "dis 13.590226657068051 pick_success 0\n",
      "desired_action : [0, 68, 95] phase_loss 0.0031484153812492153 dis_reward 0\n",
      "action  [ 0.01661882  0.27081615  0.58166593  0.9897944   0.36141363  0.763705\n",
      "  0.77801377  0.9699061  -0.03999704] real action [1.66188180e-02 8.15786858e+01 9.44400414e+01]\n",
      "reward -0.10314841538124922 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "torch.Size([1, 12])\n",
      "[ 0.01661882  0.27081615  0.58166593  0.9897944   0.36141363  0.763705\n",
      "  0.77801377  0.9699061  -0.03999704]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.048214431920928946, -0.41696417298023225, -0.037653682589530946]\n",
      "action: [1.66188180e-02 8.15786858e+01 9.44400414e+01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "success = 0# 97%\n",
    "trial = 100\n",
    "steps = []\n",
    "#step2 0.79\n",
    "# step3 0.12\n",
    "# step4 0.03\n",
    "for seed in range(trial):\n",
    "    np.random.seed(seed)\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        action,_ = model.predict(obs, deterministic=True)\n",
    "        print(action)\n",
    "        obs, rewards, done,_, info = env.step(action)\n",
    "        step += 1\n",
    "        if done:\n",
    "            steps.append(step)\n",
    "            if rewards >= 0.95:\n",
    "                success += 1\n",
    "            print(\"done\")\n",
    "            break\n",
    "RL_success = success/trial\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL_success 0.84\n",
      "mean 3.85\n",
      "step2 0.65\n",
      "step3 0.12\n",
      "step4 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"RL_success\",RL_success)\n",
    "step2 = steps.count(2)/len(steps)\n",
    "step3 = steps.count(3)/len(steps)\n",
    "step4 = steps.count(4)/len(steps)\n",
    "print(\"mean\",np.mean(steps))\n",
    "print(\"step2\",step2)\n",
    "print(\"step3\",step3)\n",
    "print(\"step4\",step4)\n",
    "# seen color\n",
    "# RL_success 0.97\n",
    "# mean 2.53\n",
    "# step2 0.87\n",
    "# step3 0.04\n",
    "# step4 0.01\n",
    "# unseen color\n",
    "# RL_success 0.92\n",
    "# mean 2.89\n",
    "# step2 0.83\n",
    "# step3 0.04\n",
    "# step4 0.02\n",
    "# unseen color unseen letters\n",
    "# RL_success 0.81\n",
    "# mean 4.12\n",
    "# step2 0.64\n",
    "# step3 0.09\n",
    "# step4 0.03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Success rate|mean step|\n",
    "| :----: | :----: | :----: |\n",
    "| PutLetterontheBowl|0.97|2.53|\n",
    "| PutLetterontheBowlUnseen|0.92|2.89|\n",
    "\n",
    "|  | Success rate|mean step|\n",
    "| :----: | :----: | :----: |\n",
    "| RL|0.92|2.53|\n",
    "| VLM+LLM code|0.79|4.24|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) UHD Graphics (TGL GT1)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 23.0.4-0ubuntu1~22.04.1\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 23.0.4-0ubuntu1~22.04.1\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) UHD Graphics (TGL GT1)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets\n",
    "env = ResPickOrPlaceEnvWithoutLangReward(\n",
    "                                        task= PutLetterontheBowl,\n",
    "                                         image_obs=True,\n",
    "                                         residual=True,\n",
    "                                         observation_noise=5,\n",
    "                                         render=True,\n",
    "                                         multi_discrete=False,\n",
    "                                         scale_action=True,\n",
    "                                         ee=\"suction\",\n",
    "                                         scale_obs=True,\n",
    "                                         neglect_steps=False,\n",
    "                                         one_hot_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.056250141920928975, -0.3901784729802322, -0.053500000000000006]\n",
      "action: [ 0. 71. 91.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 68, 95] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.28571429] real action [ 0. 71. 91.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.06428585192092895, -0.3767856229802322, -0.053500000000000006]\n",
      "action: [ 0. 66. 88.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 67, 95] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ] real action [ 0. 66. 88.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.05892871192092897, -0.3821427629802322, -0.053500000000000006]\n",
      "action: [ 0. 68. 90.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 66, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.35714286] real action [ 0. 68. 90.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.04017872192092897, -0.3928570429802322, -0.053500000000000006]\n",
      "action: [ 0. 72. 97.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 66, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.14285714] real action [ 0. 72. 97.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.048214431920928946, -0.38749990298023224, -0.053500000000000006]\n",
      "action: [ 0. 70. 94.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 67, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [ 0. 70. 94.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.05892871192092897, -0.37946419298023226, -0.053500000000000006]\n",
      "action: [ 0. 67. 90.]\n",
      "pick_success 0\n",
      "dis 6.0 pick_success 0\n",
      "desired_action : [0, 67, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.35714286] real action [ 0. 67. 90.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.053571571920928956, -0.3767856229802322, -0.053500000000000006]\n",
      "action: [ 0. 66. 92.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 67, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.21428571] real action [ 0. 66. 92.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.  0.  0.  1.  0.  0.  0.  0.5 0. ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.045535861920928955, -0.4008927529802322, -0.04012125527858734]\n",
      "action: [ 0. 75. 95.]\n",
      "pick_success 0\n",
      "dis 8.06225774829855 pick_success 0\n",
      "desired_action : [0, 67, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [0.  0.  0.  1.  0.  0.  0.  0.5 0. ] real action [ 0. 75. 95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.06160728192092896, -0.3767856229802322, -0.053500000000000006]\n",
      "action: [ 0. 66. 89.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 67, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143] real action [ 0. 66. 89.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.03214301192092894, -0.38749990298023224, -0.053500000000000006]\n",
      "action: [  0.  70. 100.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 67, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.35714286] real action [  0.  70. 100.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.042857291920928964, -0.36607134298023225, -0.053500000000000006]\n",
      "action: [ 0. 62. 96.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 67, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.07142857] real action [ 0. 62. 96.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.43303571 0.64285714 0.19196429 0.76339286 0.30357143 0.42410714\n",
      " 0.78571429 0.74107143 0.82142857 0.18303571 0.65625    0.40178571] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.        ]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.184821158079071, -0.6339283429802323, -0.035694747999310494]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 161, 181] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.        ] real action [  0. 162. 181.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.22321429 0.53571429 0.57142857 0.59375    0.71875    0.80803571\n",
      " 0.74107143 0.20982143 0.81696429 0.46428571 0.28125    0.75892857] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.6366069129802322, -0.03633053770661354]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 161, 181] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.07142857] real action [  0. 163. 182.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.22321429 0.53571429 0.57142857 0.59375    0.71875    0.80803571\n",
      " 0.74107143 0.20982143 0.81696429 0.46428571 0.28125    0.75892857] [False]\n",
      "get_expert_demonstration\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.184821158079071, -0.6312497729802322, -0.036471418872475625]\n",
      "pick_success 0\n",
      "dis 0.0 pick_success 0\n",
      "desired_action : [0, 161, 181] phase_loss 0.0 dis_reward 0\n",
      "action  [0. 0. 0. 1. 0. 0. 0. 0. 0.] real action [  0. 161. 181.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.22321429 0.53571429 0.57142857 0.59375    0.71875    0.80803571\n",
      " 0.74107143 0.20982143 0.81696429 0.46428571 0.28125    0.75892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.18214258807907102, -0.6366069129802322, -0.040356503635644914]\n",
      "action: [  0. 163. 180.]\n",
      "pick_success 1\n",
      "dis 2.23606797749979 pick_success 1\n",
      "desired_action : [0, 161, 181] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [  0. 163. 180.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.22321429 0.53571429 0.57142857 0.59375    0.00446429 0.5\n",
      " 0.74107143 0.20982143 0.81696429 0.46428571 0.28125    0.75892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571 -0.14285714]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [-0.17946436192092896, -0.6366069129802322, 0.0248567126467824]\n",
      "place_xyz[2] 0.0248567126467824 False\n",
      "desired_action : [1, 166, 47] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571 -0.14285714] real action [  1. 163.  45.]\n",
      "reward 0.99974 done:  True\n",
      "observation: [0.22321429 0.53571429 0.57142857 0.59375    0.71428571 0.20535714\n",
      " 0.74107143 0.20982143 0.81696429 0.46428571 0.28125    0.75892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.018750161920928987, -0.5428569629802322, -0.053500000000000006]\n",
      "action: [  0. 128. 105.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 124, 102] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571] real action [  0. 128. 105.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02678587192092896, -0.5348212529802323, -0.053500000000000006]\n",
      "action: [  0. 125. 102.]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 124, 102] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.        ] real action [  0. 125. 102.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.5       ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.045535861920928955, -0.5374998229802322, -0.053500000000000006]\n",
      "action: [  0. 126.  95.]\n",
      "pick_success 0\n",
      "dis 7.280109889280518 pick_success 0\n",
      "desired_action : [0, 124, 102] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.5       ] real action [  0. 126.  95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.029464441920928952, -0.5321426829802323, -0.053500000000000006]\n",
      "action: [  0. 124. 101.]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 124, 102] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.07142857] real action [  0. 124. 101.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.03482158192092899, -0.5187498329802323, -0.053500000000000006]\n",
      "action: [  0. 119.  99.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 124, 102] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.21428571] real action [  0. 119.  99.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.03482158192092899, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [  0. 118.  99.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 123, 102] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571] real action [  0. 118.  99.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.03482158192092899, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [  0. 118.  99.]\n",
      "pick_success 0\n",
      "dis 6.4031242374328485 pick_success 0\n",
      "desired_action : [0, 123, 103] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571] real action [  0. 118.  99.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857  0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02410730192092897, -0.5107141229802322, -0.053500000000000006]\n",
      "action: [  0. 116. 103.]\n",
      "pick_success 0\n",
      "dis 6.0 pick_success 0\n",
      "desired_action : [0, 122, 103] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857  0.07142857] real action [  0. 116. 103.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.029464441920928952, -0.5187498329802323, -0.053500000000000006]\n",
      "action: [  0. 119. 101.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 122, 103] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.07142857] real action [  0. 119. 101.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.03214301192092894, -0.5241069729802322, -0.053500000000000006]\n",
      "action: [  0. 121. 100.]\n",
      "pick_success 0\n",
      "dis 3.0 pick_success 0\n",
      "desired_action : [0, 121, 103] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.14285714] real action [  0. 121. 100.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46875    0.18303571 0.55357143 0.45535714 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02142873192092898, -0.5214284029802323, -0.053500000000000006]\n",
      "action: [  0. 120. 104.]\n",
      "pick_success 0\n",
      "dis 0.0 pick_success 0\n",
      "desired_action : [0, 120, 104] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.14285714] real action [  0. 120. 104.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.46875    0.18303571 0.53125    0.46428571 0.26339286 0.69196429\n",
      " 0.75       0.1875     0.30357143 0.38392857 0.5625     0.69196429] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.16071437192092897, -0.4785712829802322, -0.053500000000000006]\n",
      "action: [  0. 104.  52.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 106, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.21428571] real action [  0. 104.  52.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47321429 0.21875    0.41964286 0.55357143 0.73214286 0.70089286\n",
      " 0.73660714 0.30803571 0.1875     0.78571429 0.21875    0.29017857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.42857143]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.15267866192092897, -0.47321414298023223, -0.035485073760151864]\n",
      "pick_success 0\n",
      "dis 7.211102550927978 pick_success 0\n",
      "desired_action : [0, 106, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.42857143] real action [  0. 102.  55.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47321429 0.21875    0.41964286 0.55357143 0.73214286 0.70089286\n",
      " 0.73660714 0.30803571 0.1875     0.78571429 0.21875    0.29017857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.16339294192092896, -0.4785712829802322, -0.053500000000000006]\n",
      "action: [  0. 104.  51.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 106, 48] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714] real action [  0. 104.  51.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47321429 0.21875    0.41964286 0.55357143 0.73214286 0.70089286\n",
      " 0.73660714 0.30803571 0.1875     0.78571429 0.21875    0.29017857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.17678579192092897, -0.49999984298023226, -0.053500000000000006]\n",
      "action: [  0. 112.  46.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 107, 48] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.21428571] real action [  0. 112.  46.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47321429 0.21875    0.41964286 0.55357143 0.73214286 0.70089286\n",
      " 0.73660714 0.30803571 0.1875     0.78571429 0.21875    0.29017857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.17142865192092896, -0.4785712829802322, -0.053500000000000006]\n",
      "action: [  0. 104.  48.]\n",
      "pick_success 0\n",
      "dis 3.0 pick_success 0\n",
      "desired_action : [0, 107, 48] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.07142857] real action [  0. 104.  48.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47321429 0.21875    0.41964286 0.55357143 0.73214286 0.70089286\n",
      " 0.73660714 0.30803571 0.1875     0.78571429 0.21875    0.29017857] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.16875008192092897, -0.4946427029802322, -0.053500000000000006]\n",
      "action: [  0. 110.  49.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 108, 47] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ] real action [  0. 110.  49.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47321429 0.21875    0.41964286 0.55357143 0.73214286 0.70089286\n",
      " 0.73660714 0.30803571 0.1875     0.78571429 0.21875    0.29017857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.16875008192092897, -0.46785700298023225, -0.04089742323756218]\n",
      "action: [  0. 100.  49.]\n",
      "pick_success 1\n",
      "dis 8.246211251235321 pick_success 1\n",
      "desired_action : [0, 108, 47] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143  0.        ] real action [  0. 100.  49.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.04464286 0.48660714 0.41964286 0.55357143 0.73214286 0.70089286\n",
      " 0.73660714 0.30803571 0.1875     0.78571429 0.21875    0.29017857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.14285714 -0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.12321439192092895, -0.6366069129802322, 0.024314527377486232]\n",
      "place_xyz[2] 0.024314527377486232 False\n",
      "desired_action : [1, 165, 69] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.14285714 -0.21428571] real action [  1. 163.  66.]\n",
      "reward 0.99974 done:  True\n",
      "observation: [0.75892857 0.29017857 0.41964286 0.55357143 0.73214286 0.70089286\n",
      " 0.73660714 0.30803571 0.1875     0.78571429 0.21875    0.29017857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.35714286]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.17946401807907103, -0.6178569229802322, -0.03996520473062992]\n",
      "action: [  0. 156. 179.]\n",
      "pick_success 1\n",
      "dis 7.810249675906654 pick_success 1\n",
      "desired_action : [0, 162, 184] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.35714286] real action [  0. 156. 179.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.18303571 0.53125    0.66517857 0.16964286 0.04464286 0.51785714\n",
      " 0.82589286 0.52232143 0.30803571 0.75892857 0.34375    0.23660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.64285714  0.5       ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.17410687807907105, -0.36071420298023227, 0.021526695206761363]\n",
      "place_xyz[2] 0.021526695206761363 False\n",
      "desired_action : [1, 69, 170] phase_loss 0.0 dis_reward -0.0026\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.64285714  0.5       ] real action [  1.  60. 177.]\n",
      "reward 0.9974 done:  True\n",
      "observation: [0.18303571 0.53125    0.66517857 0.16964286 0.29464286 0.8125\n",
      " 0.82589286 0.52232143 0.30803571 0.75892857 0.34375    0.23660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.045535861920928955, -0.5696426629802323, -0.053500000000000006]\n",
      "action: [  0. 138.  95.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 134, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.14285714] real action [  0. 138.  95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.71875    0.59821429 0.43303571 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.03482158192092899, -0.5562498129802322, -0.053500000000000006]\n",
      "action: [  0. 133.  99.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 134, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  0. 133.  99.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.71875    0.59821429 0.43303571 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.045535861920928955, -0.5669640929802322, -0.053500000000000006]\n",
      "action: [  0. 137.  95.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 134, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714] real action [  0. 137.  95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.71875    0.59821429 0.43303571 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02410730192092897, -0.5589283829802323, -0.053500000000000006]\n",
      "action: [  0. 134. 103.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 133, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.42857143] real action [  0. 134. 103.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.71875    0.59821429 0.43303571 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.03214301192092894, -0.5669640929802322, -0.053500000000000006]\n",
      "action: [  0. 137. 100.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 132, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571] real action [  0. 137. 100.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.71875    0.59821429 0.43303571 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02410730192092897, -0.5562498129802322, -0.053500000000000006]\n",
      "action: [  0. 133. 103.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 132, 98] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.42857143] real action [  0. 133. 103.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.71875    0.59821429 0.43303571 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.5       ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.05892871192092897, -0.5455355329802323, -0.03904158419370651]\n",
      "action: [  0. 129.  90.]\n",
      "pick_success 0\n",
      "dis 8.246211251235321 pick_success 0\n",
      "desired_action : [0, 131, 98] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.5       ] real action [  0. 129.  90.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.71875    0.59821429 0.43303571 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.042857291920928964, -0.5589283829802323, -0.053500000000000006]\n",
      "action: [  0. 134.  96.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 131, 98] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.07142857] real action [  0. 134.  96.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.71875    0.59821429 0.43303571 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.029464441920928952, -0.5749998029802322, -0.039343025371432305]\n",
      "action: [  0. 140. 101.]\n",
      "pick_success 1\n",
      "dis 10.44030650891055 pick_success 1\n",
      "desired_action : [0, 130, 98] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.28571429] real action [  0. 140. 101.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.58928571  0.71875    -0.03125     0.48214286  0.17410714  0.49107143\n",
      "  0.77232143  0.13392857  0.19642857  0.71875     0.35267857  0.12946429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.5        0.57142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.152678318079071, -0.33660707298023224, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 44, 161] phase_loss 0.0 dis_reward -0.0022600000000000003\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.5        0.57142857] real action [  1.  51. 169.]\n",
      "reward 0.99774 done:  True\n",
      "observation: [0.58928571 0.71875    0.18303571 0.74107143 0.17410714 0.49107143\n",
      " 0.77232143 0.13392857 0.19642857 0.71875    0.35267857 0.12946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857  0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.06428585192092895, -0.34999992298023225, -0.03674481047689915]\n",
      "pick_success 0\n",
      "dis 8.06225774829855 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857  0.07142857] real action [ 0. 56. 88.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.06964299192092896, -0.35535706298023223, -0.04317327944934368]\n",
      "action: [ 0. 58. 86.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857] real action [ 0. 58. 86.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.06964299192092896, -0.35535706298023223, -0.039045627996325494]\n",
      "action: [ 0. 58. 86.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857] real action [ 0. 58. 86.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.05892871192092897, -0.3633927729802322, -0.053500000000000006]\n",
      "action: [ 0. 61. 90.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571] real action [ 0. 61. 90.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.42857143]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.050893001920928965, -0.36071420298023227, -0.053500000000000006]\n",
      "action: [ 0. 60. 93.]\n",
      "pick_success 0\n",
      "dis 7.211102550927978 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.42857143] real action [ 0. 60. 93.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.14285714]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.06160728192092896, -0.36071420298023227, -0.053500000000000006]\n",
      "action: [ 0. 60. 89.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.14285714] real action [ 0. 60. 89.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.06428585192092895, -0.36071420298023227, -0.053500000000000006]\n",
      "action: [ 0. 60. 88.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.07142857] real action [ 0. 60. 88.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.42857143]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.050893001920928965, -0.36874991298023224, -0.053500000000000006]\n",
      "action: [ 0. 63. 93.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.42857143] real action [ 0. 63. 93.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.07232156192092895, -0.36071420298023227, -0.04003109580278397]\n",
      "action: [ 0. 60. 85.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714] real action [ 0. 60. 85.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.06428585192092895, -0.3580356329802322, -0.053500000000000006]\n",
      "action: [ 0. 59. 88.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.07142857] real action [ 0. 59. 88.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.38839286 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.07767870192092896, -0.3633927729802322, -0.04196426256000996]\n",
      "action: [ 0. 61. 83.]\n",
      "pick_success 1\n",
      "dis 5.0 pick_success 1\n",
      "desired_action : [0, 64, 87] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429] real action [ 0. 61. 83.]\n",
      "reward 0.0 done:  True\n",
      "observation: [0.01785714 0.51785714 0.76339286 0.19642857 0.48214286 0.5625\n",
      " 0.28571429 0.78571429 0.79910714 0.67410714 0.49107143 0.16964286] [ True]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.14285714]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.01607159192092894, -0.3392856429802322, -0.04004986195266247]\n",
      "action: [  0.  52. 106.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 56, 104] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.14285714] real action [  0.  52. 106.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.50892857 0.33928571 0.16964286 0.25       0.46428571\n",
      " 0.80803571 0.22321429 0.38392857 0.75       0.69642857 0.71875   ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.        ]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.02142873192092898, -0.35267849298023224, -0.03918835131824017]\n",
      "action: [  0.  57. 104.]\n",
      "pick_success 1\n",
      "dis 1.4142135623730951 pick_success 1\n",
      "desired_action : [0, 56, 105] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.        ] real action [  0.  57. 104.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.67410714 0.50892857 0.33928571 0.16964286 0.00446429 0.5\n",
      " 0.80803571 0.22321429 0.38392857 0.75       0.69642857 0.71875   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571 -0.5       ]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [-0.18482150192092894, -0.6767854629802322, 0.022613003827631477]\n",
      "place_xyz[2] 0.022613003827631477 False\n",
      "desired_action : [1, 181, 50] phase_loss 0.0 dis_reward -0.0011600000000000002\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571 -0.5       ] real action [  1. 178.  43.]\n",
      "reward 0.99884 done:  True\n",
      "observation: [0.67410714 0.50892857 0.33928571 0.16964286 0.78571429 0.19642857\n",
      " 0.80803571 0.22321429 0.38392857 0.75       0.69642857 0.71875   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.57142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.12589296192092897, -0.5401783929802322, -0.03539166769385338]\n",
      "pick_success 0\n",
      "dis 8.54400374531753 pick_success 0\n",
      "desired_action : [0, 130, 73] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.57142857] real action [  0. 127.  65.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58035714 0.32589286 0.55357143 0.70982143 0.32142857 0.57589286\n",
      " 0.81696429 0.66964286 0.22767857 0.14732143 0.82589286 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.42857143]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.08839298192092895, -0.5482141029802322, -0.04158723710477352]\n",
      "action: [  0. 130.  79.]\n",
      "pick_success 0\n",
      "dis 6.0 pick_success 0\n",
      "desired_action : [0, 130, 73] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.42857143] real action [  0. 130.  79.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58035714 0.32589286 0.55357143 0.70982143 0.32142857 0.57589286\n",
      " 0.81696429 0.66964286 0.22767857 0.14732143 0.82589286 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.28571429]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.09375012192092896, -0.5428569629802322, -0.053500000000000006]\n",
      "action: [  0. 128.  77.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 130, 73] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.28571429] real action [  0. 128.  77.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58035714 0.32589286 0.55357143 0.70982143 0.32142857 0.57589286\n",
      " 0.81696429 0.66964286 0.22767857 0.14732143 0.82589286 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.14285714]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.09910726192092897, -0.5401783929802322, -0.053500000000000006]\n",
      "action: [  0. 127.  75.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 131, 73] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.14285714] real action [  0. 127.  75.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58035714 0.32589286 0.55357143 0.70982143 0.32142857 0.57589286\n",
      " 0.81696429 0.66964286 0.22767857 0.14732143 0.82589286 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.10178583192092897, -0.5348212529802323, -0.03881715035438538]\n",
      "action: [  0. 125.  74.]\n",
      "pick_success 1\n",
      "dis 6.082762530298219 pick_success 1\n",
      "desired_action : [0, 131, 73] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.07142857] real action [  0. 125.  74.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.04017857 0.49107143 0.55357143 0.70982143 0.32142857 0.57589286\n",
      " 0.81696429 0.66964286 0.22767857 0.14732143 0.82589286 0.41964286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.42857143 -0.28571429]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [0.09107120807907104, -0.7062497329802322, 0.02617571966350079]\n",
      "place_xyz[2] 0.02617571966350079 False\n",
      "desired_action : [1, 183, 150] phase_loss 0.0 dis_reward -0.00104\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.42857143 -0.28571429] real action [  1. 189. 146.]\n",
      "reward 0.99896 done:  True\n",
      "observation: [0.86607143 0.65178571 0.55357143 0.70982143 0.32142857 0.57589286\n",
      " 0.81696429 0.66964286 0.22767857 0.14732143 0.82589286 0.41964286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.14732117807907102, -0.31517851298023225, -0.04994405882805586]\n",
      "action: [  0.  43. 167.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 45, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.14285714] real action [  0.  43. 167.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.50446429 0.5        0.73660714 0.25446429 0.20089286 0.75446429\n",
      " 0.36607143 0.15178571 0.20535714 0.4375     0.68303571 0.77232143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.16071402807907104, -0.31785708298023224, -0.046227091759443284]\n",
      "action: [  0.  44. 172.]\n",
      "pick_success 1\n",
      "dis 3.0 pick_success 1\n",
      "desired_action : [0, 44, 169] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.21428571] real action [  0.  44. 172.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.50446429 0.5        0.73660714 0.25446429 0.         0.48660714\n",
      " 0.36607143 0.15178571 0.20535714 0.4375     0.68303571 0.77232143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.85714286 -0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.042857291920928964, -0.35535706298023223, 0.01839940340816975]\n",
      "place_xyz[2] 0.01839940340816975 False\n",
      "desired_action : [1, 46, 98] phase_loss 0.0 dis_reward -0.0029599999999999995\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.85714286 -0.14285714] real action [ 1. 58. 96.]\n",
      "reward 0.99704 done:  True\n",
      "observation: [0.50446429 0.5        0.73660714 0.25446429 0.24553571 0.41517857\n",
      " 0.36607143 0.15178571 0.20535714 0.4375     0.68303571 0.77232143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.10714262807907105, -0.4919641329802322, -0.03969902342557907]\n",
      "action: [  0. 109. 152.]\n",
      "pick_success 1\n",
      "dis 4.242640687119285 pick_success 1\n",
      "desired_action : [0, 112, 149] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571] real action [  0. 109. 152.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.41071429 0.17857143 0.02678571 0.48214286 0.70089286 0.31696429\n",
      " 0.83035714 0.75892857 0.29017857 0.46428571 0.17410714 0.75446429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.92857143  0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.15803545807907105, -0.6633926129802322, 0.021750142775475982]\n",
      "place_xyz[2] 0.021750142775475982 False\n",
      "desired_action : [1, 186, 170] phase_loss 0.0 dis_reward -0.003400000000000001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.92857143  0.07142857] real action [  1. 173. 171.]\n",
      "reward 0.9966 done:  True\n",
      "observation: [0.41071429 0.17857143 0.78125    0.75446429 0.70089286 0.31696429\n",
      " 0.83035714 0.75892857 0.29017857 0.46428571 0.17410714 0.75446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.08303549807907101, -0.5348212529802323, -0.03932346759736538]\n",
      "action: [  0. 125. 143.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 124, 146] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571] real action [  0. 125. 143.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.52232143 0.17857143 0.00892857 0.50446429 0.82589286 0.49107143\n",
      " 0.20535714 0.45089286 0.23660714 0.19642857 0.17410714 0.75892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.5        -0.21428571]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [-0.03750015192092898, -0.30446423298023223, 0.022502297513186935]\n",
      "place_xyz[2] 0.022502297513186935 False\n",
      "desired_action : [1, 46, 101] phase_loss 0.0 dis_reward -0.0011600000000000002\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.5        -0.21428571] real action [ 1. 39. 98.]\n",
      "reward 0.99884 done:  True\n",
      "observation: [0.52232143 0.17857143 0.16964286 0.44642857 0.82589286 0.49107143\n",
      " 0.20535714 0.45089286 0.23660714 0.19642857 0.17410714 0.75892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10714297192092898, -0.4785712829802322, -0.053500000000000006]\n",
      "action: [  0. 104.  72.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 107, 77] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286] real action [  0. 104.  72.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.09107155192092897, -0.48928556298023224, -0.053500000000000006]\n",
      "action: [  0. 108.  78.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 107, 76] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.07142857] real action [  0. 108.  78.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.08571441192092896, -0.4785712829802322, -0.053500000000000006]\n",
      "action: [  0. 104.  80.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 107, 76] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571] real action [  0. 104.  80.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10714297192092898, -0.48928556298023224, -0.053500000000000006]\n",
      "action: [  0. 108.  72.]\n",
      "pick_success 0\n",
      "dis 4.0 pick_success 0\n",
      "desired_action : [0, 108, 76] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286] real action [  0. 108.  72.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10178583192092897, -0.49999984298023226, -0.053500000000000006]\n",
      "action: [  0. 112.  74.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 108, 76] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.21428571] real action [  0. 112.  74.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10446440192092896, -0.48928556298023224, -0.053500000000000006]\n",
      "action: [  0. 108.  73.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 109, 76] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.28571429] real action [  0. 108.  73.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.08571441192092896, -0.4973212729802322, -0.053500000000000006]\n",
      "action: [  0. 111.  80.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 109, 75] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571] real action [  0. 111.  80.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.09642869192092896, -0.4919641329802322, -0.053500000000000006]\n",
      "action: [  0. 109.  76.]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 109, 75] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [  0. 109.  76.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.09375012192092896, -0.4973212729802322, -0.053500000000000006]\n",
      "action: [  0. 111.  77.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 110, 75] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ] real action [  0. 111.  77.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.34375    0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.08303584192092897, -0.47321414298023223, -0.04073694331943989]\n",
      "action: [  0. 102.  81.]\n",
      "pick_success 1\n",
      "dis 10.0 pick_success 1\n",
      "desired_action : [0, 110, 75] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.28571429] real action [  0. 102.  81.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.04464286 0.46428571 0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.  0.  0.  0.  0.  0.  1. -1.  0.]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.06428585192092895, -0.26428568298023225, 0.022411623015999797]\n",
      "place_xyz[2] 0.022411623015999797 False\n",
      "desired_action : [1, 38, 88] phase_loss 0.0 dis_reward -0.003920000000000001\n",
      "action  [ 1.  0.  0.  0.  0.  0.  1. -1.  0.] real action [ 1. 24. 88.]\n",
      "reward 0.99608 done:  True\n",
      "observation: [0.13839286 0.36607143 0.21875    0.17857143 0.8125     0.76785714\n",
      " 0.26339286 0.75446429 0.75446429 0.21428571 0.16964286 0.39285714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.  0.  1.  0.  0.  0.  0.  0.  0.5]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.206249718079071, -0.30982137298023227, -0.04136792740225792]\n",
      "action: [  0.  41. 189.]\n",
      "pick_success 0\n",
      "dis 7.0 pick_success 0\n",
      "desired_action : [0, 41, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [0.  0.  1.  0.  0.  0.  0.  0.  0.5] real action [  0.  41. 189.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.17678544807907104, -0.31785708298023224, -0.053500000000000006]\n",
      "action: [  0.  44. 178.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 41, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.28571429] real action [  0.  44. 178.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.19821400807907102, -0.30178566298023224, -0.04541732540726662]\n",
      "action: [  0.  38. 186.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 41, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.28571429] real action [  0.  38. 186.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.184821158079071, -0.30446423298023223, -0.053500000000000006]\n",
      "action: [  0.  39. 181.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 41, 181] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.07142857] real action [  0.  39. 181.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.187499728079071, -0.29642852298023226, -0.053500000000000006]\n",
      "action: [  0.  36. 182.]\n",
      "pick_success 0\n",
      "dis 6.0 pick_success 0\n",
      "desired_action : [0, 42, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ] real action [  0.  36. 182.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.19821400807907102, -0.30178566298023224, -0.039404718041419984]\n",
      "action: [  0.  38. 186.]\n",
      "pick_success 0\n",
      "dis 5.656854249492381 pick_success 0\n",
      "desired_action : [0, 42, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.28571429] real action [  0.  38. 186.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.187499728079071, -0.29642852298023226, -0.04899915198236704]\n",
      "action: [  0.  36. 182.]\n",
      "pick_success 0\n",
      "dis 6.0 pick_success 0\n",
      "desired_action : [0, 42, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ] real action [  0.  36. 182.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.17142830807907106, -0.30982137298023227, -0.053500000000000006]\n",
      "action: [  0.  41. 176.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 42, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.42857143] real action [  0.  41. 176.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.19821400807907102, -0.30982137298023227, -0.053500000000000006]\n",
      "action: [  0.  41. 186.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 43, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.28571429] real action [  0.  41. 186.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.19017829807907105, -0.30982137298023227, -0.053500000000000006]\n",
      "action: [  0.  41. 183.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 43, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.07142857] real action [  0.  41. 183.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.20089257807907102, -0.3232142229802322, -0.053500000000000006]\n",
      "action: [  0.  46. 187.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 43, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.35714286] real action [  0.  46. 187.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.28571429 0.32589286 0.18303571 0.8125     0.40625    0.68303571\n",
      " 0.80803571 0.60714286 0.79464286 0.32589286 0.54017857 0.24107143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.07232121807907105, -0.5669640929802322, -0.053500000000000006]\n",
      "action: [  0. 137. 139.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 132, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.21428571] real action [  0. 137. 139.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.07232121807907105, -0.5642855229802322, -0.053500000000000006]\n",
      "action: [  0. 136. 139.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 132, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571] real action [  0. 136. 139.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.07232121807907105, -0.5616069529802322, -0.053500000000000006]\n",
      "action: [  0. 135. 139.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 132, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571] real action [  0. 135. 139.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.048214088079071016, -0.5642855229802322, -0.053500000000000006]\n",
      "action: [  0. 136. 130.]\n",
      "pick_success 0\n",
      "dis 7.211102550927978 pick_success 0\n",
      "desired_action : [0, 132, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.42857143] real action [  0. 136. 130.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.07232121807907105, -0.5455355329802323, -0.053500000000000006]\n",
      "action: [  0. 129. 139.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 132, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571] real action [  0. 129. 139.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.048214088079071016, -0.5508926729802321, -0.053500000000000006]\n",
      "action: [  0. 131. 130.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 132, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.42857143] real action [  0. 131. 130.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.06160693807907103, -0.5562498129802322, -0.053500000000000006]\n",
      "action: [  0. 133. 135.]\n",
      "pick_success 0\n",
      "dis 1.4142135623730951 pick_success 0\n",
      "desired_action : [0, 132, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.07142857] real action [  0. 133. 135.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.06428550807907102, -0.5455355329802323, -0.053500000000000006]\n",
      "action: [  0. 129. 136.]\n",
      "pick_success 0\n",
      "dis 3.0 pick_success 0\n",
      "desired_action : [0, 132, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.        ] real action [  0. 129. 136.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.08035692807907102, -0.5535712429802322, -0.03561908735334873]\n",
      "pick_success 0\n",
      "dis 7.0 pick_success 0\n",
      "desired_action : [0, 132, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.42857143] real action [  0. 132. 142.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.05089265807907101, -0.5455355329802323, -0.053500000000000006]\n",
      "action: [  0. 129. 131.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 132, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286] real action [  0. 129. 131.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.056249798079071045, -0.5616069529802322, -0.053500000000000006]\n",
      "action: [  0. 135. 133.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 132, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.21428571] real action [  0. 135. 133.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.58928571 0.60714286 0.70089286 0.26785714 0.1875     0.33035714\n",
      " 0.75892857 0.77678571 0.24553571 0.73660714 0.44196429 0.31696429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.35714286]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.02410695807907104, -0.5830355129802323, -0.035197574481368066]\n",
      "pick_success 0\n",
      "dis 5.385164807134517 pick_success 0\n",
      "desired_action : [0, 141, 116] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.35714286] real action [  0. 143. 121.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.79910714 0.28571429 0.62946429 0.51785714 0.22321429 0.33482143\n",
      " 0.29464286 0.70089286 0.75892857 0.75446429 0.55357143 0.17410714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.018749818079071057, -0.5776783729802322, -0.04000570794939995]\n",
      "action: [  0. 141. 119.]\n",
      "pick_success 1\n",
      "dis 2.000000000000014 pick_success 1\n",
      "desired_action : [0, 141, 117] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.21428571] real action [  0. 141. 119.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.79910714 0.28571429 0.01339286 0.48214286 0.22321429 0.33482143\n",
      " 0.29464286 0.70089286 0.75892857 0.75446429 0.55357143 0.17410714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.5        -0.35714286]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.13928546807907105, -0.6366069129802322, 0.02726637849211693]\n",
      "place_xyz[2] 0.02726637849211693 False\n",
      "desired_action : [1, 170, 169] phase_loss 0.0 dis_reward -0.00148\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.5        -0.35714286] real action [  1. 163. 164.]\n",
      "reward 0.99852 done:  True\n",
      "observation: [0.79910714 0.28571429 0.72321429 0.72321429 0.22321429 0.33482143\n",
      " 0.29464286 0.70089286 0.75892857 0.75446429 0.55357143 0.17410714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.        ]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.18214293192092895, -0.5508926729802321, -0.053500000000000006]\n",
      "action: [  0. 131.  44.]\n",
      "pick_success 1\n",
      "dis 2.0 pick_success 1\n",
      "desired_action : [0, 133, 44] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.        ] real action [  0. 131.  44.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.46428571 0.51339286 0.01785714 0.49553571 0.45535714 0.79464286\n",
      " 0.75446429 0.42410714 0.33035714 0.15178571 0.1875     0.59821429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.21428571 -0.07142857]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping: place [-0.21160720192092897, -0.40624989298023223, 0.024594420544803146]\n",
      "place_xyz[2] 0.024594420544803146 False\n",
      "desired_action : [1, 74, 34] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.21428571 -0.07142857] real action [ 1. 77. 33.]\n",
      "reward 0.9998 done:  True\n",
      "observation: [0.46428571 0.51339286 0.34821429 0.15178571 0.45535714 0.79464286\n",
      " 0.75446429 0.42410714 0.33035714 0.15178571 0.1875     0.59821429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.12857118807907103, -0.5428569629802322, -0.03736232949793339]\n",
      "action: [  0. 128. 160.]\n",
      "pick_success 1\n",
      "dis 3.605551275463989 pick_success 1\n",
      "desired_action : [0, 125, 158] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.14285714] real action [  0. 128. 160.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.24107143 0.72767857 0.         0.48660714 0.6875     0.23660714\n",
      " 0.33928571 0.15178571 0.8125     0.50446429 0.32589286 0.43303571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.71428571  0.5       ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.19017864192092895, -0.3767856229802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 76, 34] phase_loss 0.0 dis_reward -0.00298\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.71428571  0.5       ] real action [ 1. 66. 41.]\n",
      "reward 0.99702 done:  True\n",
      "observation: [0.24107143 0.72767857 0.28125    0.17410714 0.6875     0.23660714\n",
      " 0.33928571 0.15178571 0.8125     0.50446429 0.32589286 0.43303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.14285714]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.20089257807907102, -0.6071426429802322, -0.03914511187374592]\n",
      "action: [  0. 152. 187.]\n",
      "pick_success 1\n",
      "dis 4.47213595499958 pick_success 1\n",
      "desired_action : [0, 148, 185] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.14285714] real action [  0. 152. 187.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.24553571 0.50446429 0.         0.48660714 0.41071429 0.1875\n",
      " 0.75892857 0.13839286 0.82589286 0.50446429 0.47767857 0.58928571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.         -0.57142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.03214266807907101, -0.48660699298023224, 0.024666160322725776]\n",
      "place_xyz[2] 0.024666160322725776 False\n",
      "desired_action : [1, 107, 132] phase_loss 0.0 dis_reward -0.00128\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.         -0.57142857] real action [  1. 107. 124.]\n",
      "reward 0.99872 done:  True\n",
      "observation: [0.24553571 0.50446429 0.45982143 0.54464286 0.41071429 0.1875\n",
      " 0.75892857 0.13839286 0.82589286 0.50446429 0.47767857 0.58928571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.13392867192092897, -0.5616069529802322, -0.053500000000000006]\n",
      "action: [  0. 135.  62.]\n",
      "pick_success 0\n",
      "dis 4.472135954999586 pick_success 0\n",
      "desired_action : [0, 137, 58] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.28571429] real action [  0. 135.  62.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.67410714 0.61160714 0.25892857 0.17857143 0.70535714\n",
      " 0.42410714 0.53125    0.28125    0.16071429 0.43303571 0.78571429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.15000009192092895, -0.5696426629802323, -0.053500000000000006]\n",
      "action: [  0. 138.  56.]\n",
      "pick_success 0\n",
      "dis 2.236067977499783 pick_success 0\n",
      "desired_action : [0, 137, 58] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.14285714] real action [  0. 138.  56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.67410714 0.61160714 0.25892857 0.17857143 0.70535714\n",
      " 0.42410714 0.53125    0.28125    0.16071429 0.43303571 0.78571429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.16339294192092896, -0.5616069529802322, -0.053500000000000006]\n",
      "action: [  0. 135.  51.]\n",
      "pick_success 0\n",
      "dis 7.280109889280512 pick_success 0\n",
      "desired_action : [0, 137, 58] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ] real action [  0. 135.  51.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.67410714 0.61160714 0.25892857 0.17857143 0.70535714\n",
      " 0.42410714 0.53125    0.28125    0.16071429 0.43303571 0.78571429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.42857143]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.12857153192092896, -0.5616069529802322, -0.053500000000000006]\n",
      "action: [  0. 135.  64.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 137, 58] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.42857143] real action [  0. 135.  64.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.67410714 0.61160714 0.25892857 0.17857143 0.70535714\n",
      " 0.42410714 0.53125    0.28125    0.16071429 0.43303571 0.78571429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.13660724192092896, -0.5616069529802322, -0.053500000000000006]\n",
      "action: [  0. 135.  61.]\n",
      "pick_success 0\n",
      "dis 2.236067977499796 pick_success 0\n",
      "desired_action : [0, 136, 59] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.21428571] real action [  0. 135.  61.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.67410714 0.61160714 0.25892857 0.17857143 0.70535714\n",
      " 0.42410714 0.53125    0.28125    0.16071429 0.43303571 0.78571429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.13928581192092895, -0.5562498129802322, -0.053500000000000006]\n",
      "action: [  0. 133.  60.]\n",
      "pick_success 0\n",
      "dis 2.236067977499793 pick_success 0\n",
      "desired_action : [0, 135, 59] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.14285714] real action [  0. 133.  60.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.67410714 0.61160714 0.25892857 0.17857143 0.70535714\n",
      " 0.42410714 0.53125    0.28125    0.16071429 0.43303571 0.78571429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.57142857 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.14732152192092896, -0.5883926529802322, -0.03902602551877499]\n",
      "action: [  0. 145.  57.]\n",
      "pick_success 1\n",
      "dis 11.401754250991377 pick_success 1\n",
      "desired_action : [0, 134, 60] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.57142857 -0.07142857] real action [  0. 145.  57.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.66964286  0.67410714 -0.03571429  0.50446429  0.17857143  0.70535714\n",
      "  0.42410714  0.53125     0.28125     0.16071429  0.43303571  0.78571429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.57142857 0.57142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.04017837807907104, -0.4758927129802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 95, 119] phase_loss 0.0 dis_reward -0.00256\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.57142857 0.57142857] real action [  1. 103. 127.]\n",
      "reward 0.99744 done:  True\n",
      "observation: [0.66964286 0.67410714 0.41071429 0.58035714 0.17857143 0.70535714\n",
      " 0.42410714 0.53125    0.28125    0.16071429 0.43303571 0.78571429] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.07142857]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.18214293192092895, -0.5107141229802322, -0.03845327517390251]\n",
      "action: [  0. 116.  44.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 113, 45] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.07142857] real action [  0. 116.  44.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.27232143 0.6875     0.78125    0.44196429 0.         0.49553571\n",
      " 0.79017857 0.71428571 0.36607143 0.38392857 0.57142857 0.5625    ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.07142857]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.06696442192092897, -0.41964274298023224, 0.022630784638226036]\n",
      "place_xyz[2] 0.022630784638226036 False\n",
      "desired_action : [1, 82, 86] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.07142857] real action [ 1. 82. 87.]\n",
      "reward 0.99998 done:  True\n",
      "observation: [0.27232143 0.6875     0.78125    0.44196429 0.35267857 0.39285714\n",
      " 0.79017857 0.71428571 0.36607143 0.38392857 0.57142857 0.5625    ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.07142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.13660724192092896, -0.34999992298023225, -0.053500000000000006]\n",
      "action: [ 0. 56. 61.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 59, 60] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.07142857] real action [ 0. 56. 61.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.54464286 0.5625     0.26339286 0.26785714 0.76339286 0.40625\n",
      " 0.53125    0.15178571 0.25892857 0.59375    0.73660714 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.5        -0.28571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.15000009192092895, -0.3767856229802322, -0.04024968466162682]\n",
      "action: [ 0. 66. 56.]\n",
      "pick_success 0\n",
      "dis 8.06225774829855 pick_success 0\n",
      "desired_action : [0, 59, 60] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.5        -0.28571429] real action [ 0. 66. 56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.54464286 0.5625     0.26339286 0.26785714 0.76339286 0.40625\n",
      " 0.53125    0.15178571 0.25892857 0.59375    0.73660714 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5        -0.07142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.14196438192092897, -0.3392856429802322, -0.03970348818600178]\n",
      "action: [ 0. 52. 59.]\n",
      "pick_success 1\n",
      "dis 7.0710678118654755 pick_success 1\n",
      "desired_action : [0, 59, 60] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5        -0.07142857] real action [ 0. 52. 59.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.54464286 0.5625     0.04017857 0.5        0.76339286 0.40625\n",
      " 0.53125    0.15178571 0.25892857 0.59375    0.73660714 0.73660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.14285714 0.28571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.152678318079071, -0.6473211929802323, 0.023372968636453155]\n",
      "place_xyz[2] 0.023372968636453155 False\n",
      "desired_action : [1, 165, 165] phase_loss 0.0 dis_reward -0.0004\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.14285714 0.28571429] real action [  1. 167. 169.]\n",
      "reward 0.9996 done:  True\n",
      "observation: [0.54464286 0.5625     0.77232143 0.76339286 0.76339286 0.40625\n",
      " 0.53125    0.15178571 0.25892857 0.59375    0.73660714 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.01339302192092895, -0.5428569629802322, -0.053500000000000006]\n",
      "action: [  0. 128. 107.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 124, 109] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.14285714] real action [  0. 128. 107.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.55357143 0.48660714 0.71875    0.74107143 0.29017857 0.54017857\n",
      " 0.31696429 0.12946429 0.36607143 0.76339286 0.80357143 0.1875    ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-1.7192092893747457e-07, -0.5348212529802323, -0.053500000000000006]\n",
      "action: [  0. 125. 112.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 124, 109] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.21428571] real action [  0. 125. 112.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.55357143 0.48660714 0.71875    0.74107143 0.29017857 0.54017857\n",
      " 0.31696429 0.12946429 0.36607143 0.76339286 0.80357143 0.1875    ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.02142873192092898, -0.5241069729802322, -0.053500000000000006]\n",
      "action: [  0. 121. 104.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 124, 109] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286] real action [  0. 121. 104.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.55357143 0.48660714 0.71875    0.74107143 0.29017857 0.54017857\n",
      " 0.31696429 0.12946429 0.36607143 0.76339286 0.80357143 0.1875    ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.42857143]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.008035538079071036, -0.5241069729802322, -0.04090831598639488]\n",
      "action: [  0. 121. 115.]\n",
      "pick_success 0\n",
      "dis 7.211102550927978 pick_success 0\n",
      "desired_action : [0, 125, 109] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.42857143] real action [  0. 121. 115.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.55357143 0.48660714 0.71875    0.74107143 0.29017857 0.54017857\n",
      " 0.31696429 0.12946429 0.36607143 0.76339286 0.80357143 0.1875    ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.01607159192092894, -0.5455355329802323, -0.053500000000000006]\n",
      "action: [  0. 129. 106.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 125, 109] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.21428571] real action [  0. 129. 106.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.55357143 0.48660714 0.71875    0.74107143 0.29017857 0.54017857\n",
      " 0.31696429 0.12946429 0.36607143 0.76339286 0.80357143 0.1875    ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.42857143]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.008035538079071036, -0.5187498329802323, -0.03945476917922497]\n",
      "action: [  0. 119. 115.]\n",
      "pick_success 1\n",
      "dis 8.48528137423857 pick_success 1\n",
      "desired_action : [0, 125, 109] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.42857143] real action [  0. 119. 115.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.04017857 0.46875    0.71875    0.74107143 0.29017857 0.54017857\n",
      " 0.31696429 0.12946429 0.36607143 0.76339286 0.80357143 0.1875    ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.64285714  0.85714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.19017864192092895, -0.36607134298023225, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 71, 29] phase_loss 0.0 dis_reward -0.0045\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.64285714  0.85714286] real action [ 1. 62. 41.]\n",
      "reward 0.9955 done:  True\n",
      "observation: [0.29910714 0.15625    0.71875    0.74107143 0.29017857 0.54017857\n",
      " 0.31696429 0.12946429 0.36607143 0.76339286 0.80357143 0.1875    ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.42857143]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.10982154192092897, -0.3955356129802322, -0.04057417793571949]\n",
      "action: [ 0. 73. 71.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 70, 65] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.42857143] real action [ 0. 73. 71.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.3125     0.29017857 0.54017857 0.54910714 0.76785714 0.29017857\n",
      " 0.83482143 0.79017857 0.55357143 0.77678571 0.21875    0.54910714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.11250011192092896, -0.4008927529802322, -0.053500000000000006]\n",
      "action: [ 0. 75. 70.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 70, 65] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.35714286] real action [ 0. 75. 70.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.3125     0.29017857 0.54017857 0.54910714 0.76785714 0.29017857\n",
      " 0.83482143 0.79017857 0.55357143 0.77678571 0.21875    0.54910714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.11785725192092897, -0.3955356129802322, -0.053500000000000006]\n",
      "action: [ 0. 73. 68.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 70, 64] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571] real action [ 0. 73. 68.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.3125     0.29017857 0.54017857 0.54910714 0.76785714 0.29017857\n",
      " 0.83482143 0.79017857 0.55357143 0.77678571 0.21875    0.54910714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.13928581192092895, -0.37142848298023223, -0.03759620322287083]\n",
      "action: [ 0. 64. 60.]\n",
      "pick_success 1\n",
      "dis 7.211102550927978 pick_success 1\n",
      "desired_action : [0, 70, 64] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.35714286] real action [ 0. 64. 60.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.03571429 0.51339286 0.54017857 0.54910714 0.76785714 0.29017857\n",
      " 0.83482143 0.79017857 0.55357143 0.77678571 0.21875    0.54910714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.71428571 -0.42857143]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping: place [0.013392678079071019, -0.30446423298023223, 0.021113160975277427]\n",
      "place_xyz[2] 0.021113160975277427 False\n",
      "desired_action : [1, 49, 123] phase_loss 0.0 dis_reward -0.002719999999999997\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.71428571 -0.42857143] real action [  1.  39. 117.]\n",
      "reward 0.99728 done:  True\n",
      "observation: [0.19642857 0.54464286 0.54017857 0.54910714 0.76785714 0.29017857\n",
      " 0.83482143 0.79017857 0.55357143 0.77678571 0.21875    0.54910714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.045535861920928955, -0.4142856029802322, -0.03672928719222546]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 81, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.21428571] real action [ 0. 80. 95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.16517857 0.63392857 0.59375    0.3125     0.36160714 0.41071429\n",
      " 0.47767857 0.72321429 0.73660714 0.54017857 0.1875     0.125     ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.045535861920928955, -0.41696417298023225, -0.0477580258846283]\n",
      "action: [ 0. 81. 95.]\n",
      "pick_success 0\n",
      "dis 3.0 pick_success 0\n",
      "desired_action : [0, 81, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.21428571] real action [ 0. 81. 95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.16517857 0.63392857 0.59375    0.3125     0.36160714 0.41071429\n",
      " 0.47767857 0.72321429 0.73660714 0.54017857 0.1875     0.125     ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.053571571920928956, -0.40624989298023223, -0.03967862746119499]\n",
      "action: [ 0. 77. 92.]\n",
      "pick_success 1\n",
      "dis 3.0 pick_success 1\n",
      "desired_action : [0, 80, 92] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.        ] real action [ 0. 77. 92.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.16517857 0.63392857 0.59375    0.3125     0.02678571 0.49553571\n",
      " 0.47767857 0.72321429 0.73660714 0.54017857 0.1875     0.125     ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.85714286  0.57142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.15535688807907105, -0.45446415298023224, 0.024712755322456363]\n",
      "place_xyz[2] 0.024712755322456363 False\n",
      "desired_action : [1, 107, 162] phase_loss 0.0 dis_reward -0.00416\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.85714286  0.57142857] real action [  1.  95. 170.]\n",
      "reward 0.99584 done:  True\n",
      "observation: [0.16517857 0.63392857 0.59375    0.3125     0.43303571 0.76339286\n",
      " 0.47767857 0.72321429 0.73660714 0.54017857 0.1875     0.125     ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.12321439192092895, -0.5428569629802322, -0.03742878867685795]\n",
      "action: [  0. 128.  66.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 125, 65] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.07142857] real action [  0. 128.  66.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.64732143 0.55357143 0.         0.49107143 0.49107143 0.83035714\n",
      " 0.28125    0.62053571 0.27232143 0.19196429 0.81696429 0.29464286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.28571429  0.35714286]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.085714068079071, -0.3580356329802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 63, 139] phase_loss 0.0 dis_reward -0.0008200000000000001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.28571429  0.35714286] real action [  1.  59. 144.]\n",
      "reward 0.99918 done:  True\n",
      "observation: [0.64732143 0.55357143 0.25       0.64285714 0.49107143 0.83035714\n",
      " 0.28125    0.62053571 0.27232143 0.19196429 0.81696429 0.29464286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.053571228079071054, -0.6205354929802323, -0.053500000000000006]\n",
      "action: [  0. 157. 132.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 161, 134] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714] real action [  0. 157. 132.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.07232121807907105, -0.6392854829802322, -0.053500000000000006]\n",
      "action: [  0. 164. 139.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 161, 134] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.35714286] real action [  0. 164. 139.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.058928368079071036, -0.6205354929802323, -0.053500000000000006]\n",
      "action: [  0. 157. 134.]\n",
      "pick_success 0\n",
      "dis 4.0 pick_success 0\n",
      "desired_action : [0, 161, 134] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.        ] real action [  0. 157. 134.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.058928368079071036, -0.6205354929802323, -0.053500000000000006]\n",
      "action: [  0. 157. 134.]\n",
      "pick_success 0\n",
      "dis 4.0 pick_success 0\n",
      "desired_action : [0, 161, 134] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.        ] real action [  0. 157. 134.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.056249798079071045, -0.6178569229802322, -0.053500000000000006]\n",
      "action: [  0. 156. 133.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 160, 134] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.07142857] real action [  0. 156. 133.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.058928368079071036, -0.6392854829802322, -0.053500000000000006]\n",
      "action: [  0. 164. 134.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 159, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.        ] real action [  0. 164. 134.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.06428550807907102, -0.6285712029802322, -0.053500000000000006]\n",
      "action: [  0. 160. 136.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 158, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  0. 160. 136.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.04285694807907103, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [  0. 159. 128.]\n",
      "pick_success 0\n",
      "dis 7.280109889280518 pick_success 0\n",
      "desired_action : [0, 157, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143] real action [  0. 159. 128.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.5       ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.04017837807907104, -0.6419640529802322, -0.0368513817191124]\n",
      "pick_success 0\n",
      "dis 11.313708498984761 pick_success 0\n",
      "desired_action : [0, 157, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.5       ] real action [  0. 165. 127.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.048214088079071016, -0.6366069129802322, -0.0389642341285944]\n",
      "action: [  0. 163. 130.]\n",
      "pick_success 0\n",
      "dis 7.810249675906654 pick_success 0\n",
      "desired_action : [0, 157, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.28571429] real action [  0. 163. 130.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.06428550807907102, -0.6473211929802323, -0.0344717370569706]\n",
      "pick_success 0\n",
      "dis 10.04987562112089 pick_success 0\n",
      "desired_action : [0, 157, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.14285714] real action [  0. 167. 136.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.46428571 0.50892857 0.71875    0.59821429 0.21428571 0.16964286\n",
      " 0.82589286 0.27678571 0.22767857 0.69196429 0.49553571 0.15178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857  0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.168749738079071, -0.4919641329802322, -0.040385708048939706]\n",
      "action: [  0. 109. 175.]\n",
      "pick_success 1\n",
      "dis 8.06225774829855 pick_success 1\n",
      "desired_action : [0, 117, 174] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857  0.07142857] real action [  0. 109. 175.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.04464286 0.49107143 0.63839286 0.42410714 0.24553571 0.72767857\n",
      " 0.83035714 0.66964286 0.45535714 0.125      0.24553571 0.26339286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.64285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.20089292192092895, -0.47321414298023223, 0.024954098254442218]\n",
      "place_xyz[2] 0.024954098254442218 False\n",
      "desired_action : [1, 102, 28] phase_loss 0.0 dis_reward -0.00162\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.64285714] real action [  1. 102.  37.]\n",
      "reward 0.99838 done:  True\n",
      "observation: [0.48660714 0.16071429 0.63839286 0.42410714 0.24553571 0.72767857\n",
      " 0.83035714 0.66964286 0.45535714 0.125      0.24553571 0.26339286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.03214301192092894, -0.37946419298023226, -0.053500000000000006]\n",
      "action: [  0.  67. 100.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 70, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.21428571] real action [  0.  67. 100.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.75       0.54017857 0.3125     0.43303571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.57142857]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.018750161920928987, -0.37946419298023226, -0.04158604873716831]\n",
      "action: [  0.  67. 105.]\n",
      "pick_success 0\n",
      "dis 8.54400374531753 pick_success 0\n",
      "desired_action : [0, 70, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.57142857] real action [  0.  67. 105.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.75       0.54017857 0.3125     0.43303571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.02678587192092896, -0.3901784729802322, -0.053500000000000006]\n",
      "action: [  0.  71. 102.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 70, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.35714286] real action [  0.  71. 102.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.75       0.54017857 0.3125     0.43303571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.28571429]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.029464441920928952, -0.3928570429802322, -0.0392976233959198]\n",
      "action: [  0.  72. 101.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 69, 98] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.28571429] real action [  0.  72. 101.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.75       0.54017857 0.3125     0.43303571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.02678587192092896, -0.3901784729802322, -0.053500000000000006]\n",
      "action: [  0.  71. 102.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 69, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.35714286] real action [  0.  71. 102.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.75       0.54017857 0.3125     0.43303571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.14285714]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.03482158192092899, -0.38749990298023224, -0.03619938513636589]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 68, 98] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.14285714] real action [ 0. 70. 99.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.75       0.54017857 0.3125     0.43303571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.42857143]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.02410730192092897, -0.38482133298023224, -0.053500000000000006]\n",
      "action: [  0.  69. 103.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 68, 98] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.42857143] real action [  0.  69. 103.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.75       0.54017857 0.3125     0.43303571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.21428571]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.03214301192092894, -0.38749990298023224, -0.041350645780563355]\n",
      "action: [  0.  70. 100.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 66, 98] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.21428571] real action [  0.  70. 100.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.75       0.54017857 0.3125     0.43303571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.28571429]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [-0.029464441920928952, -0.3901784729802322, -0.04369813932478428]\n",
      "action: [  0.  71. 101.]\n",
      "pick_success 1\n",
      "dis 5.830951894845301 pick_success 1\n",
      "desired_action : [0, 66, 98] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.28571429] real action [  0.  71. 101.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.75        0.54017857 -0.01339286  0.48660714  0.19642857  0.73660714\n",
      "  0.70535714  0.78125     0.20089286  0.14285714  0.57142857  0.23660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.57142857 0.78571429]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping: place [-0.12857153192092896, -0.5642855229802322, 0.02825505749881268]\n",
      "place_xyz[2] 0.02825505749881268 False\n",
      "desired_action : [1, 128, 53] phase_loss 0.0 dis_reward -0.0037000000000000006\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.57142857 0.78571429] real action [  1. 136.  64.]\n",
      "reward 0.9963 done:  True\n",
      "observation: [0.75       0.54017857 0.58035714 0.27678571 0.19642857 0.73660714\n",
      " 0.70535714 0.78125    0.20089286 0.14285714 0.57142857 0.23660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.        ]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.08839263807907105, -0.6874997429802322, -0.053500000000000006]\n",
      "action: [  0. 182. 145.]\n",
      "pick_success 0\n",
      "dis 4.0 pick_success 0\n",
      "desired_action : [0, 178, 145] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.        ] real action [  0. 182. 145.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.78571429 0.35714286 0.53125    0.67410714 0.79464286 0.64732143\n",
      " 0.42410714 0.39732143 0.29464286 0.74107143 0.59375    0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.09642834807907102, -0.6848211729802323, -0.053500000000000006]\n",
      "action: [  0. 181. 148.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 178, 145] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.21428571] real action [  0. 181. 148.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.78571429 0.35714286 0.53125    0.67410714 0.79464286 0.64732143\n",
      " 0.42410714 0.39732143 0.29464286 0.74107143 0.59375    0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.21428571]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.08035692807907102, -0.6660711829802322, -0.03357359191775322]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 177, 145] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.21428571] real action [  0. 174. 142.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.78571429 0.35714286 0.53125    0.67410714 0.79464286 0.64732143\n",
      " 0.42410714 0.39732143 0.29464286 0.74107143 0.59375    0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.35714286 -0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.085714068079071, -0.6901783129802322, -0.04054683616757393]\n",
      "action: [  0. 183. 144.]\n",
      "pick_success 1\n",
      "dis 6.082762530298219 pick_success 1\n",
      "desired_action : [0, 177, 145] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.35714286 -0.07142857] real action [  0. 183. 144.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.78571429  0.35714286  0.53125     0.67410714 -0.01339286  0.5\n",
      "  0.42410714  0.39732143  0.29464286  0.74107143  0.59375     0.15178571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.         -0.28571429]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [-0.07232156192092895, -0.45446415298023224, 0.02319746927917004]\n",
      "place_xyz[2] 0.02319746927917004 False\n",
      "desired_action : [1, 95, 89] phase_loss 0.0 dis_reward -0.00032\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.         -0.28571429] real action [ 1. 95. 85.]\n",
      "reward 0.99968 done:  True\n",
      "observation: [0.78571429 0.35714286 0.53125    0.67410714 0.39285714 0.38392857\n",
      " 0.42410714 0.39732143 0.29464286 0.74107143 0.59375    0.15178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.64285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.08303549807907101, -0.31517851298023225, -0.051040801987051965]\n",
      "action: [  0.  43. 143.]\n",
      "pick_success 0\n",
      "dis 9.848857801796104 pick_success 0\n",
      "desired_action : [0, 47, 152] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.64285714] real action [  0.  43. 143.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.39285714 0.41964286 0.74107143 0.4375     0.20982143 0.67857143\n",
      " 0.67857143 0.78571429 0.23214286 0.14732143 0.57589286 0.16517857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.42857143 -0.5       ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.08839263807907105, -0.3419642129802323, -0.04168206623196602]\n",
      "action: [  0.  53. 145.]\n",
      "pick_success 0\n",
      "dis 9.899494936611665 pick_success 0\n",
      "desired_action : [0, 46, 152] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.42857143 -0.5       ] real action [  0.  53. 145.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.39285714 0.41964286 0.74107143 0.4375     0.20982143 0.67857143\n",
      " 0.67857143 0.78571429 0.23214286 0.14732143 0.57589286 0.16517857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.10982119807907104, -0.32053565298023223, -0.04101965932548046]\n",
      "action: [  0.  45. 153.]\n",
      "pick_success 0\n",
      "dis 1.4142135623730951 pick_success 0\n",
      "desired_action : [0, 46, 152] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.07142857] real action [  0.  45. 153.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.39285714 0.41964286 0.74107143 0.4375     0.20982143 0.67857143\n",
      " 0.67857143 0.78571429 0.23214286 0.14732143 0.57589286 0.16517857] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.11249976807907103, -0.32857136298023226, -0.04163941910862923]\n",
      "action: [  0.  48. 154.]\n",
      "pick_success 1\n",
      "dis 2.23606797749979 pick_success 1\n",
      "desired_action : [0, 47, 152] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.14285714] real action [  0.  48. 154.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.39285714  0.41964286  0.74107143  0.4375     -0.00446429  0.49553571\n",
      "  0.67857143  0.78571429  0.23214286  0.14732143  0.57589286  0.16517857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.17946401807907103, -0.6151783529802322, 0.022388286866247657]\n",
      "place_xyz[2] 0.022388286866247657 False\n",
      "desired_action : [1, 152, 176] phase_loss 0.0 dis_reward -0.0003599999999999999\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.21428571 0.21428571] real action [  1. 155. 179.]\n",
      "reward 0.99964 done:  True\n",
      "observation: [0.39285714 0.41964286 0.74107143 0.4375     0.67410714 0.79464286\n",
      " 0.67857143 0.78571429 0.23214286 0.14732143 0.57589286 0.16517857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.14732152192092896, -0.32053565298023223, -0.03926437518000603]\n",
      "action: [ 0. 45. 57.]\n",
      "pick_success 0\n",
      "dis 6.0827625302982185 pick_success 0\n",
      "desired_action : [0, 51, 58] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857] real action [ 0. 45. 57.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.32142857 0.80357143 0.69642857 0.82589286 0.22767857 0.25892857\n",
      " 0.78125    0.16964286 0.77232143 0.48660714 0.53571429 0.25446429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.07142857 -0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.15535723192092896, -0.3392856429802322, -0.053500000000000006]\n",
      "action: [ 0. 52. 54.]\n",
      "pick_success 1\n",
      "dis 4.1231056256176535 pick_success 1\n",
      "desired_action : [0, 51, 58] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.07142857 -0.28571429] real action [ 0. 52. 54.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.32142857 0.80357143 0.69642857 0.82589286 0.         0.51785714\n",
      " 0.78125    0.16964286 0.77232143 0.48660714 0.53571429 0.25446429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.85714286 -0.64285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.22232148192092896, -0.7008925929802322, 0.03612393417954445]\n",
      "place_xyz[2] 0.03612393417954445 False\n",
      "desired_action : [1, 175, 38] phase_loss 0.0 dis_reward -0.0045\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.85714286 -0.64285714] real action [  1. 187.  29.]\n",
      "reward 0.9955 done:  True\n",
      "observation: [0.32142857 0.80357143 0.69642857 0.82589286 0.82142857 0.15625\n",
      " 0.78125    0.16964286 0.77232143 0.48660714 0.53571429 0.25446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15000009192092895, -0.3419642129802323, -0.04174341803789139]\n",
      "action: [ 0. 53. 56.]\n",
      "pick_success 0\n",
      "dis 6.4031242374328485 pick_success 0\n",
      "desired_action : [0, 48, 52] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.28571429] real action [ 0. 53. 56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.21428571 0.23214286 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16875008192092897, -0.33660707298023224, -0.053500000000000006]\n",
      "action: [ 0. 51. 49.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 48, 53] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.21428571] real action [ 0. 51. 49.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.21428571 0.23214286 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.17678579192092897, -0.3312499329802322, -0.053500000000000006]\n",
      "action: [ 0. 49. 46.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 48, 53] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.42857143] real action [ 0. 49. 46.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.21428571 0.23214286 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15803580192092895, -0.3419642129802323, -0.053500000000000006]\n",
      "action: [ 0. 53. 53.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 47, 54] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.07142857] real action [ 0. 53. 53.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.21428571 0.23214286 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16071437192092897, -0.32857136298023226, -0.053500000000000006]\n",
      "action: [ 0. 48. 52.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 46, 54] phase_loss 0.0 dis_reward 0\n",
      "action  [0. 0. 1. 0. 0. 0. 0. 0. 0.] real action [ 0. 48. 52.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.21428571 0.23214286 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16607151192092895, -0.31785708298023224, -0.053500000000000006]\n",
      "action: [ 0. 44. 50.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 45, 56] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714] real action [ 0. 44. 50.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.19642857 0.25446429 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.35714286 -0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15000009192092895, -0.3312499329802322, -0.053500000000000006]\n",
      "action: [ 0. 49. 56.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 44, 57] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.35714286 -0.07142857] real action [ 0. 49. 56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.19642857 0.25446429 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16339294192092896, -0.3258927929802322, -0.053500000000000006]\n",
      "action: [ 0. 47. 51.]\n",
      "pick_success 0\n",
      "dis 8.06225774829855 pick_success 0\n",
      "desired_action : [0, 43, 58] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.42857143] real action [ 0. 47. 51.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.19642857 0.25446429 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16339294192092896, -0.31785708298023224, -0.03956205567717552]\n",
      "action: [ 0. 44. 51.]\n",
      "pick_success 0\n",
      "dis 8.246211251235321 pick_success 0\n",
      "desired_action : [0, 42, 59] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.42857143] real action [ 0. 44. 51.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.19642857 0.25446429 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15803580192092895, -0.32857136298023226, -0.053500000000000006]\n",
      "action: [ 0. 48. 53.]\n",
      "pick_success 0\n",
      "dis 8.48528137423857 pick_success 0\n",
      "desired_action : [0, 42, 59] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.28571429] real action [ 0. 48. 53.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.53571429 0.19642857 0.25446429 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16339294192092896, -0.30178566298023224, -0.042111964732408524]\n",
      "action: [ 0. 38. 51.]\n",
      "pick_success 0\n",
      "dis 9.486832980505138 pick_success 0\n",
      "desired_action : [0, 41, 60] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.42857143] real action [ 0. 38. 51.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.19642857 0.53571429 0.19642857 0.25446429 0.60267857 0.22767857\n",
      " 0.54017857 0.56696429 0.79910714 0.51785714 0.82589286 0.78125   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15000009192092895, -0.5428569629802322, -0.053500000000000006]\n",
      "action: [  0. 128.  56.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143] real action [  0. 128.  56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.12053582192092896, -0.5482141029802322, -0.053500000000000006]\n",
      "action: [  0. 130.  67.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.35714286] real action [  0. 130.  67.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.14196438192092897, -0.5348212529802323, -0.053500000000000006]\n",
      "action: [  0. 125.  59.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.21428571] real action [  0. 125.  59.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13660724192092896, -0.5535712429802322, -0.053500000000000006]\n",
      "action: [  0. 132.  61.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [  0. 132.  61.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.14732152192092896, -0.5455355329802323, -0.053500000000000006]\n",
      "action: [  0. 129.  57.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.35714286] real action [  0. 129.  57.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.12857153192092896, -0.5535712429802322, -0.053500000000000006]\n",
      "action: [  0. 132.  64.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.14285714] real action [  0. 132.  64.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.5        0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13125010192092895, -0.5669640929802322, -0.04235912656784058]\n",
      "action: [  0. 137.  63.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.5        0.07142857] real action [  0. 137.  63.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15000009192092895, -0.5428569629802322, -0.053500000000000006]\n",
      "action: [  0. 128.  56.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143] real action [  0. 128.  56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.12589296192092897, -0.5455355329802323, -0.053500000000000006]\n",
      "action: [  0. 129.  65.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571] real action [  0. 129.  65.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13125010192092895, -0.5348212529802323, -0.053500000000000006]\n",
      "action: [  0. 125.  63.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.07142857] real action [  0. 125.  63.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15267866192092897, -0.5428569629802322, -0.053500000000000006]\n",
      "action: [  0. 128.  55.]\n",
      "pick_success 0\n",
      "dis 7.280109889280518 pick_success 0\n",
      "desired_action : [0, 130, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ] real action [  0. 128.  55.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.47767857 0.52232143 0.58035714 0.27678571 0.4375     0.79017857\n",
      " 0.20982143 0.5        0.83035714 0.55357143 0.27232143 0.15625   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.07232156192092895, -0.4973212729802322, -0.053500000000000006]\n",
      "action: [  0. 111.  85.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 108, 87] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.14285714] real action [  0. 111.  85.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.21428571 0.46875    0.30357143 0.80803571 0.48214286 0.38839286\n",
      " 0.60267857 0.125      0.62946429 0.74553571 0.82589286 0.54910714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.08035727192092895, -0.4919641329802322, -0.053500000000000006]\n",
      "action: [  0. 109.  82.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 108, 88] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.07142857 -0.35714286] real action [  0. 109.  82.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.21428571 0.46875    0.30357143 0.80803571 0.48214286 0.38839286\n",
      " 0.60267857 0.125      0.62946429 0.74553571 0.82589286 0.54910714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.5        -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.07500013192092897, -0.5080355529802323, -0.039809606805443765]\n",
      "action: [  0. 115.  84.]\n",
      "pick_success 1\n",
      "dis 8.94427190999916 pick_success 1\n",
      "desired_action : [0, 107, 88] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.5        -0.21428571] real action [  0. 115.  84.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.21428571  0.46875     0.30357143  0.80803571 -0.02232143  0.51339286\n",
      "  0.60267857  0.125       0.62946429  0.74553571  0.82589286  0.54910714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429  0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.15535688807907105, -0.5669640929802322, 0.025212484389543537]\n",
      "place_xyz[2] 0.025212484389543537 False\n",
      "desired_action : [1, 141, 167] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429  0.21428571] real action [  1. 137. 170.]\n",
      "reward 0.9995 done:  True\n",
      "observation: [0.21428571 0.46875    0.30357143 0.80803571 0.57142857 0.77678571\n",
      " 0.60267857 0.125      0.62946429 0.74553571 0.82589286 0.54910714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.07499978807907104, -0.37946419298023226, -0.053500000000000006]\n",
      "action: [  0.  67. 140.]\n",
      "pick_success 1\n",
      "dis 1.4142135623730951 pick_success 1\n",
      "desired_action : [0, 68, 139] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.07142857] real action [  0.  67. 140.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.67857143 0.37053571 0.29017857 0.35267857 0.00446429 0.49553571\n",
      " 0.70982143 0.78571429 0.47767857 0.125      0.82142857 0.55803571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.35714286  0.35714286]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [0.184821158079071, -0.6124997829802322, 0.028504484310746196]\n",
      "place_xyz[2] 0.028504484310746196 False\n",
      "desired_action : [1, 159, 176] phase_loss 0.0 dis_reward -0.001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.35714286  0.35714286] real action [  1. 154. 181.]\n",
      "reward 0.999 done:  True\n",
      "observation: [0.67857143 0.37053571 0.29017857 0.35267857 0.67857143 0.80357143\n",
      " 0.70982143 0.78571429 0.47767857 0.125      0.82142857 0.55803571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.15000009192092895, -0.3741070529802322, -0.053500000000000006]\n",
      "action: [ 0. 65. 56.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 66, 59] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571] real action [ 0. 65. 56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19642857 0.56696429 0.29464286 0.26339286 0.70982143 0.41071429\n",
      " 0.46875    0.72767857 0.4375     0.42410714 0.75       0.71875   ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.        ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.14196438192092897, -0.3901784729802322, -0.053500000000000006]\n",
      "action: [ 0. 71. 59.]\n",
      "pick_success 1\n",
      "dis 6.0 pick_success 1\n",
      "desired_action : [0, 65, 59] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.        ] real action [ 0. 71. 59.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.19642857  0.56696429 -0.02232143  0.5         0.70982143  0.41071429\n",
      "  0.46875     0.72767857  0.4375      0.42410714  0.75        0.71875   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429 -0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.12321404807907105, -0.6392854829802322, 0.02707409577071667]\n",
      "place_xyz[2] 0.02707409577071667 False\n",
      "desired_action : [1, 168, 161] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429 -0.21428571] real action [  1. 164. 158.]\n",
      "reward 0.9995 done:  True\n",
      "observation: [0.19642857 0.56696429 0.69642857 0.71428571 0.70982143 0.41071429\n",
      " 0.46875    0.72767857 0.4375     0.42410714 0.75       0.71875   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.053571228079071054, -0.43035702298023226, -0.042350506246089936]\n",
      "action: [  0.  86. 132.]\n",
      "pick_success 1\n",
      "dis 2.8284271247461903 pick_success 1\n",
      "desired_action : [0, 84, 130] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.14285714] real action [  0.  86. 132.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.44642857 0.29464286 0.         0.48660714 0.70089286 0.76339286\n",
      " 0.74553571 0.16071429 0.20535714 0.72767857 0.78125    0.46875   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.85714286 0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.19821435192092896, -0.6794640329802322, 0.01676150828227401]\n",
      "place_xyz[2] 0.01676150828227401 False\n",
      "desired_action : [1, 167, 36] phase_loss 0.0 dis_reward -0.0029599999999999995\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.85714286 0.14285714] real action [  1. 179.  38.]\n",
      "reward 0.99704 done:  True\n",
      "observation: [0.44642857 0.29464286 0.78571429 0.16071429 0.70089286 0.76339286\n",
      " 0.74553571 0.16071429 0.20535714 0.72767857 0.78125    0.46875   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.17678579192092897, -0.5830355129802323, -0.03884921579062939]\n",
      "action: [  0. 143.  46.]\n",
      "pick_success 1\n",
      "dis 2.8284271247461903 pick_success 1\n",
      "desired_action : [0, 145, 48] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.14285714] real action [  0. 143.  46.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.20535714 0.74107143 0.70089286 0.57142857 0.02232143 0.50446429\n",
      " 0.48214286 0.70535714 0.29910714 0.42410714 0.34375    0.13839286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.35714286 0.        ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.12321404807907105, -0.5026784129802322, 0.023244619347155097]\n",
      "place_xyz[2] 0.023244619347155097 False\n",
      "desired_action : [1, 108, 158] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.35714286 0.        ] real action [  1. 113. 158.]\n",
      "reward 0.9995 done:  True\n",
      "observation: [0.20535714 0.74107143 0.70089286 0.57142857 0.50892857 0.71875\n",
      " 0.48214286 0.70535714 0.29910714 0.42410714 0.34375    0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.13124975807907102, -0.37142848298023223, -0.053500000000000006]\n",
      "action: [  0.  64. 161.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 64, 156] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.35714286] real action [  0.  64. 161.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.69642857 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.11249976807907103, -0.35535706298023223, -0.053500000000000006]\n",
      "action: [  0.  58. 154.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 64, 156] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.14285714] real action [  0.  58. 154.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.69642857 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.10982119807907104, -0.3741070529802322, -0.053500000000000006]\n",
      "action: [  0.  65. 153.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 64, 157] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571] real action [  0.  65. 153.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.69642857 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.13124975807907102, -0.37142848298023223, -0.053500000000000006]\n",
      "action: [  0.  64. 161.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 65, 157] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.35714286] real action [  0.  64. 161.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.69642857 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.57142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.09642834807907102, -0.3633927729802322, -0.040652885869145394]\n",
      "action: [  0.  61. 148.]\n",
      "pick_success 0\n",
      "dis 9.848857801796104 pick_success 0\n",
      "desired_action : [0, 65, 157] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.57142857] real action [  0.  61. 148.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.69642857 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.10714262807907105, -0.38749990298023224, -0.053500000000000006]\n",
      "action: [  0.  70. 152.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 65, 157] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.28571429] real action [  0.  70. 152.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.69642857 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.12053547807907106, -0.3741070529802322, -0.053500000000000006]\n",
      "action: [  0.  65. 157.]\n",
      "pick_success 0\n",
      "dis 0.0 pick_success 0\n",
      "desired_action : [0, 65, 157] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.07142857] real action [  0.  65. 157.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.69642857 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.5       ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.136606898079071, -0.36071420298023227, -0.03983943893015385]\n",
      "action: [  0.  60. 163.]\n",
      "pick_success 1\n",
      "dis 7.810249675906654 pick_success 1\n",
      "desired_action : [0, 65, 157] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.5       ] real action [  0.  60. 163.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.03125    0.47321429 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.14285714 0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.09375012192092896, -0.6526783329802321, 0.020059491485357288]\n",
      "place_xyz[2] 0.020059491485357288 False\n",
      "desired_action : [1, 167, 72] phase_loss 0.0 dis_reward -0.0005799999999999999\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.14285714 0.35714286] real action [  1. 169.  77.]\n",
      "reward 0.99942 done:  True\n",
      "observation: [0.77232143 0.31696429 0.43303571 0.25       0.52232143 0.51785714\n",
      " 0.79910714 0.69642857 0.74553571 0.32142857 0.20089286 0.32589286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.07767870192092896, -0.5214284029802323, -0.043059967294335366]\n",
      "action: [  0. 120.  83.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 119, 80] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.21428571] real action [  0. 120.  83.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.30803571 0.20535714 0.00892857 0.48214286 0.31696429 0.58035714\n",
      " 0.81696429 0.59821429 0.53125    0.72767857 0.80803571 0.28571429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.64285714 0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.14732117807907102, -0.5428569629802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 119, 163] phase_loss 0.0 dis_reward -0.0019399999999999999\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.64285714 0.28571429] real action [  1. 128. 167.]\n",
      "reward 0.99806 done:  True\n",
      "observation: [0.30803571 0.20535714 0.5625     0.73660714 0.31696429 0.58035714\n",
      " 0.81696429 0.59821429 0.53125    0.72767857 0.80803571 0.28571429] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.42857143]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.03482123807907106, -0.4249998829802322, -0.03963591141998768]\n",
      "action: [  0.  84. 125.]\n",
      "pick_success 1\n",
      "dis 6.082762530298219 pick_success 1\n",
      "desired_action : [0, 83, 119] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.42857143] real action [  0.  84. 125.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.6875     0.32589286 0.00892857 0.46875    0.47767857 0.77678571\n",
      " 0.74107143 0.59821429 0.375      0.16071429 0.16964286 0.71428571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.14285714  0.5       ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.14732117807907102, -0.29642852298023226, 0.023436189606785778]\n",
      "place_xyz[2] 0.023436189606785778 False\n",
      "desired_action : [1, 38, 160] phase_loss 0.0 dis_reward -0.00106\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.14285714  0.5       ] real action [  1.  36. 167.]\n",
      "reward 0.99894 done:  True\n",
      "observation: [0.6875     0.32589286 0.15178571 0.72321429 0.47767857 0.77678571\n",
      " 0.74107143 0.59821429 0.375      0.16071429 0.16964286 0.71428571] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.17142865192092896, -0.6446426229802322, -0.04199607840180397]\n",
      "action: [  0. 166.  48.]\n",
      "pick_success 1\n",
      "dis 3.605551275463989 pick_success 1\n",
      "desired_action : [0, 163, 50] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714] real action [  0. 166.  48.]\n",
      "reward 0.0 done:  False\n",
      "observation: [-0.00446429  0.5         0.42857143  0.76785714  0.83035714  0.60714286\n",
      "  0.46875     0.23214286  0.18303571  0.28571429  0.57589286  0.50892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.         -0.71428571]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [-0.18750007192092896, -0.4812498529802322, 0.024568017549812797]\n",
      "place_xyz[2] 0.024568017549812797 False\n",
      "desired_action : [1, 105, 52] phase_loss 0.0 dis_reward -0.0020000000000000005\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.         -0.71428571] real action [  1. 105.  42.]\n",
      "reward 0.998 done:  True\n",
      "observation: [0.45089286 0.19642857 0.42857143 0.76785714 0.83035714 0.60714286\n",
      " 0.46875    0.23214286 0.18303571 0.28571429 0.57589286 0.50892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.02946409807907102, -0.6499997629802322, -0.036264525562524796]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 167, 128] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286] real action [  0. 168. 123.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.74553571 0.57142857 0.61607143 0.32589286 0.38839286 0.74107143\n",
      " 0.25446429 0.16071429 0.18303571 0.54910714 0.38839286 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.03482123807907106, -0.6446426229802322, -0.03982534429430962]\n",
      "action: [  0. 166. 125.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 167, 128] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571] real action [  0. 166. 125.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.01785714 0.50892857 0.61607143 0.32589286 0.38839286 0.74107143\n",
      " 0.25446429 0.16071429 0.18303571 0.54910714 0.38839286 0.39285714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.57142857  0.        ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.02946409807907102, -0.2883928129802322, 0.020415578015148643]\n",
      "place_xyz[2] 0.020415578015148643 False\n",
      "desired_action : [1, 41, 123] phase_loss 0.0 dis_reward -0.00128\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.57142857  0.        ] real action [  1.  33. 123.]\n",
      "reward 0.99872 done:  True\n",
      "observation: [0.14732143 0.56696429 0.61607143 0.32589286 0.38839286 0.74107143\n",
      " 0.25446429 0.16071429 0.18303571 0.54910714 0.38839286 0.39285714] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.09642869192092896, -0.6312497729802322, -0.03756231425702572]\n",
      "action: [  0. 161.  76.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 160, 79] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571] real action [  0. 161.  76.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.00892857 0.50892857 0.72321429 0.73214286 0.41964286 0.70535714\n",
      " 0.38392857 0.39285714 0.50892857 0.15178571 0.19642857 0.77232143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.         0.57142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [-0.042857291920928964, -0.43035702298023226, 0.022944292031228546]\n",
      "place_xyz[2] 0.022944292031228546 False\n",
      "desired_action : [1, 86, 88] phase_loss 0.0 dis_reward -0.00128\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.         0.57142857] real action [ 1. 86. 96.]\n",
      "reward 0.99872 done:  True\n",
      "observation: [0.37946429 0.44642857 0.72321429 0.73214286 0.41964286 0.70535714\n",
      " 0.38392857 0.39285714 0.50892857 0.15178571 0.19642857 0.77232143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.42857143]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.03750015192092898, -0.6821426029802322, -0.03542389890551567]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 178, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.42857143] real action [  0. 180.  98.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.55357143 0.61607143 0.22321429 0.80357143 0.79464286 0.41071429\n",
      " 0.45535714 0.28571429 0.1875     0.13839286 0.18303571 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.14285714]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.05892871192092897, -0.6687497529802322, -0.03487443535029888]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 178, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.14285714] real action [  0. 175.  90.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.55357143 0.61607143 0.22321429 0.80357143 0.79464286 0.41071429\n",
      " 0.45535714 0.28571429 0.1875     0.13839286 0.18303571 0.39285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.42857143]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.06964299192092896, -0.6821426029802322, -0.037678556352853776]\n",
      "action: [  0. 180.  86.]\n",
      "pick_success 1\n",
      "dis 6.324555320336759 pick_success 1\n",
      "desired_action : [0, 178, 92] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.42857143] real action [  0. 180.  86.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.55357143 0.61607143 0.22321429 0.80357143 0.00446429 0.52232143\n",
      " 0.45535714 0.28571429 0.1875     0.13839286 0.18303571 0.39285714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.         -0.57142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.08571441192092896, -0.30982137298023227, 0.02122296763211489]\n",
      "place_xyz[2] 0.02122296763211489 False\n",
      "desired_action : [1, 41, 88] phase_loss 0.0 dis_reward -0.00128\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.         -0.57142857] real action [ 1. 41. 80.]\n",
      "reward 0.99872 done:  True\n",
      "observation: [0.55357143 0.61607143 0.22321429 0.80357143 0.17410714 0.38392857\n",
      " 0.45535714 0.28571429 0.1875     0.13839286 0.18303571 0.39285714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.03214301192092894, -0.3258927929802322, -0.03988305462896824]\n",
      "action: [  0.  47. 100.]\n",
      "pick_success 1\n",
      "dis 4.242640687119285 pick_success 1\n",
      "desired_action : [0, 50, 103] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.21428571] real action [  0.  47. 100.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.66517857 0.58928571 0.02232143 0.51339286 0.54910714 0.22321429\n",
      " 0.80357143 0.32589286 0.57142857 0.78571429 0.30803571 0.74107143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429 -0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.16607116807907102, -0.5321426829802323, 0.02164129910618067]\n",
      "place_xyz[2] 0.02164129910618067 False\n",
      "desired_action : [1, 128, 176] phase_loss 0.0 dis_reward -0.0004\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429 -0.14285714] real action [  1. 124. 174.]\n",
      "reward 0.9996 done:  True\n",
      "observation: [0.66517857 0.58928571 0.56696429 0.79910714 0.54910714 0.22321429\n",
      " 0.80357143 0.32589286 0.57142857 0.78571429 0.30803571 0.74107143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.28571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.04017872192092897, -0.3232142229802322, -0.053500000000000006]\n",
      "action: [ 0. 46. 97.]\n",
      "pick_success 0\n",
      "dis 6.4031242374328485 pick_success 0\n",
      "desired_action : [0, 41, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.28571429] real action [ 0. 46. 97.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.77232143 0.18303571 0.41517857 0.57142857 0.79017857\n",
      " 0.67857143 0.33035714 0.79910714 0.63392857 0.40178571 0.20982143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.06696442192092897, -0.30446423298023223, -0.04148319347202778]\n",
      "action: [ 0. 39. 87.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 41, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.42857143] real action [ 0. 39. 87.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.77232143 0.18303571 0.41517857 0.57142857 0.79017857\n",
      " 0.67857143 0.33035714 0.79910714 0.63392857 0.40178571 0.20982143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.05892871192092897, -0.30446423298023223, -0.039561739027500153]\n",
      "action: [ 0. 39. 90.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 41, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.21428571] real action [ 0. 39. 90.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.77232143 0.18303571 0.41517857 0.57142857 0.79017857\n",
      " 0.67857143 0.33035714 0.79910714 0.63392857 0.40178571 0.20982143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.28571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.04017872192092897, -0.3258927929802322, -0.040769817143678666]\n",
      "action: [ 0. 47. 97.]\n",
      "pick_success 0\n",
      "dis 7.810249675906654 pick_success 0\n",
      "desired_action : [0, 41, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.28571429] real action [ 0. 47. 97.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.77232143 0.18303571 0.41517857 0.57142857 0.79017857\n",
      " 0.67857143 0.33035714 0.79910714 0.63392857 0.40178571 0.20982143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.042857291920928964, -0.3232142229802322, -0.053500000000000006]\n",
      "action: [ 0. 46. 96.]\n",
      "pick_success 0\n",
      "dis 6.4031242374328485 pick_success 0\n",
      "desired_action : [0, 41, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.21428571] real action [ 0. 46. 96.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.77232143 0.18303571 0.41517857 0.57142857 0.79017857\n",
      " 0.67857143 0.33035714 0.79910714 0.63392857 0.40178571 0.20982143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.06964299192092896, -0.30446423298023223, -0.037449825391173364]\n",
      "action: [ 0. 39. 86.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 40, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ] real action [ 0. 39. 86.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.28571429 0.77232143 0.18303571 0.41517857 0.57142857 0.79017857\n",
      " 0.67857143 0.33035714 0.79910714 0.63392857 0.40178571 0.20982143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.053571571920928956, -0.30178566298023224, -0.04058318196237087]\n",
      "action: [ 0. 38. 92.]\n",
      "pick_success 1\n",
      "dis 2.0 pick_success 1\n",
      "desired_action : [0, 40, 92] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857] real action [ 0. 38. 92.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.28571429 0.77232143 0.01339286 0.5        0.57142857 0.79017857\n",
      " 0.67857143 0.33035714 0.79910714 0.63392857 0.40178571 0.20982143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.14285714 -0.57142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.19553578192092896, -0.4464284429802322, 0.022638770729303363]\n",
      "place_xyz[2] 0.022638770729303363 False\n",
      "desired_action : [1, 90, 47] phase_loss 0.0 dis_reward -0.0013599999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.14285714 -0.57142857] real action [ 1. 92. 39.]\n",
      "reward 0.99864 done:  True\n",
      "observation: [0.28571429 0.77232143 0.41071429 0.18303571 0.57142857 0.79017857\n",
      " 0.67857143 0.33035714 0.79910714 0.63392857 0.40178571 0.20982143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.42857143]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.06428585192092895, -0.3741070529802322, -0.04232332094013691]\n",
      "action: [ 0. 65. 88.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 68, 82] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.42857143] real action [ 0. 65. 88.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.64285714 0.75892857 0.30357143 0.36607143 0.75892857 0.40625\n",
      " 0.53571429 0.21875    0.44196429 0.5625     0.1875     0.72321429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.06964299192092896, -0.37946419298023226, -0.04016227258741856]\n",
      "action: [ 0. 67. 86.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 68, 82] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.28571429] real action [ 0. 67. 86.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.64285714 0.75892857 0.30357143 0.36607143 0.75892857 0.40625\n",
      " 0.53571429 0.21875    0.44196429 0.5625     0.1875     0.72321429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.08303584192092897, -0.36071420298023227, -0.0388634724766016]\n",
      "action: [ 0. 60. 81.]\n",
      "pick_success 0\n",
      "dis 8.06225774829855 pick_success 0\n",
      "desired_action : [0, 68, 82] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.07142857] real action [ 0. 60. 81.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.64285714 0.75892857 0.30357143 0.36607143 0.75892857 0.40625\n",
      " 0.53571429 0.21875    0.44196429 0.5625     0.1875     0.72321429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.06964299192092896, -0.37946419298023226, -0.053500000000000006]\n",
      "action: [ 0. 67. 86.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 68, 82] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.28571429] real action [ 0. 67. 86.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.64285714 0.75892857 0.30357143 0.36607143 0.75892857 0.40625\n",
      " 0.53571429 0.21875    0.44196429 0.5625     0.1875     0.72321429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.42857143 -0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.09107155192092897, -0.39821418298023226, -0.03952904587984085]\n",
      "action: [ 0. 74. 78.]\n",
      "pick_success 1\n",
      "dis 8.602325267042627 pick_success 1\n",
      "desired_action : [0, 67, 83] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.42857143 -0.28571429] real action [ 0. 74. 78.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.64285714  0.75892857 -0.01785714  0.51785714  0.75892857  0.40625\n",
      "  0.53571429  0.21875     0.44196429  0.5625      0.1875      0.72321429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.21428571 -0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.17142865192092896, -0.5294641129802322, 0.023427775107324127]\n",
      "place_xyz[2] 0.023427775107324127 False\n",
      "desired_action : [1, 120, 49] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.21428571 -0.07142857] real action [  1. 123.  48.]\n",
      "reward 0.9998 done:  True\n",
      "observation: [0.64285714 0.75892857 0.51339286 0.24107143 0.75892857 0.40625\n",
      " 0.53571429 0.21875    0.44196429 0.5625     0.1875     0.72321429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.14285714]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.0053573119209289755, -0.5241069729802322, -0.03802513314783573]\n",
      "action: [  0. 121. 110.]\n",
      "pick_success 1\n",
      "dis 2.0 pick_success 1\n",
      "desired_action : [0, 121, 112] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.14285714] real action [  0. 121. 110.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.21428571 0.33035714 0.37946429 0.75892857 0.00892857 0.50446429\n",
      " 0.63839286 0.16517857 0.17410714 0.54910714 0.82589286 0.67857143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.57142857  0.07142857]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping: place [0.03214266807907101, -0.28303567298023224, 0.020721014566719535]\n",
      "place_xyz[2] 0.020721014566719535 False\n",
      "desired_action : [1, 39, 123] phase_loss 0.0 dis_reward -0.0013000000000000008\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.57142857  0.07142857] real action [  1.  31. 124.]\n",
      "reward 0.9987 done:  True\n",
      "observation: [0.21428571 0.33035714 0.37946429 0.75892857 0.13392857 0.5625\n",
      " 0.63839286 0.16517857 0.17410714 0.54910714 0.82589286 0.67857143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.14285714]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.10446440192092896, -0.6017855029802321, -0.04023617862164974]\n",
      "action: [  0. 150.  73.]\n",
      "pick_success 1\n",
      "dis 2.23606797749979 pick_success 1\n",
      "desired_action : [0, 149, 71] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.14285714] real action [  0. 150.  73.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.00446429 0.48660714 0.5625     0.83035714 0.32589286 0.68303571\n",
      " 0.37946429 0.27232143 0.57589286 0.51785714 0.81696429 0.76339286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.57142857 0.        ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.15803545807907105, -0.7116068729802322, 0.025704667881131175]\n",
      "place_xyz[2] 0.025704667881131175 False\n",
      "desired_action : [1, 183, 171] phase_loss 0.0 dis_reward -0.00128\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.57142857 0.        ] real action [  1. 191. 171.]\n",
      "reward 0.99872 done:  True\n",
      "observation: [0.84375    0.75892857 0.5625     0.83035714 0.32589286 0.68303571\n",
      " 0.37946429 0.27232143 0.57589286 0.51785714 0.81696429 0.76339286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.57142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.20357149192092897, -0.5562498129802322, -0.04050493223965168]\n",
      "action: [  0. 133.  36.]\n",
      "pick_success 1\n",
      "dis 8.246211251235321 pick_success 1\n",
      "desired_action : [0, 135, 44] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.57142857] real action [  0. 133.  36.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.02232143 0.52678571 0.64285714 0.59821429 0.44196429 0.42410714\n",
      " 0.26785714 0.62053571 0.83035714 0.36160714 0.24553571 0.21875   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.14285714 -0.64285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.048214088079071016, -0.36607134298023225, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 60, 139] phase_loss 0.0 dis_reward -0.0017000000000000001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.14285714 -0.64285714] real action [  1.  62. 130.]\n",
      "reward 0.9983 done:  True\n",
      "observation: [0.28571429 0.61607143 0.64285714 0.59821429 0.44196429 0.42410714\n",
      " 0.26785714 0.62053571 0.83035714 0.36160714 0.24553571 0.21875   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.07142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.05089265807907101, -0.6499997629802322, -0.0400424057841301]\n",
      "action: [  0. 168. 131.]\n",
      "pick_success 1\n",
      "dis 4.123105625617661 pick_success 1\n",
      "desired_action : [0, 172, 130] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.07142857] real action [  0. 168. 131.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.69196429 0.18303571 0.03125    0.48660714 0.17857143 0.80803571\n",
      " 0.41071429 0.47321429 0.30803571 0.23214286 0.58482143 0.72767857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.28571429 0.        ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.136606898079071, -0.5616069529802322, 0.025255362480878833]\n",
      "place_xyz[2] 0.025255362480878833 False\n",
      "desired_action : [1, 131, 163] phase_loss 0.0 dis_reward -0.00032\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.28571429 0.        ] real action [  1. 135. 163.]\n",
      "reward 0.99968 done:  True\n",
      "observation: [0.69196429 0.18303571 0.61607143 0.72321429 0.17857143 0.80803571\n",
      " 0.41071429 0.47321429 0.30803571 0.23214286 0.58482143 0.72767857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.35714286]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.03482123807907106, -0.34732135298023226, -0.04303644394874573]\n",
      "action: [  0.  55. 125.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 53, 120] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.35714286] real action [  0.  55. 125.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53125    0.54017857 0.74553571 0.39732143 0.23660714 0.53571429\n",
      " 0.28125    0.77232143 0.20535714 0.22321429 0.67857143 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.42857143]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.03749980807907105, -0.34732135298023226, -0.03984106129407883]\n",
      "action: [  0.  55. 126.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 53, 121] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.42857143] real action [  0.  55. 126.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53125    0.54017857 0.74553571 0.39732143 0.23660714 0.53571429\n",
      " 0.28125    0.77232143 0.20535714 0.22321429 0.67857143 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.02946409807907102, -0.32857136298023226, -0.04235945066809654]\n",
      "action: [  0.  48. 123.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 53, 121] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.21428571] real action [  0.  48. 123.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53125    0.54017857 0.74553571 0.39732143 0.23660714 0.53571429\n",
      " 0.28125    0.77232143 0.20535714 0.22321429 0.67857143 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.02678552807907103, -0.3258927929802322, -0.041941569954156876]\n",
      "action: [  0.  47. 122.]\n",
      "pick_success 1\n",
      "dis 6.082762530298219 pick_success 1\n",
      "desired_action : [0, 53, 121] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.14285714] real action [  0.  47. 122.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.53125    0.54017857 0.74553571 0.39732143 0.02678571 0.49553571\n",
      " 0.28125    0.77232143 0.20535714 0.22321429 0.67857143 0.70089286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.168749738079071, -0.36607134298023225, 0.022517620563507083]\n",
      "place_xyz[2] 0.022517620563507083 False\n",
      "desired_action : [1, 63, 173] phase_loss 0.0 dis_reward -0.0001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  1.  62. 175.]\n",
      "reward 0.9999 done:  True\n",
      "observation: [0.53125    0.54017857 0.74553571 0.39732143 0.29464286 0.77678571\n",
      " 0.28125    0.77232143 0.20535714 0.22321429 0.67857143 0.70089286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.10982119807907104, -0.5508926729802321, -0.053500000000000006]\n",
      "action: [  0. 131. 153.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 132, 148] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.35714286] real action [  0. 131. 153.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.17410714 0.16964286 0.6875     0.32589286 0.58928571 0.66071429\n",
      " 0.17410714 0.76785714 0.43303571 0.14732143 0.23214286 0.42410714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.28571429]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.10714262807907105, -0.5482141029802322, -0.053500000000000006]\n",
      "action: [  0. 130. 152.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 131, 148] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.28571429] real action [  0. 130. 152.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.17410714 0.16964286 0.6875     0.32589286 0.58928571 0.66071429\n",
      " 0.17410714 0.76785714 0.43303571 0.14732143 0.23214286 0.42410714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.07142857]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.09910691807907102, -0.5482141029802322, -0.03987219913303852]\n",
      "action: [  0. 130. 149.]\n",
      "pick_success 1\n",
      "dis 1.0 pick_success 1\n",
      "desired_action : [0, 130, 148] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.07142857] real action [  0. 130. 149.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.17410714 0.16964286 0.6875     0.32589286 0.01339286 0.49107143\n",
      " 0.17410714 0.76785714 0.43303571 0.14732143 0.23214286 0.42410714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.14285714 0.5       ]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping: place [-0.02678587192092896, -0.3446427829802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 52, 95] phase_loss 0.0 dis_reward -0.00106\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.14285714 0.5       ] real action [  1.  54. 102.]\n",
      "reward 0.99894 done:  True\n",
      "observation: [0.17410714 0.16964286 0.6875     0.32589286 0.24107143 0.45089286\n",
      " 0.17410714 0.76785714 0.43303571 0.14732143 0.23214286 0.42410714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.07142857]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.09910726192092897, -0.4785712829802322, -0.03807518056035042]\n",
      "action: [  0. 104.  75.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 107, 74] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.07142857] real action [  0. 104.  75.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.50892857 0.8125     0.02678571 0.48660714 0.75892857 0.19196429\n",
      " 0.79910714 0.63839286 0.28571429 0.53571429 0.21875    0.25446429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.5         0.35714286]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.03482123807907106, -0.35267849298023224, 0.02001315632462502]\n",
      "place_xyz[2] 0.02001315632462502 False\n",
      "desired_action : [1, 64, 120] phase_loss 0.0 dis_reward -0.00148\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.5         0.35714286] real action [  1.  57. 125.]\n",
      "reward 0.99852 done:  True\n",
      "observation: [0.50892857 0.8125     0.26339286 0.55357143 0.75892857 0.19196429\n",
      " 0.79910714 0.63839286 0.28571429 0.53571429 0.21875    0.25446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.15535688807907105, -0.4142856029802322, -0.04254789634048939]\n",
      "action: [  0.  80. 170.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 77, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.07142857] real action [  0.  80. 170.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38392857 0.38839286 0.66964286 0.70982143 0.34375    0.75446429\n",
      " 0.61607143 0.13839286 0.17410714 0.19642857 0.79464286 0.37946429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.5       ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.133928328079071, -0.39821418298023226, -0.044171564117074014]\n",
      "action: [  0.  74. 162.]\n",
      "pick_success 1\n",
      "dis 7.615773105863909 pick_success 1\n",
      "desired_action : [0, 77, 169] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.5       ] real action [  0.  74. 162.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.38392857 0.38839286 0.66964286 0.70982143 0.01785714 0.52678571\n",
      " 0.61607143 0.13839286 0.17410714 0.19642857 0.79464286 0.37946429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857 -0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.21964291192092894, -0.5669640929802322, 0.023861813336610797]\n",
      "place_xyz[2] 0.023861813336610797 False\n",
      "desired_action : [1, 138, 31] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857 -0.07142857] real action [  1. 137.  30.]\n",
      "reward 0.99996 done:  True\n",
      "observation: [0.38392857 0.38839286 0.66964286 0.70982143 0.61607143 0.16517857\n",
      " 0.61607143 0.13839286 0.17410714 0.19642857 0.79464286 0.37946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.02410730192092897, -0.4437498729802322, -0.039865748792886735]\n",
      "action: [  0.  91. 103.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 89, 105] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.14285714] real action [  0.  91. 103.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.60714286 0.50892857 0.79017857 0.39732143 0.46875\n",
      " 0.8125     0.29017857 0.22321429 0.20982143 0.78571429 0.59821429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.029464441920928952, -0.4249998829802322, -0.04088336026668549]\n",
      "action: [  0.  84. 101.]\n",
      "pick_success 1\n",
      "dis 6.4031242374328485 pick_success 1\n",
      "desired_action : [0, 89, 105] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.28571429] real action [  0.  84. 101.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.1875     0.60714286 0.50892857 0.79017857 0.03125    0.51339286\n",
      " 0.8125     0.29017857 0.22321429 0.20982143 0.78571429 0.59821429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.28571429 -0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.18482150192092894, -0.3446427829802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 50, 47] phase_loss 0.0 dis_reward -0.00064\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.28571429 -0.28571429] real action [ 1. 54. 43.]\n",
      "reward 0.99936 done:  True\n",
      "observation: [0.1875     0.60714286 0.50892857 0.79017857 0.25446429 0.21428571\n",
      " 0.8125     0.29017857 0.22321429 0.20982143 0.78571429 0.59821429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.5         0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.16339259807907103, -0.29642852298023226, -0.039270125165581704]\n",
      "action: [  0.  36. 173.]\n",
      "pick_success 0\n",
      "dis 7.615773105863909 pick_success 0\n",
      "desired_action : [0, 43, 170] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.5         0.21428571] real action [  0.  36. 173.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19196429 0.75892857 0.47321429 0.80803571 0.26339286 0.30357143\n",
      " 0.6875     0.35714286 0.78571429 0.74107143 0.45535714 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.5        0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.16071402807907104, -0.33392850298023224, -0.039793304935097695]\n",
      "action: [  0.  50. 172.]\n",
      "pick_success 0\n",
      "dis 7.280109889280518 pick_success 0\n",
      "desired_action : [0, 43, 170] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.5        0.14285714] real action [  0.  50. 172.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19196429 0.75892857 0.47321429 0.80803571 0.26339286 0.30357143\n",
      " 0.6875     0.35714286 0.78571429 0.74107143 0.45535714 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.16071402807907104, -0.30178566298023224, -0.04009970261156559]\n",
      "action: [  0.  38. 172.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 43, 171] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.14285714] real action [  0.  38. 172.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19196429 0.75892857 0.47321429 0.80803571 0.26339286 0.30357143\n",
      " 0.6875     0.35714286 0.78571429 0.74107143 0.45535714 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.16071402807907104, -0.3124999429802322, -0.042565172374248506]\n",
      "action: [  0.  42. 172.]\n",
      "pick_success 0\n",
      "dis 1.4142135623730951 pick_success 0\n",
      "desired_action : [0, 43, 171] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  0.  42. 172.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.19196429 0.75892857 0.47321429 0.80803571 0.26339286 0.30357143\n",
      " 0.6875     0.35714286 0.78571429 0.74107143 0.45535714 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.16071402807907104, -0.3071428029802322, -0.037828847602009774]\n",
      "action: [  0.  40. 172.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 43, 171] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.14285714] real action [  0.  40. 172.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.02232143 0.49553571 0.47321429 0.80803571 0.26339286 0.30357143\n",
      " 0.6875     0.35714286 0.78571429 0.74107143 0.45535714 0.51785714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.42857143  0.57142857]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.16607116807907102, -0.6553569029802322, 0.023199169874191287]\n",
      "place_xyz[2] 0.023199169874191287 False\n",
      "desired_action : [1, 176, 166] phase_loss 0.0 dis_reward -0.0020000000000000005\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.42857143  0.57142857] real action [  1. 170. 174.]\n",
      "reward 0.998 done:  True\n",
      "observation: [0.76785714 0.77232143 0.47321429 0.80803571 0.26339286 0.30357143\n",
      " 0.6875     0.35714286 0.78571429 0.74107143 0.45535714 0.51785714] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.11250011192092896, -0.4973212729802322, -0.036407889634370805]\n",
      "pick_success 0\n",
      "dis 8.94427190999916 pick_success 0\n",
      "desired_action : [0, 119, 74] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.28571429] real action [  0. 111.  70.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.20089286 0.59375    0.53125    0.33035714 0.53571429 0.67410714\n",
      " 0.78125    0.16071429 0.25892857 0.23660714 0.82142857 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.10714297192092898, -0.5267855429802322, -0.042938677430152894]\n",
      "action: [  0. 122.  72.]\n",
      "pick_success 1\n",
      "dis 3.605551275463989 pick_success 1\n",
      "desired_action : [0, 119, 74] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714] real action [  0. 122.  72.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.20089286  0.59375    -0.00446429  0.50446429  0.53571429  0.67410714\n",
      "  0.78125     0.16071429  0.25892857  0.23660714  0.82142857  0.73660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.21428571 0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.14732152192092896, -0.3633927729802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 58, 53] phase_loss 0.0 dis_reward -0.0005000000000000009\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.21428571 0.28571429] real action [ 1. 61. 57.]\n",
      "reward 0.9994999999999999 done:  True\n",
      "observation: [0.20089286 0.59375    0.25446429 0.26339286 0.53571429 0.67410714\n",
      " 0.78125    0.16071429 0.25892857 0.23660714 0.82142857 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.35714286 -0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.6607140429802323, -0.035893400967121125]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 167, 186] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.35714286 -0.21428571] real action [  0. 172. 183.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.61607143 0.29017857 0.45535714 0.61160714 0.74553571 0.83035714\n",
      " 0.17410714 0.46875    0.8125     0.49553571 0.34375    0.15178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.35714286]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.21160685807907098, -0.6446426229802322, -0.03875378689169884]\n",
      "action: [  0. 166. 191.]\n",
      "pick_success 1\n",
      "dis 5.0990195135927845 pick_success 1\n",
      "desired_action : [0, 167, 186] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.35714286] real action [  0. 166. 191.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.61607143 0.29017857 0.45535714 0.61160714 0.01785714 0.47321429\n",
      " 0.17410714 0.46875    0.8125     0.49553571 0.34375    0.15178571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.57142857 0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.010714451920928958, -0.3258927929802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 39, 105] phase_loss 0.0 dis_reward -0.0014599999999999995\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.57142857 0.21428571] real action [  1.  47. 108.]\n",
      "reward 0.99854 done:  True\n",
      "observation: [0.61607143 0.29017857 0.45535714 0.61160714 0.21428571 0.45982143\n",
      " 0.17410714 0.46875    0.8125     0.49553571 0.34375    0.15178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.        ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.17410687807907105, -0.5214284029802323, -0.04081094062328339]\n",
      "action: [  0. 120. 177.]\n",
      "pick_success 1\n",
      "dis 3.0 pick_success 1\n",
      "desired_action : [0, 117, 177] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.        ] real action [  0. 120. 177.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.47321429 0.21428571 0.46428571 0.49553571 0.         0.5\n",
      " 0.79910714 0.71875    0.19642857 0.3125     0.25892857 0.67410714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.78571429 -0.35714286]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.09107120807907104, -0.3258927929802322, 0.022842684738337997]\n",
      "place_xyz[2] 0.022842684738337997 False\n",
      "desired_action : [1, 58, 151] phase_loss 0.0 dis_reward -0.002919999999999997\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.78571429 -0.35714286] real action [  1.  47. 146.]\n",
      "reward 0.99708 done:  True\n",
      "observation: [0.47321429 0.21428571 0.46428571 0.49553571 0.19196429 0.65178571\n",
      " 0.79910714 0.71875    0.19642857 0.3125     0.25892857 0.67410714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.07142857]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.11250011192092896, -0.6017855029802321, -0.03576100042462349]\n",
      "pick_success 0\n",
      "dis 1.4142135623730951 pick_success 0\n",
      "desired_action : [0, 151, 71] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.07142857] real action [  0. 150.  70.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.5       ]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.12857153192092896, -0.6071426429802322, -0.053500000000000006]\n",
      "action: [  0. 152.  64.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 151, 71] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.5       ] real action [  0. 152.  64.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.42857143]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.12589296192092897, -0.6098212129802323, -0.053500000000000006]\n",
      "action: [  0. 153.  65.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 151, 71] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.42857143] real action [  0. 153.  65.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.07142857]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.10714297192092898, -0.6071426429802322, -0.03576307727396488]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 150, 72] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.07142857] real action [  0. 152.  72.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.28571429]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.12053582192092896, -0.6151783529802322, -0.053500000000000006]\n",
      "action: [  0. 155.  67.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 150, 72] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.28571429] real action [  0. 155.  67.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.28571429]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.12053582192092896, -0.6044640729802322, -0.053500000000000006]\n",
      "action: [  0. 151.  67.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 150, 72] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.28571429] real action [  0. 151.  67.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.42857143]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.12589296192092897, -0.6017855029802321, -0.04619637301564217]\n",
      "action: [  0. 150.  65.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 149, 72] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.42857143] real action [  0. 150.  65.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.07142857]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.11250011192092896, -0.6151783529802322, -0.03921319155395031]\n",
      "action: [  0. 155.  70.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 149, 72] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.07142857] real action [  0. 155.  70.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.11785725192092897, -0.6017855029802321, -0.053500000000000006]\n",
      "action: [  0. 150.  68.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 149, 72] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571] real action [  0. 150.  68.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.11785725192092897, -0.6017855029802321, -0.053500000000000006]\n",
      "action: [  0. 150.  68.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 149, 73] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571] real action [  0. 150.  68.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.26785714 0.49107143 0.67410714 0.31696429 0.40178571 0.80357143\n",
      " 0.16964286 0.13839286 0.68303571 0.76785714 0.57589286 0.51785714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.57142857]\n",
      "lang goal put the Letter R on a green bowl\n",
      "steping pick:  [-0.08839298192092895, -0.6098212129802323, -0.03822336329519749]\n",
      "action: [  0. 153.  79.]\n",
      "pick_success 1\n",
      "dis 7.810249675906654 pick_success 1\n",
      "desired_action : [0, 148, 73] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.57142857] real action [  0. 153.  79.]\n",
      "reward 0.0 done:  True\n",
      "observation: [ 0.26785714  0.49107143 -0.00892857  0.46875     0.40178571  0.80357143\n",
      "  0.16964286  0.13839286  0.68303571  0.76785714  0.57589286  0.51785714] [ True]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.5        -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.20089292192092895, -0.3312499329802322, -0.039935869932174684]\n",
      "action: [ 0. 49. 37.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 56, 38] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.5        -0.07142857] real action [ 0. 49. 37.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.25       0.16964286\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.21428577192092896, -0.3419642129802323, -0.053500000000000006]\n",
      "action: [ 0. 53. 32.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 56, 38] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.42857143] real action [ 0. 53. 32.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.25       0.16964286\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.20357149192092897, -0.33392850298023224, -0.053500000000000006]\n",
      "action: [ 0. 50. 36.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 55, 39] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.14285714] real action [ 0. 50. 36.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.25       0.16964286\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.20625006192092896, -0.35535706298023223, -0.053500000000000006]\n",
      "action: [ 0. 58. 35.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 55, 39] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.21428571] real action [ 0. 58. 35.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.25       0.16964286\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.5        -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.20892863192092898, -0.3312499329802322, -0.044559087440371514]\n",
      "action: [ 0. 49. 34.]\n",
      "pick_success 0\n",
      "dis 7.810249675906654 pick_success 0\n",
      "desired_action : [0, 55, 39] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.5        -0.28571429] real action [ 0. 49. 34.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.25       0.16964286\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.35714286 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.21160720192092897, -0.3633927729802322, -0.040439555257558824]\n",
      "action: [ 0. 61. 33.]\n",
      "pick_success 0\n",
      "dis 8.48528137423857 pick_success 0\n",
      "desired_action : [0, 55, 39] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.35714286 -0.35714286] real action [ 0. 61. 33.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.25       0.16964286\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.21160720192092897, -0.3419642129802323, -0.053500000000000006]\n",
      "action: [ 0. 53. 33.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 55, 39] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286] real action [ 0. 53. 33.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.25       0.16964286\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.5       ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.21696434192092895, -0.33660707298023224, -0.0397830026447773]\n",
      "action: [ 0. 51. 31.]\n",
      "pick_success 1\n",
      "dis 8.94427190999916 pick_success 1\n",
      "desired_action : [0, 55, 39] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.5       ] real action [ 0. 51. 31.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.02678571 0.52678571\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.5        -0.71428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.10446405807907105, -0.6044640729802322, 0.022767326772212985]\n",
      "place_xyz[2] 0.022767326772212985 False\n",
      "desired_action : [1, 158, 161] phase_loss 0.0 dis_reward -0.00298\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.5        -0.71428571] real action [  1. 151. 151.]\n",
      "reward 0.99702 done:  True\n",
      "observation: [0.79910714 0.43303571 0.46875    0.52678571 0.69196429 0.71428571\n",
      " 0.20535714 0.50892857 0.70535714 0.71875    0.38839286 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.03214266807907101, -0.46785700298023225, -0.0390675382912159]\n",
      "action: [  0. 100. 125.]\n",
      "pick_success 0\n",
      "dis 3.6055512754639776 pick_success 0\n",
      "desired_action : [0, 98, 122] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.21428571] real action [  0. 100. 125.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.4375     0.54464286 0.625      0.375      0.80803571 0.16964286\n",
      " 0.24107143 0.24107143 0.35714286 0.76339286 0.77678571 0.63839286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.010714108079071027, -0.4651784329802322, -0.03882395459711552]\n",
      "action: [  0.  99. 117.]\n",
      "pick_success 1\n",
      "dis 5.099019513592799 pick_success 1\n",
      "desired_action : [0, 98, 122] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286] real action [  0.  99. 117.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.00446429 0.52232143 0.625      0.375      0.80803571 0.16964286\n",
      " 0.24107143 0.24107143 0.35714286 0.76339286 0.77678571 0.63839286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.   0.   0.   0.   1.   0.   0.  -0.5  0. ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.15535723192092896, -0.3258927929802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 54, 54] phase_loss 0.0 dis_reward -0.0009800000000000002\n",
      "action  [ 1.   0.   0.   0.   1.   0.   0.  -0.5  0. ] real action [ 1. 47. 54.]\n",
      "reward 0.99902 done:  True\n",
      "observation: [0.20089286 0.27232143 0.625      0.375      0.80803571 0.16964286\n",
      " 0.24107143 0.24107143 0.35714286 0.76339286 0.77678571 0.63839286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.11517833807907102, -0.4919641329802322, -0.03828509694337845]\n",
      "action: [  0. 109. 155.]\n",
      "pick_success 1\n",
      "dis 2.23606797749979 pick_success 1\n",
      "desired_action : [0, 110, 153] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  0. 109. 155.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.64285714 0.1875     0.36607143 0.27678571 0.01785714 0.48660714\n",
      " 0.74553571 0.46428571 0.21428571 0.4375     0.22767857 0.78125   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.35714286 0.92857143]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping: place [0.20357114807907106, -0.34999992298023225, 0.02039170076698065]\n",
      "place_xyz[2] 0.02039170076698065 False\n",
      "desired_action : [1, 51, 175] phase_loss 0.0 dis_reward -0.00388\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.35714286 0.92857143] real action [  1.  56. 188.]\n",
      "reward 0.99612 done:  True\n",
      "observation: [0.64285714 0.1875     0.36607143 0.27678571 0.25       0.83035714\n",
      " 0.74553571 0.46428571 0.21428571 0.4375     0.22767857 0.78125   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.010714451920928958, -0.3901784729802322, -0.04228304123878479]\n",
      "action: [  0.  71. 108.]\n",
      "pick_success 1\n",
      "dis 6.708203932499369 pick_success 1\n",
      "desired_action : [0, 77, 105] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.21428571] real action [  0.  71. 108.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.61160714 0.35714286 0.3125     0.73660714 0.03571429 0.48660714\n",
      " 0.74107143 0.64732143 0.79910714 0.13839286 0.23660714 0.13839286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.78571429  0.85714286]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.18482150192092894, -0.6499997629802322, 0.020113764308393005]\n",
      "place_xyz[2] 0.020113764308393005 False\n",
      "desired_action : [1, 179, 31] phase_loss 0.0 dis_reward -0.005299999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.78571429  0.85714286] real action [  1. 168.  43.]\n",
      "reward 0.9947 done:  True\n",
      "observation: [0.61160714 0.35714286 0.3125     0.73660714 0.76785714 0.18303571\n",
      " 0.74107143 0.64732143 0.79910714 0.13839286 0.23660714 0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13928581192092895, -0.4142856029802322, -0.053500000000000006]\n",
      "action: [ 0. 80. 60.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 74, 59] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.07142857] real action [ 0. 80. 60.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.33035714 0.26339286 0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13928581192092895, -0.3955356129802322, -0.053500000000000006]\n",
      "action: [ 0. 73. 60.]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 74, 60] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.07142857] real action [ 0. 73. 60.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.33035714 0.26339286 0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15000009192092895, -0.4089284629802322, -0.053500000000000006]\n",
      "action: [ 0. 78. 56.]\n",
      "pick_success 0\n",
      "dis 5.656854249492381 pick_success 0\n",
      "desired_action : [0, 74, 60] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.21428571] real action [ 0. 78. 56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.33035714 0.26339286 0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.14196438192092897, -0.38482133298023224, -0.053500000000000006]\n",
      "action: [ 0. 69. 59.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 73, 60] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ] real action [ 0. 69. 59.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.33035714 0.26339286 0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13660724192092896, -0.40624989298023223, -0.053500000000000006]\n",
      "action: [ 0. 77. 61.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 72, 61] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.14285714] real action [ 0. 77. 61.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.33035714 0.26339286 0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13928581192092895, -0.3955356129802322, -0.053500000000000006]\n",
      "action: [ 0. 73. 60.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 71, 62] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.07142857] real action [ 0. 73. 60.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.3125     0.28125    0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.12589296192092897, -0.39821418298023226, -0.053500000000000006]\n",
      "action: [ 0. 74. 65.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 70, 63] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.14285714] real action [ 0. 74. 65.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.3125     0.28125    0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.14732152192092896, -0.3767856229802322, -0.053500000000000006]\n",
      "action: [ 0. 66. 57.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 69, 63] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.42857143] real action [ 0. 66. 57.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.3125     0.28125    0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.12589296192092897, -0.3901784729802322, -0.053500000000000006]\n",
      "action: [ 0. 71. 65.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 68, 64] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.14285714] real action [ 0. 71. 65.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.3125     0.28125    0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13125010192092895, -0.3928570429802322, -0.053500000000000006]\n",
      "action: [ 0. 72. 63.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 67, 65] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.        ] real action [ 0. 72. 63.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41964286 0.79910714 0.3125     0.28125    0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13660724192092896, -0.3741070529802322, -0.053500000000000006]\n",
      "action: [ 0. 65. 61.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 67, 65] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714] real action [ 0. 65. 61.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.41964286 0.79910714 0.3125     0.28125    0.70982143 0.50892857\n",
      " 0.44642857 0.47767857 0.61160714 0.1875     0.80357143 0.73214286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.045535861920928955, -0.5830355129802323, -0.053500000000000006]\n",
      "action: [  0. 143.  95.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 138, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.21428571] real action [  0. 143.  95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.045535861920928955, -0.5723212329802323, -0.053500000000000006]\n",
      "action: [  0. 139.  95.]\n",
      "pick_success 0\n",
      "dis 3.0 pick_success 0\n",
      "desired_action : [0, 139, 92] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.21428571] real action [  0. 139.  95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.07232156192092895, -0.5642855229802322, -0.0345938073694706]\n",
      "pick_success 0\n",
      "dis 8.54400374531753 pick_success 0\n",
      "desired_action : [0, 139, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ] real action [  0. 136.  85.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.35714286 -0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.056250141920928975, -0.5830355129802323, -0.053500000000000006]\n",
      "action: [  0. 143.  91.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 139, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.35714286 -0.07142857] real action [  0. 143.  91.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.06160728192092896, -0.5803569429802322, -0.053500000000000006]\n",
      "action: [  0. 142.  89.]\n",
      "pick_success 0\n",
      "dis 5.656854249492381 pick_success 0\n",
      "desired_action : [0, 138, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.21428571] real action [  0. 142.  89.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.04017872192092897, -0.5723212329802323, -0.053500000000000006]\n",
      "action: [  0. 139.  97.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 137, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.35714286] real action [  0. 139.  97.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.06428585192092895, -0.5589283829802323, -0.053500000000000006]\n",
      "action: [  0. 134.  88.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 136, 94] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.28571429] real action [  0. 134.  88.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.05892871192092897, -0.5669640929802322, -0.053500000000000006]\n",
      "action: [  0. 137.  90.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 136, 94] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714] real action [  0. 137.  90.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.050893001920928965, -0.5803569429802322, -0.053500000000000006]\n",
      "action: [  0. 142.  93.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 135, 94] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.07142857] real action [  0. 142.  93.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.042857291920928964, -0.5776783729802322, -0.04235269299149513]\n",
      "action: [  0. 141.  96.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 134, 95] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.28571429] real action [  0. 141.  96.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.73660714 0.67857143 0.61607143 0.41071429 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.05892871192092897, -0.5589283829802323, -0.053500000000000006]\n",
      "action: [  0. 134.  90.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 134, 95] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714] real action [  0. 134.  90.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.73660714 0.67857143 0.59375    0.42410714 0.20982143 0.61607143\n",
      " 0.24107143 0.31696429 0.83035714 0.20982143 0.43303571 0.70089286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.35714286 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.13928546807907105, -0.38749990298023224, -0.053500000000000006]\n",
      "action: [  0.  70. 164.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 65, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.35714286 -0.35714286] real action [  0.  70. 164.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.29017857 0.75446429 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.16339259807907103, -0.3821427629802322, -0.053500000000000006]\n",
      "action: [  0.  68. 173.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 65, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.28571429] real action [  0.  68. 173.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.29017857 0.75446429 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.14196403807907104, -0.3580356329802322, -0.043423758655786515]\n",
      "action: [  0.  59. 165.]\n",
      "pick_success 0\n",
      "dis 7.211102550927978 pick_success 0\n",
      "desired_action : [0, 65, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.28571429] real action [  0.  59. 165.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.29017857 0.75446429 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.15803545807907105, -0.3901784729802322, -0.04207506759464741]\n",
      "action: [  0.  71. 171.]\n",
      "pick_success 0\n",
      "dis 7.280109889280518 pick_success 0\n",
      "desired_action : [0, 64, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.14285714] real action [  0.  71. 171.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.29017857 0.75446429 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.14732117807907102, -0.36071420298023227, -0.053500000000000006]\n",
      "action: [  0.  60. 167.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 62, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714] real action [  0.  60. 167.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.29017857 0.75446429 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.14999974807907102, -0.36071420298023227, -0.053500000000000006]\n",
      "action: [  0.  60. 168.]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 60, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.07142857] real action [  0.  60. 168.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.25892857 0.75892857 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.152678318079071, -0.3580356329802322, -0.053500000000000006]\n",
      "action: [  0.  59. 169.]\n",
      "pick_success 0\n",
      "dis 1.4142135623731 pick_success 0\n",
      "desired_action : [0, 58, 170] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.07142857] real action [  0.  59. 169.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.25892857 0.75892857 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.14732117807907102, -0.3580356329802322, -0.053500000000000006]\n",
      "action: [  0.  59. 167.]\n",
      "pick_success 0\n",
      "dis 5.000000000000005 pick_success 0\n",
      "desired_action : [0, 55, 170] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571] real action [  0.  59. 167.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.25892857 0.75892857 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.13928546807907105, -0.35535706298023223, -0.04312481714785099]\n",
      "action: [  0.  58. 164.]\n",
      "pick_success 0\n",
      "dis 7.810249675906659 pick_success 0\n",
      "desired_action : [0, 53, 170] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.         -0.42857143] real action [  0.  58. 164.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.22767857 0.75892857 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.15535688807907105, -0.33392850298023224, -0.053500000000000006]\n",
      "action: [  0.  50. 170.]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 51, 170] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ] real action [  0.  50. 170.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.72767857 0.22767857 0.22767857 0.75892857 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857  0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.15535688807907105, -0.31517851298023225, -0.053500000000000006]\n",
      "action: [  0.  43. 170.]\n",
      "pick_success 0\n",
      "dis 7.0 pick_success 0\n",
      "desired_action : [0, 50, 170] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857  0.        ] real action [  0.  43. 170.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.72767857 0.22767857 0.22767857 0.75892857 0.52678571 0.40178571\n",
      " 0.66964286 0.67410714 0.33035714 0.14285714 0.26339286 0.40625   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.4598212929802322, -0.053500000000000006]\n",
      "action: [  0.  97. 168.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 99, 168] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.        ] real action [  0.  97. 168.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.44196429 0.75       0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.15535688807907105, -0.4598212929802322, -0.053500000000000006]\n",
      "action: [  0.  97. 170.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 100, 168] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714] real action [  0.  97. 170.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.44196429 0.75       0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.57142857 -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.14464260807907103, -0.48660699298023224, -0.04185871018469334]\n",
      "action: [  0. 107. 166.]\n",
      "pick_success 0\n",
      "dis 7.280109889280518 pick_success 0\n",
      "desired_action : [0, 100, 168] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.57142857 -0.14285714] real action [  0. 107. 166.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.44196429 0.75       0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.16071402807907104, -0.46785700298023225, -0.053500000000000006]\n",
      "action: [  0. 100. 172.]\n",
      "pick_success 0\n",
      "dis 4.0 pick_success 0\n",
      "desired_action : [0, 100, 168] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.28571429] real action [  0. 100. 172.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.44196429 0.75       0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.13928546807907105, -0.47321414298023223, -0.053500000000000006]\n",
      "action: [  0. 102. 164.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 100, 168] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.28571429] real action [  0. 102. 164.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.44196429 0.75       0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.14732117807907102, -0.47053557298023224, -0.053500000000000006]\n",
      "action: [  0. 101. 167.]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 101, 168] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [  0. 101. 167.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.44196429 0.75       0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.15535688807907105, -0.47053557298023224, -0.053500000000000006]\n",
      "action: [  0. 101. 170.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 101, 168] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.14285714] real action [  0. 101. 170.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.44196429 0.75       0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.14196403807907104, -0.44910701298023226, -0.04045707529783249]\n",
      "action: [  0.  93. 165.]\n",
      "pick_success 1\n",
      "dis 9.486832980505138 pick_success 1\n",
      "desired_action : [0, 102, 168] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571] real action [  0.  93. 165.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.04910714 0.50892857 0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.64285714 -0.57142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [0.12589261807907104, -0.28035710298023225, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 39, 167] phase_loss 0.0 dis_reward -0.0029000000000000002\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.64285714 -0.57142857] real action [  1.  30. 159.]\n",
      "reward 0.9971 done:  True\n",
      "observation: [0.16517857 0.72321429 0.25892857 0.26339286 0.50446429 0.45535714\n",
      " 0.80357143 0.33035714 0.70982143 0.59821429 0.17410714 0.74553571] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.35714286 -0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.18214258807907102, -0.33392850298023224, -0.04222943617403507]\n",
      "action: [  0.  50. 180.]\n",
      "pick_success 1\n",
      "dis 5.0990195135927845 pick_success 1\n",
      "desired_action : [0, 45, 181] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.35714286 -0.07142857] real action [  0.  50. 180.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.58928571  0.24553571  0.59375     0.64732143 -0.01339286  0.50446429\n",
      "  0.19642857  0.48214286  0.28125     0.21428571  0.81696429  0.41071429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.5        -0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.02142873192092898, -0.33660707298023224, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 44, 108] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.5        -0.28571429] real action [  1.  51. 104.]\n",
      "reward 0.9987 done:  True\n",
      "observation: [0.58928571 0.24553571 0.59375    0.64732143 0.20089286 0.46875\n",
      " 0.19642857 0.48214286 0.28125    0.21428571 0.81696429 0.41071429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.5        -0.35714286]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.06160693807907103, -0.5053569829802322, -0.039497453555464745]\n",
      "action: [  0. 114. 135.]\n",
      "pick_success 1\n",
      "dis 8.602325267042627 pick_success 1\n",
      "desired_action : [0, 107, 140] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.5        -0.35714286] real action [  0. 114. 135.]\n",
      "reward 0.0 done:  False\n",
      "observation: [-0.01785714  0.51785714  0.79017857  0.28125     0.33482143  0.27678571\n",
      "  0.78125     0.50446429  0.17410714  0.74107143  0.23214286  0.49107143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.07142857 0.78571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.02410695807907104, -0.3419642129802323, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 52, 110] phase_loss 0.0 dis_reward -0.00244\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.07142857 0.78571429] real action [  1.  53. 121.]\n",
      "reward 0.99756 done:  True\n",
      "observation: [0.20089286 0.5625     0.79017857 0.28125    0.33482143 0.27678571\n",
      " 0.78125    0.50446429 0.17410714 0.74107143 0.23214286 0.49107143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.07142857 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.15535688807907105, -0.6392854829802322, -0.053500000000000006]\n",
      "action: [  0. 164. 170.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.07142857 -0.21428571] real action [  0. 164. 170.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.14999974807907102, -0.6232140629802323, -0.053500000000000006]\n",
      "action: [  0. 158. 168.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.35714286] real action [  0. 158. 168.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.15535688807907105, -0.6205354929802323, -0.053500000000000006]\n",
      "action: [  0. 157. 170.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571] real action [  0. 157. 170.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.17946401807907103, -0.6366069129802322, -0.04336841015517712]\n",
      "action: [  0. 163. 179.]\n",
      "pick_success 0\n",
      "dis 6.0 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.42857143] real action [  0. 163. 179.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.14999974807907102, -0.6446426229802322, -0.053500000000000006]\n",
      "action: [  0. 166. 168.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.35714286] real action [  0. 166. 168.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.16607116807907102, -0.6312497729802322, -0.053500000000000006]\n",
      "action: [  0. 161. 174.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.07142857] real action [  0. 161. 174.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.15535688807907105, -0.6312497729802322, -0.053500000000000006]\n",
      "action: [  0. 161. 170.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.21428571] real action [  0. 161. 170.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.168749738079071, -0.6339283429802323, -0.053500000000000006]\n",
      "action: [  0. 162. 175.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  0. 162. 175.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.15803545807907105, -0.6312497729802322, -0.053500000000000006]\n",
      "action: [  0. 161. 171.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714 -0.14285714] real action [  0. 161. 171.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.17142830807907106, -0.6446426229802322, -0.053500000000000006]\n",
      "action: [  0. 166. 176.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 163, 173] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.21428571] real action [  0. 166. 176.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.17410687807907105, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [  0. 159. 177.]\n",
      "pick_success 0\n",
      "dis 6.4031242374328485 pick_success 0\n",
      "desired_action : [0, 163, 172] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.28571429] real action [  0. 159. 177.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.49107143 0.52678571 0.66964286 0.30803571 0.72767857 0.77232143\n",
      " 0.21875    0.70982143 0.1875     0.19642857 0.81696429 0.48214286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.07142857]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.06696442192092897, -0.6044640729802322, -0.04009841366112232]\n",
      "action: [  0. 151.  87.]\n",
      "pick_success 0\n",
      "dis 1.4142135623730951 pick_success 0\n",
      "desired_action : [0, 150, 86] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.07142857] real action [  0. 151.  87.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.25892857 0.6875     0.66964286 0.38392857 0.25446429 0.24107143\n",
      " 0.8125     0.66071429 0.44642857 0.48214286 0.50892857 0.77232143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.05892871192092897, -0.5883926529802322, -0.040771512150764466]\n",
      "action: [  0. 145.  90.]\n",
      "pick_success 1\n",
      "dis 6.4031242374328485 pick_success 1\n",
      "desired_action : [0, 150, 86] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.28571429] real action [  0. 145.  90.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.25892857 0.6875     0.03125    0.47767857 0.25446429 0.24107143\n",
      " 0.8125     0.66071429 0.44642857 0.48214286 0.50892857 0.77232143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.71428571  0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.0053573119209289755, -0.4410713029802322, 0.021594010271131996]\n",
      "place_xyz[2] 0.021594010271131996 False\n",
      "desired_action : [1, 100, 108] phase_loss 0.0 dis_reward -0.00208\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.71428571  0.14285714] real action [  1.  90. 110.]\n",
      "reward 0.99792 done:  True\n",
      "observation: [0.25892857 0.6875     0.41964286 0.47767857 0.25446429 0.24107143\n",
      " 0.8125     0.66071429 0.44642857 0.48214286 0.50892857 0.77232143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.03214266807907101, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [  0. 159. 124.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 159, 119] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.35714286] real action [  0. 159. 124.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.20982143 0.37946429 0.78571429 0.70982143 0.53125\n",
      " 0.70982143 0.17857143 0.16517857 0.60714286 0.47767857 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.02410695807907104, -0.6232140629802323, -0.03681822291016579]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 158, 119] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  0. 158. 121.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.20982143 0.37946429 0.78571429 0.70982143 0.53125\n",
      " 0.70982143 0.17857143 0.16517857 0.60714286 0.47767857 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.42857143]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.03482123807907106, -0.6151783529802322, -0.053500000000000006]\n",
      "action: [  0. 155. 125.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 158, 119] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.42857143] real action [  0. 155. 125.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.20982143 0.37946429 0.78571429 0.70982143 0.53125\n",
      " 0.70982143 0.17857143 0.16517857 0.60714286 0.47767857 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.03214266807907101, -0.6232140629802323, -0.053500000000000006]\n",
      "action: [  0. 158. 124.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 158, 119] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.35714286] real action [  0. 158. 124.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.20982143 0.37946429 0.78571429 0.70982143 0.53125\n",
      " 0.70982143 0.17857143 0.16517857 0.60714286 0.47767857 0.31696429] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.07142857]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.021428388079071048, -0.6178569229802322, -0.037542490124702455]\n",
      "action: [  0. 156. 120.]\n",
      "pick_success 1\n",
      "dis 2.23606797749979 pick_success 1\n",
      "desired_action : [0, 158, 119] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.07142857] real action [  0. 156. 120.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.24107143 0.20982143 0.37946429 0.78571429 0.02232143 0.49107143\n",
      " 0.70982143 0.17857143 0.16517857 0.60714286 0.47767857 0.31696429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.07142857 -0.28571429]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping: place [-0.12053582192092896, -0.48928556298023224, 0.023280370026826862]\n",
      "place_xyz[2] 0.023280370026826862 False\n",
      "desired_action : [1, 107, 71] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.07142857 -0.28571429] real action [  1. 108.  67.]\n",
      "reward 0.99966 done:  True\n",
      "observation: [0.24107143 0.20982143 0.37946429 0.78571429 0.48660714 0.29464286\n",
      " 0.70982143 0.17857143 0.16517857 0.60714286 0.47767857 0.31696429] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02410695807907104, -0.34732135298023226, -0.053500000000000006]\n",
      "action: [  0.  55. 121.]\n",
      "pick_success 0\n",
      "dis 0.0 pick_success 0\n",
      "desired_action : [0, 55, 121] phase_loss 0.0 dis_reward 0\n",
      "action  [0. 0. 0. 1. 0. 0. 0. 0. 0.] real action [  0.  55. 121.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.24553571 0.54017857\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.28571429 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.018749818079071057, -0.3580356329802322, -0.053500000000000006]\n",
      "action: [  0.  59. 119.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 55, 121] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.28571429 -0.14285714] real action [  0.  59. 119.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.24553571 0.54017857\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02410695807907104, -0.3392856429802322, -0.053500000000000006]\n",
      "action: [  0.  52. 121.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 54, 122] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.        ] real action [  0.  52. 121.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.24553571 0.54017857\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.35714286 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02946409807907102, -0.36071420298023227, -0.053500000000000006]\n",
      "action: [  0.  60. 123.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 55, 121] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.35714286 0.14285714] real action [  0.  60. 123.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.24553571 0.54017857\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02410695807907104, -0.34732135298023226, -0.053500000000000006]\n",
      "action: [  0.  55. 121.]\n",
      "pick_success 0\n",
      "dis 0.0 pick_success 0\n",
      "desired_action : [0, 55, 121] phase_loss 0.0 dis_reward 0\n",
      "action  [0. 0. 0. 1. 0. 0. 0. 0. 0.] real action [  0.  55. 121.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.24553571 0.54017857\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.42857143 0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02410695807907104, -0.3633927729802322, -0.053500000000000006]\n",
      "action: [  0.  61. 121.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 57, 120] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.42857143 0.        ] real action [  0.  61. 121.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.24553571 0.54017857\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.03482123807907106, -0.33660707298023224, -0.039599347695708276]\n",
      "action: [  0.  51. 125.]\n",
      "pick_success 0\n",
      "dis 7.810249675906654 pick_success 0\n",
      "desired_action : [0, 57, 120] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.28571429] real action [  0.  51. 125.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.24553571 0.54017857\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.5       ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.04285694807907103, -0.33660707298023224, -0.053500000000000006]\n",
      "action: [  0.  51. 128.]\n",
      "pick_success 1\n",
      "dis 10.0 pick_success 1\n",
      "desired_action : [0, 57, 120] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.5       ] real action [  0.  51. 128.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.02678571 0.46875\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.07142857 0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.20089292192092895, -0.5857140829802322, 0.025057423837482933]\n",
      "place_xyz[2] 0.025057423837482933 False\n",
      "desired_action : [1, 143, 34] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.07142857 0.21428571] real action [  1. 144.  37.]\n",
      "reward 0.9998 done:  True\n",
      "observation: [0.41517857 0.34821429 0.79017857 0.54017857 0.65625    0.13392857\n",
      " 0.65178571 0.76339286 0.63839286 0.15178571 0.29910714 0.75      ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.0026783980790710538, -0.35535706298023223, -0.047735553070902825]\n",
      "action: [  0.  58. 113.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 60, 107] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.42857143] real action [  0.  58. 113.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02678587192092896, -0.35535706298023223, -0.053500000000000006]\n",
      "action: [  0.  58. 102.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 60, 106] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.35714286] real action [  0.  58. 102.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.029464441920928952, -0.34999992298023225, -0.053500000000000006]\n",
      "action: [  0.  56. 101.]\n",
      "pick_success 0\n",
      "dis 6.4031242374328485 pick_success 0\n",
      "desired_action : [0, 60, 106] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.42857143] real action [  0.  56. 101.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02678587192092896, -0.3633927729802322, -0.053500000000000006]\n",
      "action: [  0.  61. 102.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 59, 107] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286] real action [  0.  61. 102.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.010714451920928958, -0.37142848298023223, -0.04307633063197136]\n",
      "action: [  0.  64. 108.]\n",
      "pick_success 0\n",
      "dis 7.0 pick_success 0\n",
      "desired_action : [0, 57, 108] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.07142857] real action [  0.  64. 108.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02410730192092897, -0.34732135298023226, -0.053500000000000006]\n",
      "action: [  0.  55. 103.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 58, 108] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.28571429] real action [  0.  55. 103.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02142873192092898, -0.3633927729802322, -0.053500000000000006]\n",
      "action: [  0.  61. 104.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 58, 108] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571] real action [  0.  61. 104.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.0026787419209289842, -0.34732135298023226, -0.053500000000000006]\n",
      "action: [  0.  55. 111.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 56, 109] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286  0.28571429] real action [  0.  55. 111.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02410730192092897, -0.36874991298023224, -0.03821088357269764]\n",
      "action: [  0.  63. 103.]\n",
      "pick_success 0\n",
      "dis 9.219544457292887 pick_success 0\n",
      "desired_action : [0, 56, 109] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.28571429] real action [  0.  63. 103.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.26785714 0.47767857 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.5       ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.03214301192092894, -0.35267849298023224, -0.053500000000000006]\n",
      "action: [  0.  57. 100.]\n",
      "pick_success 0\n",
      "dis 9.055385138137417 pick_success 0\n",
      "desired_action : [0, 56, 109] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.5       ] real action [  0.  57. 100.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.67410714 0.77232143 0.24553571 0.49107143 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.3580356329802322, -0.053500000000000006]\n",
      "action: [  0.  59. 106.]\n",
      "pick_success 0\n",
      "dis 5.656854249492381 pick_success 0\n",
      "desired_action : [0, 55, 110] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.28571429] real action [  0.  59. 106.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.67410714 0.77232143 0.24553571 0.49107143 0.37053571 0.17410714\n",
      " 0.67410714 0.47321429 0.67410714 0.14732143 0.38839286 0.75      ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.11785725192092897, -0.32053565298023223, -0.053500000000000006]\n",
      "action: [ 0. 45. 68.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 50, 70] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714] real action [ 0. 45. 68.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.22321429 0.3125\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10982154192092897, -0.33660707298023224, -0.053500000000000006]\n",
      "action: [ 0. 51. 71.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 51, 69] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.07142857] real action [ 0. 51. 71.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.22321429 0.3125\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10178583192092897, -0.33660707298023224, -0.053500000000000006]\n",
      "action: [ 0. 51. 74.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 52, 69] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.28571429] real action [ 0. 51. 74.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.22321429 0.3125\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.11250011192092896, -0.32053565298023223, -0.04989627918601036]\n",
      "action: [ 0. 45. 70.]\n",
      "pick_success 0\n",
      "dis 7.280109889280518 pick_success 0\n",
      "desired_action : [0, 52, 68] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.        ] real action [ 0. 45. 70.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.22321429 0.3125\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.12589296192092897, -0.3232142229802322, -0.053500000000000006]\n",
      "action: [ 0. 46. 65.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 52, 68] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.35714286] real action [ 0. 46. 65.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.22321429 0.3125\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.35714286 0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10446440192092896, -0.34732135298023226, -0.053500000000000006]\n",
      "action: [ 0. 55. 73.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 53, 68] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.35714286 0.21428571] real action [ 0. 55. 73.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.22321429 0.3125\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.12321439192092895, -0.32053565298023223, -0.045750485569238664]\n",
      "action: [ 0. 45. 66.]\n",
      "pick_success 0\n",
      "dis 8.06225774829855 pick_success 0\n",
      "desired_action : [0, 53, 67] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.28571429] real action [ 0. 45. 66.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.22321429 0.3125\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10446440192092896, -0.3392856429802322, -0.053500000000000006]\n",
      "action: [ 0. 52. 73.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 53, 67] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.21428571] real action [ 0. 52. 73.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.22321429 0.3125\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10982154192092897, -0.32053565298023223, -0.053500000000000006]\n",
      "action: [ 0. 45. 71.]\n",
      "pick_success 1\n",
      "dis 8.94427190999916 pick_success 1\n",
      "desired_action : [0, 53, 67] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.07142857] real action [ 0. 45. 71.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.03571429 0.48214286\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.14285714  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.08571441192092896, -0.6553569029802322, 0.025637550257146362]\n",
      "place_xyz[2] 0.025637550257146362 False\n",
      "desired_action : [1, 172, 80] phase_loss 0.0 dis_reward -8e-05\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.14285714  0.        ] real action [  1. 170.  80.]\n",
      "reward 0.99992 done:  True\n",
      "observation: [0.5        0.82142857 0.51339286 0.53125    0.78571429 0.34821429\n",
      " 0.20089286 0.57142857 0.72321429 0.65178571 0.76785714 0.35714286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.5       ]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.15000009192092895, -0.2937499529802322, -0.053500000000000006]\n",
      "action: [ 0. 35. 56.]\n",
      "pick_success 0\n",
      "dis 7.615773105863909 pick_success 0\n",
      "desired_action : [0, 38, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.5       ] real action [ 0. 35. 56.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29017857 0.47321429 0.81696429 0.20535714 0.16964286 0.21875\n",
      " 0.19642857 0.67857143 0.63392857 0.50446429 0.64285714 0.75892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.07142857]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.16607151192092895, -0.2883928129802322, -0.053500000000000006]\n",
      "action: [ 0. 33. 50.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 37, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.07142857] real action [ 0. 33. 50.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29017857 0.47321429 0.81696429 0.20535714 0.16964286 0.21875\n",
      " 0.19642857 0.67857143 0.63392857 0.50446429 0.64285714 0.75892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.21428571]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.16071437192092897, -0.28571424298023224, -0.053500000000000006]\n",
      "action: [ 0. 32. 52.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 37, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.21428571] real action [ 0. 32. 52.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29017857 0.47321429 0.81696429 0.20535714 0.16964286 0.21875\n",
      " 0.19642857 0.67857143 0.63392857 0.50446429 0.64285714 0.75892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.28571429]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [-0.17946436192092896, -0.3071428029802322, -0.04268397933244705]\n",
      "action: [ 0. 40. 45.]\n",
      "pick_success 1\n",
      "dis 4.47213595499958 pick_success 1\n",
      "desired_action : [0, 38, 49] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.28571429] real action [ 0. 40. 45.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.29017857  0.47321429  0.81696429  0.20535714 -0.00892857  0.51339286\n",
      "  0.19642857  0.67857143  0.63392857  0.50446429  0.64285714  0.75892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143  0.14285714]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [0.11249976807907103, -0.30178566298023224, 0.023619962833821777]\n",
      "place_xyz[2] 0.023619962833821777 False\n",
      "desired_action : [1, 44, 152] phase_loss 0.0 dis_reward -0.0008000000000000003\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143  0.14285714] real action [  1.  38. 154.]\n",
      "reward 0.9992 done:  True\n",
      "observation: [0.29017857 0.47321429 0.81696429 0.20535714 0.15178571 0.70982143\n",
      " 0.19642857 0.67857143 0.63392857 0.50446429 0.64285714 0.75892857] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.14464295192092896, -0.29910709298023225, -0.053500000000000006]\n",
      "action: [ 0. 37. 58.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 38, 56] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [ 0. 37. 58.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29910714 0.48660714 0.55357143 0.71428571 0.16964286 0.25\n",
      " 0.81696429 0.74107143 0.66071429 0.27232143 0.25       0.70535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16339294192092896, -0.30446423298023223, -0.053500000000000006]\n",
      "action: [ 0. 39. 51.]\n",
      "pick_success 0\n",
      "dis 6.324555320336759 pick_success 0\n",
      "desired_action : [0, 37, 57] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.07142857 -0.35714286] real action [ 0. 39. 51.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29910714 0.48660714 0.55357143 0.71428571 0.16964286 0.25\n",
      " 0.81696429 0.74107143 0.66071429 0.27232143 0.25       0.70535714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.13928581192092895, -0.30446423298023223, -0.053500000000000006]\n",
      "action: [ 0. 39. 60.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 37, 57] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.28571429] real action [ 0. 39. 60.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29910714 0.48660714 0.55357143 0.71428571 0.16964286 0.25\n",
      " 0.81696429 0.74107143 0.66071429 0.27232143 0.25       0.70535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.29910709298023225, -0.053500000000000006]\n",
      "action: [ 0. 37. 54.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 38, 56] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714] real action [ 0. 37. 54.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29910714 0.48660714 0.55357143 0.71428571 0.16964286 0.25\n",
      " 0.81696429 0.74107143 0.66071429 0.27232143 0.25       0.70535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16071437192092897, -0.29910709298023225, -0.053500000000000006]\n",
      "action: [ 0. 37. 52.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 38, 55] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.28571429] real action [ 0. 37. 52.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29910714 0.48660714 0.55357143 0.71428571 0.16964286 0.25\n",
      " 0.81696429 0.74107143 0.66071429 0.27232143 0.25       0.70535714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.14464295192092896, -0.30982137298023227, -0.053500000000000006]\n",
      "action: [ 0. 41. 58.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 39, 54] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.14285714] real action [ 0. 41. 58.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.29910714 0.48660714 0.55357143 0.71428571 0.16964286 0.25\n",
      " 0.81696429 0.74107143 0.66071429 0.27232143 0.25       0.70535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.14464295192092896, -0.2883928129802322, -0.0392758267223835]\n",
      "action: [ 0. 33. 58.]\n",
      "pick_success 1\n",
      "dis 9.433981132056603 pick_success 1\n",
      "desired_action : [0, 41, 53] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.14285714] real action [ 0. 33. 58.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.29910714 0.48660714 0.55357143 0.71428571 0.04017857 0.47321429\n",
      " 0.81696429 0.74107143 0.66071429 0.27232143 0.25       0.70535714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.5         0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [0.12857118807907103, -0.3312499329802322, 0.02069740926474333]\n",
      "place_xyz[2] 0.02069740926474333 False\n",
      "desired_action : [1, 56, 158] phase_loss 0.0 dis_reward -0.00106\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.5         0.14285714] real action [  1.  49. 160.]\n",
      "reward 0.99894 done:  True\n",
      "observation: [0.29910714 0.48660714 0.55357143 0.71428571 0.24553571 0.69642857\n",
      " 0.81696429 0.74107143 0.66071429 0.27232143 0.25       0.70535714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.13928546807907105, -0.43571416298023224, -0.053500000000000006]\n",
      "action: [  0.  88. 164.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 87, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.28571429] real action [  0.  88. 164.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.13928546807907105, -0.43839273298023224, -0.053500000000000006]\n",
      "action: [  0.  89. 164.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.28571429] real action [  0.  89. 164.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.12857118807907103, -0.4410713029802322, -0.053500000000000006]\n",
      "action: [  0.  90. 160.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.        ] real action [  0.  90. 160.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.14464260807907103, -0.42232131298023223, -0.04097713699936867]\n",
      "action: [  0.  83. 166.]\n",
      "pick_success 0\n",
      "dis 7.810249675906654 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.42857143] real action [  0.  83. 166.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.14196403807907104, -0.43035702298023226, -0.053500000000000006]\n",
      "action: [  0.  86. 165.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.35714286] real action [  0.  86. 165.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143  0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.133928328079071, -0.41696417298023225, -0.044248729780316354]\n",
      "action: [  0.  81. 162.]\n",
      "pick_success 0\n",
      "dis 7.280109889280518 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143  0.14285714] real action [  0.  81. 162.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.12053547807907106, -0.4464284429802322, -0.053500000000000006]\n",
      "action: [  0.  92. 157.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.21428571] real action [  0.  92. 157.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.12321404807907105, -0.43571416298023224, -0.053500000000000006]\n",
      "action: [  0.  88. 158.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.14285714] real action [  0.  88. 158.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.133928328079071, -0.4276784529802322, -0.053500000000000006]\n",
      "action: [  0.  85. 162.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714] real action [  0.  85. 162.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.13928546807907105, -0.4464284429802322, -0.053500000000000006]\n",
      "action: [  0.  92. 164.]\n",
      "pick_success 0\n",
      "dis 5.656854249492381 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.28571429] real action [  0.  92. 164.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.12857118807907103, -0.43839273298023224, -0.053500000000000006]\n",
      "action: [  0.  89. 160.]\n",
      "pick_success 0\n",
      "dis 1.0 pick_success 0\n",
      "desired_action : [0, 88, 160] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.        ] real action [  0.  89. 160.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.38839286 0.71428571 0.75       0.76785714 0.51339286 0.18303571\n",
      " 0.23214286 0.19642857 0.76785714 0.42857143 0.20982143 0.45535714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.048214431920928946, -0.37142848298023223, -0.04450913874804974]\n",
      "action: [ 0. 64. 94.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 70, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.21428571] real action [ 0. 64. 94.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.3125     0.43303571 0.39732143 0.68303571 0.79910714 0.80357143\n",
      " 0.59821429 0.39732143 0.17410714 0.13392857 0.8125     0.25892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.050893001920928965, -0.36607134298023225, -0.03973257897794247]\n",
      "action: [ 0. 62. 93.]\n",
      "pick_success 1\n",
      "dis 8.94427190999916 pick_success 1\n",
      "desired_action : [0, 70, 97] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.28571429] real action [ 0. 62. 93.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.04464286 0.51339286 0.39732143 0.68303571 0.79910714 0.80357143\n",
      " 0.59821429 0.39732143 0.17410714 0.13392857 0.8125     0.25892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.92857143 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.23303576192092895, -0.26964282298023223, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 39, 30] phase_loss 0.0 dis_reward -0.00388\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.92857143 -0.35714286] real action [ 1. 26. 25.]\n",
      "reward 0.99612 done:  True\n",
      "observation: [0.14732143 0.13392857 0.39732143 0.68303571 0.79910714 0.80357143\n",
      " 0.59821429 0.39732143 0.17410714 0.13392857 0.8125     0.25892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.10982119807907104, -0.5749998029802322, -0.039485052064061166]\n",
      "action: [  0. 140. 153.]\n",
      "pick_success 0\n",
      "dis 6.4031242374328485 pick_success 0\n",
      "desired_action : [0, 144, 148] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.35714286] real action [  0. 140. 153.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.39285714 0.62053571 0.57589286 0.40625    0.64285714 0.66071429\n",
      " 0.33928571 0.26785714 0.16964286 0.77678571 0.74553571 0.13392857] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.35714286]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.10982119807907104, -0.5857140829802322, -0.053500000000000006]\n",
      "action: [  0. 144. 153.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 144, 148] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.35714286] real action [  0. 144. 153.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.39285714 0.62053571 0.57589286 0.40625    0.64285714 0.66071429\n",
      " 0.33928571 0.26785714 0.16964286 0.77678571 0.74553571 0.13392857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.07142857]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.09374977807907103, -0.5857140829802322, -0.03804491071403027]\n",
      "action: [  0. 144. 147.]\n",
      "pick_success 1\n",
      "dis 1.4142135623730951 pick_success 1\n",
      "desired_action : [0, 145, 148] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.07142857] real action [  0. 144. 147.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.39285714 0.62053571 0.57589286 0.40625    0.01339286 0.5\n",
      " 0.33928571 0.26785714 0.16964286 0.77678571 0.74553571 0.13392857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.         -0.07142857]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping: place [-0.22232148192092896, -0.6473211929802323, 0.023624799191951755]\n",
      "place_xyz[2] 0.023624799191951755 False\n",
      "desired_action : [1, 167, 30] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.         -0.07142857] real action [  1. 167.  29.]\n",
      "reward 0.99998 done:  True\n",
      "observation: [0.39285714 0.62053571 0.57589286 0.40625    0.74553571 0.13839286\n",
      " 0.33928571 0.26785714 0.16964286 0.77678571 0.74553571 0.13392857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5        -0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.04285694807907103, -0.28571424298023224, -0.04085775262117386]\n",
      "action: [  0.  32. 128.]\n",
      "pick_success 0\n",
      "dis 7.615773105863909 pick_success 0\n",
      "desired_action : [0, 39, 131] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5        -0.21428571] real action [  0.  32. 128.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.41517857 0.17410714 0.58482143 0.39732143 0.36607143\n",
      " 0.59375    0.79017857 0.29464286 0.77678571 0.60267857 0.125     ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.06160693807907103, -0.30178566298023224, -0.040395617321133614]\n",
      "action: [  0.  38. 135.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 39, 131] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.28571429] real action [  0.  38. 135.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.41517857 0.17410714 0.58482143 0.39732143 0.36607143\n",
      " 0.59375    0.79017857 0.29464286 0.77678571 0.60267857 0.125     ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.045535518079071025, -0.30982137298023227, -0.053500000000000006]\n",
      "action: [  0.  41. 129.]\n",
      "pick_success 0\n",
      "dis 2.8284271247461903 pick_success 0\n",
      "desired_action : [0, 39, 131] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.14285714] real action [  0.  41. 129.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.41517857 0.17410714 0.58482143 0.39732143 0.36607143\n",
      " 0.59375    0.79017857 0.29464286 0.77678571 0.60267857 0.125     ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.06160693807907103, -0.29910709298023225, -0.04273996485769749]\n",
      "action: [  0.  37. 135.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 39, 131] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.28571429] real action [  0.  37. 135.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.66964286 0.41517857 0.17410714 0.58482143 0.39732143 0.36607143\n",
      " 0.59375    0.79017857 0.29464286 0.77678571 0.60267857 0.125     ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.5        -0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.045535518079071025, -0.3232142229802322, -0.04010774178802967]\n",
      "action: [  0.  46. 129.]\n",
      "pick_success 1\n",
      "dis 7.280109889280518 pick_success 1\n",
      "desired_action : [0, 39, 131] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.5        -0.14285714] real action [  0.  46. 129.]\n",
      "reward 0.0 done:  False\n",
      "observation: [ 0.66964286  0.41517857 -0.02678571  0.50892857  0.39732143  0.36607143\n",
      "  0.59375     0.79017857  0.29464286  0.77678571  0.60267857  0.125     ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.17946401807907103, -0.5482141029802322, 0.025952971518039707]\n",
      "place_xyz[2] 0.025952971518039707 False\n",
      "desired_action : [1, 133, 177] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.14285714] real action [  1. 130. 179.]\n",
      "reward 0.99974 done:  True\n",
      "observation: [0.66964286 0.41517857 0.54017857 0.8125     0.39732143 0.36607143\n",
      " 0.59375    0.79017857 0.29464286 0.77678571 0.60267857 0.125     ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.   0.   0.   1.   0.   0.   0.  -0.5  0. ]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.152678318079071, -0.5964283629802323, -0.03721426224708557]\n",
      "pick_success 0\n",
      "dis 7.0 pick_success 0\n",
      "desired_action : [0, 155, 169] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.   0.   0.   1.   0.   0.   0.  -0.5  0. ] real action [  0. 148. 169.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.63392857 0.50446429 0.34375    0.41071429 0.69196429 0.75446429\n",
      " 0.56696429 0.13392857 0.83035714 0.19196429 0.24553571 0.76339286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.14285714]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping pick:  [0.15803545807907105, -0.6044640729802322, -0.039487041369080544]\n",
      "action: [  0. 151. 171.]\n",
      "pick_success 1\n",
      "dis 4.47213595499958 pick_success 1\n",
      "desired_action : [0, 155, 169] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.14285714] real action [  0. 151. 171.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.63392857 0.50446429 0.34375    0.41071429 0.03571429 0.48660714\n",
      " 0.56696429 0.13392857 0.83035714 0.19196429 0.24553571 0.76339286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.35714286 -0.35714286]\n",
      "lang goal put the Letter R on a yellow bowl\n",
      "steping: place [-0.23303576192092895, -0.5535712429802322, 0.023147478677332405]\n",
      "place_xyz[2] 0.023147478677332405 False\n",
      "desired_action : [1, 127, 30] phase_loss 0.0 dis_reward -0.001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.35714286 -0.35714286] real action [  1. 132.  25.]\n",
      "reward 0.999 done:  True\n",
      "observation: [0.63392857 0.50446429 0.34375    0.41071429 0.60714286 0.10267857\n",
      " 0.56696429 0.13392857 0.83035714 0.19196429 0.24553571 0.76339286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.07500013192092897, -0.5749998029802322, -0.03825593164563179]\n",
      "action: [  0. 140.  84.]\n",
      "pick_success 1\n",
      "dis 2.23606797749979 pick_success 1\n",
      "desired_action : [0, 141, 82] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  0. 140.  84.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.8125     0.1875     0.25892857 0.22321429 0.01785714 0.48660714\n",
      " 0.35714286 0.67857143 0.60714286 0.58035714 0.77678571 0.79017857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.07142857 0.71428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.07499978807907104, -0.5669640929802322, 0.025286379247903827]\n",
      "place_xyz[2] 0.025286379247903827 False\n",
      "desired_action : [1, 136, 130] phase_loss 0.0 dis_reward -0.0020200000000000005\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.07142857 0.71428571] real action [  1. 137. 140.]\n",
      "reward 0.99798 done:  True\n",
      "observation: [0.8125     0.1875     0.25892857 0.22321429 0.61160714 0.62053571\n",
      " 0.35714286 0.67857143 0.60714286 0.58035714 0.77678571 0.79017857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.42857143]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.19821400807907102, -0.30446423298023223, -0.045868966564536096]\n",
      "action: [  0.  39. 186.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 42, 180] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.42857143] real action [  0.  39. 186.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.80357143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.19017829807907105, -0.32053565298023223, -0.053500000000000006]\n",
      "action: [  0.  45. 183.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 42, 180] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571] real action [  0.  45. 183.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.80357143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.57142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.16071402807907104, -0.3071428029802322, -0.053500000000000006]\n",
      "action: [  0.  40. 172.]\n",
      "pick_success 0\n",
      "dis 8.246211251235321 pick_success 0\n",
      "desired_action : [0, 42, 180] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.57142857] real action [  0.  40. 172.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.80357143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.19017829807907105, -0.30982137298023227, -0.053500000000000006]\n",
      "action: [  0.  41. 183.]\n",
      "pick_success 0\n",
      "dis 4.242640687119285 pick_success 0\n",
      "desired_action : [0, 44, 180] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571] real action [  0.  41. 183.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.80357143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.17946401807907103, -0.3071428029802322, -0.053500000000000006]\n",
      "action: [  0.  40. 179.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 44, 180] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.07142857] real action [  0.  40. 179.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.80357143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143  0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.184821158079071, -0.29642852298023226, -0.042348062455654145]\n",
      "action: [  0.  36. 181.]\n",
      "pick_success 0\n",
      "dis 8.06225774829855 pick_success 0\n",
      "desired_action : [0, 44, 180] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143  0.07142857] real action [  0.  36. 181.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.80357143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.17946401807907103, -0.3124999429802322, -0.053500000000000006]\n",
      "action: [  0.  42. 179.]\n",
      "pick_success 0\n",
      "dis 2.23606797749979 pick_success 0\n",
      "desired_action : [0, 44, 180] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.07142857] real action [  0.  42. 179.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.80357143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.17410687807907105, -0.31785708298023224, -0.053500000000000006]\n",
      "action: [  0.  44. 177.]\n",
      "pick_success 0\n",
      "dis 4.0 pick_success 0\n",
      "desired_action : [0, 44, 181] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.21428571] real action [  0.  44. 177.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.1875     0.80357143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.5         0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.19017829807907105, -0.2937499529802322, -0.042099855676293374]\n",
      "action: [  0.  35. 183.]\n",
      "pick_success 1\n",
      "dis 10.44030650891055 pick_success 1\n",
      "desired_action : [0, 45, 180] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.5         0.21428571] real action [  0.  35. 183.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.04464286 0.49107143 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.042857291920928964, -0.5455355329802323, 0.02218614795804024]\n",
      "place_xyz[2] 0.02218614795804024 False\n",
      "desired_action : [1, 133, 97] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429 -0.07142857] real action [  1. 129.  96.]\n",
      "reward 0.99966 done:  True\n",
      "observation: [0.60714286 0.41517857 0.67410714 0.23214286 0.46875    0.74553571\n",
      " 0.18303571 0.30357143 0.59375    0.43303571 0.76785714 0.77678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.15803545807907105, -0.4089284629802322, -0.042130367666482926]\n",
      "action: [  0.  78. 171.]\n",
      "pick_success 1\n",
      "dis 4.0 pick_success 1\n",
      "desired_action : [0, 82, 171] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.        ] real action [  0.  78. 171.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.48214286 0.50446429 0.02678571 0.5        0.71875    0.31696429\n",
      " 0.21428571 0.42857143 0.62946429 0.70982143 0.32142857 0.20089286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429 -0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.11517833807907102, -0.5669640929802322, 0.019164369419217113]\n",
      "place_xyz[2] 0.019164369419217113 False\n",
      "desired_action : [1, 141, 159] phase_loss 0.0 dis_reward -0.00064\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429 -0.28571429] real action [  1. 137. 155.]\n",
      "reward 0.99936 done:  True\n",
      "observation: [0.48214286 0.50446429 0.625      0.69196429 0.71875    0.31696429\n",
      " 0.21428571 0.42857143 0.62946429 0.70982143 0.32142857 0.20089286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.17946436192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "action: [  0. 141.  45.]\n",
      "pick_success 0\n",
      "dis 5.656854249492381 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.28571429] real action [  0. 141.  45.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.18482150192092894, -0.5883926529802322, -0.053500000000000006]\n",
      "action: [  0. 145.  43.]\n",
      "pick_success 0\n",
      "dis 6.0 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.42857143] real action [  0. 145.  43.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15803580192092895, -0.5937497929802322, -0.053500000000000006]\n",
      "action: [  0. 147.  53.]\n",
      "pick_success 0\n",
      "dis 4.47213595499958 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.28571429] real action [  0. 147.  53.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5964283629802323, -0.044670402839779855]\n",
      "action: [  0. 148.  54.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.35714286] real action [  0. 148.  54.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.18214293192092895, -0.5776783729802322, -0.053500000000000006]\n",
      "action: [  0. 141.  44.]\n",
      "pick_success 0\n",
      "dis 6.4031242374328485 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.35714286] real action [  0. 141.  44.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.42857143 0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15803580192092895, -0.6044640729802322, -0.040654897525906564]\n",
      "action: [  0. 151.  53.]\n",
      "pick_success 0\n",
      "dis 7.211102550927978 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.42857143 0.28571429] real action [  0. 151.  53.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.17410722192092895, -0.5883926529802322, -0.053500000000000006]\n",
      "action: [  0. 145.  47.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.         -0.14285714] real action [  0. 145.  47.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16875008192092897, -0.5803569429802322, -0.053500000000000006]\n",
      "action: [  0. 142.  49.]\n",
      "pick_success 0\n",
      "dis 3.0 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.        ] real action [  0. 142.  49.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15803580192092895, -0.5803569429802322, -0.053500000000000006]\n",
      "action: [  0. 142.  53.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.28571429] real action [  0. 142.  53.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5910712229802322, -0.053500000000000006]\n",
      "action: [  0. 146.  54.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.35714286] real action [  0. 146.  54.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16875008192092897, -0.5776783729802322, -0.053500000000000006]\n",
      "action: [  0. 141.  49.]\n",
      "pick_success 0\n",
      "dis 4.0 pick_success 0\n",
      "desired_action : [0, 145, 49] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.        ] real action [  0. 141.  49.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.18303571 0.53125    0.51785714 0.6875     0.64732143 0.21875\n",
      " 0.39732143 0.31696429 0.80357143 0.38839286 0.78125    0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.07142857]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.11249976807907103, -0.5508926729802321, -0.04115937075018883]\n",
      "action: [  0. 131. 154.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 128, 155] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 2\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.07142857] real action [  0. 131. 154.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.625      0.27232143 0.40178571 0.44196429 0.         0.5\n",
      " 0.17857143 0.27232143 0.23214286 0.73660714 0.83035714 0.43303571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.5        -0.42857143]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping: place [-0.056250141920928975, -0.6794640329802322, 0.02401650042831898]\n",
      "place_xyz[2] 0.02401650042831898 False\n",
      "desired_action : [1, 186, 97] phase_loss 0.0 dis_reward -0.0017000000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.5        -0.42857143] real action [  1. 179.  91.]\n",
      "reward 0.9983 done:  True\n",
      "observation: [0.625      0.27232143 0.40178571 0.44196429 0.78125    0.41071429\n",
      " 0.17857143 0.27232143 0.23214286 0.73660714 0.83035714 0.43303571] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.053571571920928956, -0.3392856429802322, -0.053500000000000006]\n",
      "action: [ 0. 52. 92.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 48, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.07142857] real action [ 0. 52. 92.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.056250141920928975, -0.3258927929802322, -0.053500000000000006]\n",
      "action: [ 0. 47. 91.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 50, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714] real action [ 0. 47. 91.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.050893001920928965, -0.3419642129802323, -0.053500000000000006]\n",
      "action: [ 0. 53. 93.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 51, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.        ] real action [ 0. 53. 93.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5         0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.042857291920928964, -0.30982137298023227, -0.04263489304482937]\n",
      "action: [ 0. 41. 96.]\n",
      "pick_success 0\n",
      "dis 9.486832980505138 pick_success 0\n",
      "desired_action : [0, 50, 93] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5         0.21428571] real action [ 0. 41. 96.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.06428585192092895, -0.3392856429802322, -0.053500000000000006]\n",
      "action: [ 0. 52. 88.]\n",
      "pick_success 0\n",
      "dis 6.708203932499369 pick_success 0\n",
      "desired_action : [0, 49, 94] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.35714286] real action [ 0. 52. 88.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.045535861920928955, -0.3446427829802322, -0.053500000000000006]\n",
      "action: [ 0. 54. 95.]\n",
      "pick_success 0\n",
      "dis 6.0 pick_success 0\n",
      "desired_action : [0, 48, 95] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.14285714] real action [ 0. 54. 95.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.050893001920928965, -0.3392856429802322, -0.053500000000000006]\n",
      "action: [ 0. 52. 93.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 47, 95] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ] real action [ 0. 52. 93.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.05892871192092897, -0.3312499329802322, -0.053500000000000006]\n",
      "action: [ 0. 49. 90.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 47, 95] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571] real action [ 0. 49. 90.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.056250141920928975, -0.33660707298023224, -0.053500000000000006]\n",
      "action: [ 0. 51. 91.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 46, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714] real action [ 0. 51. 91.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.06428585192092895, -0.3392856429802322, -0.04085552862286568]\n",
      "action: [ 0. 52. 88.]\n",
      "pick_success 0\n",
      "dis 10.0 pick_success 0\n",
      "desired_action : [0, 46, 96] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.35714286] real action [ 0. 52. 88.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.042857291920928964, -0.31785708298023224, -0.053500000000000006]\n",
      "action: [ 0. 44. 96.]\n",
      "pick_success 0\n",
      "dis 1.4142135623730951 pick_success 0\n",
      "desired_action : [0, 45, 97] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.21428571] real action [ 0. 44. 96.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.60267857 0.46875    0.21428571 0.41517857 0.76339286 0.66964286\n",
      " 0.72321429 0.12946429 0.31696429 0.65178571 0.36160714 0.14285714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.0026783980790710538, -0.7008925929802322, -0.03793014197051525]\n",
      "action: [  0. 187. 113.]\n",
      "pick_success 1\n",
      "dis 4.0 pick_success 1\n",
      "desired_action : [0, 187, 109] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.28571429] real action [  0. 187. 113.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.54910714 0.69196429 0.00892857 0.47767857 0.5625     0.36160714\n",
      " 0.26339286 0.65625    0.30357143 0.18303571 0.77232143 0.15625   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.21428571 -0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.19553578192092896, -0.3741070529802322, 0.022102400638163093]\n",
      "place_xyz[2] 0.022102400638163093 False\n",
      "desired_action : [1, 68, 41] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.21428571 -0.14285714] real action [ 1. 65. 39.]\n",
      "reward 0.99974 done:  True\n",
      "observation: [0.54910714 0.69196429 0.28571429 0.15625    0.5625     0.36160714\n",
      " 0.26339286 0.65625    0.30357143 0.18303571 0.77232143 0.15625   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.07767835807907103, -0.5642855229802322, -0.036779744386672975]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 141, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.35714286] real action [  0. 136. 141.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.07232121807907105, -0.5749998029802322, -0.053500000000000006]\n",
      "action: [  0. 140. 139.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 141, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571] real action [  0. 140. 139.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.07499978807907104, -0.5857140829802322, -0.053500000000000006]\n",
      "action: [  0. 144. 140.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 141, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.28571429] real action [  0. 144. 140.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.053571228079071054, -0.5910712229802322, -0.04641191831231117]\n",
      "action: [  0. 146. 132.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 141, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.28571429] real action [  0. 146. 132.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.07767835807907103, -0.5749998029802322, -0.053500000000000006]\n",
      "action: [  0. 140. 141.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 141, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.35714286] real action [  0. 140. 141.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.07767835807907103, -0.5857140829802322, -0.053500000000000006]\n",
      "action: [  0. 144. 141.]\n",
      "pick_success 0\n",
      "dis 5.830951894845301 pick_success 0\n",
      "desired_action : [0, 141, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.35714286] real action [  0. 144. 141.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.06428550807907102, -0.5642855229802322, -0.053500000000000006]\n",
      "action: [  0. 136. 136.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 141, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ] real action [  0. 136. 136.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.058928368079071036, -0.5857140829802322, -0.053500000000000006]\n",
      "action: [  0. 144. 134.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 141, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.14285714] real action [  0. 144. 134.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.05089265807907101, -0.5830355129802323, -0.053500000000000006]\n",
      "action: [  0. 143. 131.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 141, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.35714286] real action [  0. 143. 131.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.06964264807907106, -0.5910712229802322, -0.053500000000000006]\n",
      "action: [  0. 146. 138.]\n",
      "pick_success 0\n",
      "dis 5.385164807134504 pick_success 0\n",
      "desired_action : [0, 141, 136] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.14285714] real action [  0. 146. 138.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.058928368079071036, -0.5883926529802322, -0.053500000000000006]\n",
      "action: [  0. 145. 134.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 142, 135] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.14285714] real action [  0. 145. 134.]\n",
      "reward -0.1 done:  True\n",
      "observation: [0.62946429 0.60714286 0.47767857 0.80803571 0.16517857 0.60714286\n",
      " 0.41964286 0.16964286 0.80357143 0.125      0.79910714 0.74553571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.03214266807907101, -0.4758927129802322, -0.03909218853712082]\n",
      "action: [  0. 103. 124.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 106, 125] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857] real action [  0. 103. 124.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.47321429 0.55803571 0.68303571 0.42410714 0.24553571 0.71428571\n",
      " 0.24107143 0.15625    0.74107143 0.66071429 0.80357143 0.13839286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping pick:  [0.04017837807907104, -0.4785712829802322, -0.0378031170219183]\n",
      "action: [  0. 104. 127.]\n",
      "pick_success 1\n",
      "dis 2.8284271247461903 pick_success 1\n",
      "desired_action : [0, 106, 125] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714] real action [  0. 104. 127.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.01785714 0.48660714 0.68303571 0.42410714 0.24553571 0.71428571\n",
      " 0.24107143 0.15625    0.74107143 0.66071429 0.80357143 0.13839286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.21428571 0.14285714]\n",
      "lang goal put the Letter R on a blue bowl\n",
      "steping: place [-0.21160720192092897, -0.6901783129802322, 0.025526668854057792]\n",
      "place_xyz[2] 0.025526668854057792 False\n",
      "desired_action : [1, 180, 31] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.21428571 0.14285714] real action [  1. 183.  33.]\n",
      "reward 0.99974 done:  True\n",
      "observation: [0.82142857 0.13839286 0.68303571 0.42410714 0.24553571 0.71428571\n",
      " 0.24107143 0.15625    0.74107143 0.66071429 0.80357143 0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.09910691807907102, -0.5026784129802322, -0.053500000000000006]\n",
      "action: [  0. 113. 149.]\n",
      "pick_success 0\n",
      "dis 7.211102550927978 pick_success 0\n",
      "desired_action : [0, 107, 145] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.28571429] real action [  0. 113. 149.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.29464286 0.47767857 0.64732143 0.67857143 0.42410714\n",
      " 0.50446429 0.19642857 0.19196429 0.77232143 0.66964286 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.08839263807907105, -0.48928556298023224, -0.053500000000000006]\n",
      "action: [  0. 108. 145.]\n",
      "pick_success 0\n",
      "dis 0.0 pick_success 0\n",
      "desired_action : [0, 108, 145] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.        ] real action [  0. 108. 145.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.29464286 0.47767857 0.64732143 0.67857143 0.42410714\n",
      " 0.50446429 0.19642857 0.19196429 0.77232143 0.66964286 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.08839263807907105, -0.4785712829802322, -0.053500000000000006]\n",
      "action: [  0. 104. 145.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 108, 144] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.        ] real action [  0. 104. 145.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.29464286 0.47767857 0.64732143 0.67857143 0.42410714\n",
      " 0.50446429 0.19642857 0.19196429 0.77232143 0.66964286 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.09642834807907102, -0.4946427029802322, -0.053500000000000006]\n",
      "action: [  0. 110. 148.]\n",
      "pick_success 0\n",
      "dis 4.123105625617661 pick_success 0\n",
      "desired_action : [0, 109, 144] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.21428571] real action [  0. 110. 148.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.29464286 0.47767857 0.64732143 0.67857143 0.42410714\n",
      " 0.50446429 0.19642857 0.19196429 0.77232143 0.66964286 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.08839263807907105, -0.4973212729802322, -0.053500000000000006]\n",
      "action: [  0. 111. 145.]\n",
      "pick_success 0\n",
      "dis 2.0 pick_success 0\n",
      "desired_action : [0, 109, 145] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ] real action [  0. 111. 145.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.24107143 0.29464286 0.47767857 0.64732143 0.67857143 0.42410714\n",
      " 0.50446429 0.19642857 0.19196429 0.77232143 0.66964286 0.77678571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.10178548807907101, -0.4758927129802322, -0.03903917393088341]\n",
      "action: [  0. 103. 150.]\n",
      "pick_success 1\n",
      "dis 9.219544457292887 pick_success 1\n",
      "desired_action : [0, 110, 144] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429  0.35714286] real action [  0. 103. 150.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.24107143 0.29464286 0.04464286 0.47321429 0.67857143 0.42410714\n",
      " 0.50446429 0.19642857 0.19196429 0.77232143 0.66964286 0.77678571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.57142857  0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.17946436192092896, -0.4812498529802322, 0.022275112546980384]\n",
      "place_xyz[2] 0.022275112546980384 False\n",
      "desired_action : [1, 113, 44] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.57142857  0.07142857] real action [  1. 105.  45.]\n",
      "reward 0.9987 done:  True\n",
      "observation: [0.24107143 0.29464286 0.49553571 0.17857143 0.67857143 0.42410714\n",
      " 0.50446429 0.19642857 0.19196429 0.77232143 0.66964286 0.77678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.15803580192092895, -0.6526783329802321, -0.039221634924411775]\n",
      "action: [  0. 169.  53.]\n",
      "pick_success 1\n",
      "dis 4.47213595499958 pick_success 1\n",
      "desired_action : [0, 173, 55] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 1\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714] real action [  0. 169.  53.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.29017857 0.77232143 0.03125    0.5        0.45089286 0.54017857\n",
      " 0.47767857 0.12946429 0.70982143 0.74107143 0.24107143 0.34821429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429  0.57142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.06964299192092896, -0.33392850298023224, 0.020409577503800395]\n",
      "place_xyz[2] 0.020409577503800395 False\n",
      "desired_action : [1, 54, 78] phase_loss 0.0 dis_reward -0.0016\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429  0.57142857] real action [ 1. 50. 86.]\n",
      "reward 0.9984 done:  True\n",
      "observation: [0.29017857 0.77232143 0.24107143 0.39285714 0.45089286 0.54017857\n",
      " 0.47767857 0.12946429 0.70982143 0.74107143 0.24107143 0.34821429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.18214258807907102, -0.5133926929802322, -0.053500000000000006]\n",
      "action: [  0. 117. 180.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.14285714] real action [  0. 117. 180.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53571429 0.8125     0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.20357114807907106, -0.5241069729802322, -0.053500000000000006]\n",
      "action: [  0. 121. 188.]\n",
      "pick_success 0\n",
      "dis 6.082762530298219 pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.42857143] real action [  0. 121. 188.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53571429 0.8125     0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.184821158079071, -0.5294641129802322, -0.053500000000000006]\n",
      "action: [  0. 123. 181.]\n",
      "pick_success 0\n",
      "dis 3.1622776601683795 pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.21428571 -0.07142857] real action [  0. 123. 181.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53571429 0.8125     0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.184821158079071, -0.5348212529802323, -0.053500000000000006]\n",
      "action: [  0. 125. 181.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.07142857] real action [  0. 125. 181.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53571429 0.8125     0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.17410687807907105, -0.5241069729802322, -0.053500000000000006]\n",
      "action: [  0. 121. 177.]\n",
      "pick_success 0\n",
      "dis 5.0990195135927845 pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286] real action [  0. 121. 177.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53571429 0.8125     0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.17678544807907104, -0.5133926929802322, -0.053500000000000006]\n",
      "action: [  0. 117. 178.]\n",
      "pick_success 0\n",
      "dis 5.0 pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429] real action [  0. 117. 178.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53571429 0.8125     0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.17946401807907103, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [  0. 118. 179.]\n",
      "pick_success 0\n",
      "dis 3.605551275463989 pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.21428571] real action [  0. 118. 179.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53571429 0.8125     0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.5       ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.168749738079071, -0.5187498329802323, -0.053500000000000006]\n",
      "action: [  0. 119. 175.]\n",
      "pick_success 0\n",
      "dis 7.0710678118654755 pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0 dis_reward 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.5       ] real action [  0. 119. 175.]\n",
      "reward -0.1 done:  False\n",
      "observation: [0.53571429 0.8125     0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.20089257807907102, -0.5107141229802322, -0.042733259335160256]\n",
      "action: [  0. 116. 187.]\n",
      "pick_success 1\n",
      "dis 7.0710678118654755 pick_success 1\n",
      "desired_action : [0, 121, 182] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.35714286] real action [  0. 116. 187.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.03125    0.47767857 0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.07142857  0.85714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [0.07499978807907104, -0.41696417298023225, 0.025940563507378105]\n",
      "place_xyz[2] 0.025940563507378105 False\n",
      "desired_action : [1, 82, 128] phase_loss 0.0 dis_reward -0.0029000000000000002\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.07142857  0.85714286] real action [  1.  81. 140.]\n",
      "reward 0.9971 done:  True\n",
      "observation: [0.375      0.60267857 0.31696429 0.35714286 0.69196429 0.39732143\n",
      " 0.77232143 0.69642857 0.20089286 0.79017857 0.36607143 0.57142857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.42857143]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.04017837807907104, -0.5937497929802322, -0.04040538875758648]\n",
      "action: [  0. 147. 128.]\n",
      "pick_success 1\n",
      "dis 7.810249675906643 pick_success 1\n",
      "desired_action : [0, 142, 122] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.42857143] real action [  0. 147. 128.]\n",
      "reward 0.0 done:  False\n",
      "observation: [-0.00892857  0.47321429  0.57589286  0.24553571  0.20982143  0.4375\n",
      "  0.55803571  0.78571429  0.25892857  0.71428571  0.27678571  0.12946429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.12857118807907103, -0.3446427829802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 58, 160] phase_loss 0.0 dis_reward -0.0003199999999999989\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429  0.        ] real action [  1.  54. 160.]\n",
      "reward 0.99968 done:  True\n",
      "observation: [0.21428571 0.69196429 0.57589286 0.24553571 0.20982143 0.4375\n",
      " 0.55803571 0.78571429 0.25892857 0.71428571 0.27678571 0.12946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.008035881920928967, -0.36071420298023227, -0.053500000000000006]\n",
      "action: [  0.  60. 109.]\n",
      "pick_success 1\n",
      "dis 3.1622776601683795 pick_success 1\n",
      "desired_action : [0, 63, 110] phase_loss 0.0 dis_reward 0\n",
      "picked_obj 0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857] real action [  0.  60. 109.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.01785714 0.50446429 0.29464286 0.1875     0.63392857 0.54464286\n",
      " 0.55803571 0.1875     0.47321429 0.74553571 0.20535714 0.73660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.57142857 -0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.13928546807907105, -0.4624998629802322, 0.023237066321074966]\n",
      "place_xyz[2] 0.023237066321074966 False\n",
      "desired_action : [1, 106, 167] phase_loss 0.0 dis_reward -0.0014599999999999995\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.57142857 -0.21428571] real action [  1.  98. 164.]\n",
      "reward 0.99854 done:  True\n",
      "observation: [0.44196429 0.74553571 0.29464286 0.1875     0.63392857 0.54464286\n",
      " 0.55803571 0.1875     0.47321429 0.74553571 0.20535714 0.73660714] [False]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "success = 0# 97%\n",
    "trial = 100\n",
    "steps = []\n",
    "# RL_success 0.02\n",
    "# step2 0.0\n",
    "# step3 0.0\n",
    "# step4 0.01\n",
    "# step10 0.0\n",
    "# step11 0.98\n",
    "for seed in range(trial):\n",
    "    np.random.seed(seed)\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        action = env.get_expert_demonstration()\n",
    "        # action[-2:]=[0,0]\n",
    "        print(action)\n",
    "        obs, rewards, done,_, info = env.step(action)\n",
    "        step += 1\n",
    "        if done:\n",
    "            steps.append(step)\n",
    "            if rewards >= 0.95:\n",
    "                success += 1\n",
    "            print(\"done\")\n",
    "            break\n",
    "RL_success = success/trial\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL_success 0.82\n",
      "mean 5.38\n",
      "step2 0.34\n",
      "step3 0.15\n",
      "step4 0.06\n",
      "step10 0.05\n",
      "step11 0.19\n"
     ]
    }
   ],
   "source": [
    "print(\"RL_success\",RL_success)\n",
    "step2 = steps.count(2)/len(steps)\n",
    "step3 = steps.count(3)/len(steps)\n",
    "step4 = steps.count(4)/len(steps)\n",
    "step10 = steps.count(10)/len(steps)\n",
    "step11 = steps.count(11)/len(steps)\n",
    "print(\"mean\",np.mean(steps))\n",
    "print(\"step2\",step2)\n",
    "print(\"step3\",step3)\n",
    "print(\"step4\",step4)\n",
    "print(\"step10\",step10)\n",
    "print(\"step11\",step11)\n",
    "# stochastic\n",
    "# RL_success 0.98\n",
    "# mean 2.91\n",
    "# step2 0.69\n",
    "# step3 0.13\n",
    "# step4 0.04\n",
    "# step10 0.01\n",
    "# step11 0.02\n",
    "# deterministic\n",
    "# RL_success 0.79\n",
    "# mean 4.24\n",
    "# step2 0.69\n",
    "# step3 0.03\n",
    "# step4 0.01\n",
    "# step10 0.0\n",
    "# step11 0.22"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cliport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e285e3189e2c3705550e6f1561542eb0bf2036e0fba5138d48bba9b73467e388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
