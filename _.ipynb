{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T08:43:51.458201464Z",
     "start_time": "2023-09-19T08:43:48.244012830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n",
      "2023-11-30 14:08:50.859116: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-30 14:08:50.892725: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 14:08:51.962192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from environments.pickplace_environment_residual import ResPickOrPlaceEnvWithoutLangReward\n",
    "from tasks.letter import PutLetterOontheBowl,PutLetterontheBowlUnseen,PutLetterontheBowl,PutLetterontheBowlUnseenLetters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from agents.LLMRL import LLMSAC,GuideSAC\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from reward.detector import VILD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/marunyu/Data/study/DELFT/master_thesis/RA/reward/detector.py:24: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.saved_model.load` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 13:56:52.979393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.984139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.984245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.985924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.986082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.986174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.986363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.986468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.986566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 13:56:52.986651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3359 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./reward/image_path_v2/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 13:56:53.779328: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, -239876894713232437), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 3522297856, 8030175455215105088)]\n"
     ]
    }
   ],
   "source": [
    "vild = VILD()\n",
    "print(vild.session.list_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_bbox_category(found_obj,scores,category):\n",
    "    scores = scores[:,1:]\n",
    "    unoccupied_cata = np.arange(len(category))\n",
    "    unoccupied_obj = np.arange(len(found_obj))\n",
    "    new_found_obj = []\n",
    "    while len(unoccupied_cata) > 0 and len(unoccupied_obj) > 0:\n",
    "        mask = np.zeros_like(scores)\n",
    "        mask[np.ix_(unoccupied_obj,unoccupied_cata)] = 1\n",
    "        cur_score =  np.where(mask,scores,0)\n",
    "        # get max score position\n",
    "        max_idx = np.unravel_index(np.argmax(cur_score, axis=None), cur_score.shape)\n",
    "        obj = found_obj[max_idx[0]]\n",
    "        bbox = obj[2]\n",
    "        w,h = bbox[2]-bbox[0],bbox[3]-bbox[1]\n",
    "        area = w*h\n",
    "        if area > 6000 or w>100 or h>100:\n",
    "            unoccupied_obj = unoccupied_obj[unoccupied_obj!=max_idx[0]]\n",
    "            continue\n",
    "        else:\n",
    "            obj = (category[max_idx[1]],found_obj[max_idx[0]][1],found_obj[max_idx[0]][2],scores[max_idx[0],max_idx[1]])\n",
    "            new_found_obj.append(obj)\n",
    "            # remove the row and column\n",
    "            # print('remove',max_idx,cur_score[max_idx[0],max_idx[1]])\n",
    "            unoccupied_obj = unoccupied_obj[unoccupied_obj!=max_idx[0]]\n",
    "            unoccupied_cata = unoccupied_cata[unoccupied_cata!=max_idx[1]]\n",
    "    return new_found_obj\n",
    "def visuallizre_res(img,found_obj,scores):\n",
    "    for obj in found_obj:\n",
    "        if obj[0].split(\" \")[1] == \"bowl\":\n",
    "            rec_color =(0, 255, 0)\n",
    "        else:\n",
    "            rec_color =(0, 0, 255)\n",
    "        y_min,x_min,y_max,x_max = obj[2]\n",
    "        img = cv2.rectangle(img,(x_min, y_min), (x_max, y_max),rec_color , 2,)\n",
    "        img = cv2.putText(img, obj[0], (x_min, (y_min+y_max)//2), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    # plot matrix score_all\n",
    "    plt.imshow(scores, cmap='viridis')  # 'cmap' parameter defines the colormap\n",
    "    plt.colorbar() \n",
    "    m,n = scores.shape\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            text = plt.text(j, i, f'{scores[i, j]:.2f}',\n",
    "                            ha=\"center\", va=\"center\", color=\"w\")\n",
    "    plt.show()\n",
    "    for obj in found_obj:\n",
    "        print(obj)\n",
    "\n",
    "\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PutLetterOontheBowl' object has no attribute 'category_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb 单元格 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mipywidgets\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m env \u001b[39m=\u001b[39m ResPickOrPlaceEnvWithoutLangReward(\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                         task\u001b[39m=\u001b[39;49m PutLetterOontheBowl,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                         image_obs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                         residual\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                         observation_noise\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                         render\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                         multi_discrete\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                         scale_action\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                         ee\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msuction\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                         scale_obs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                         neglect_steps\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                                         one_hot_action \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_image\u001b[39m(seed\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/marunyu/Data/study/DELFT/master_thesis/RA/_.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(seed)\n",
      "File \u001b[0;32m/media/marunyu/Data/study/DELFT/master_thesis/RA/environments/pickplace_environment_residual.py:50\u001b[0m, in \u001b[0;36mResPickOrPlaceEnvWithoutLangReward.__init__\u001b[0;34m(self, task, residual, image_obs, observation_noise, vlm, multi_discrete, scale_obs, scale_action, neglect_steps, ee, render, one_hot_action)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mreward\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdetector\u001b[39;00m \u001b[39mimport\u001b[39;00m VILD\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvlm \u001b[39m=\u001b[39m VILD()\n\u001b[0;32m---> 50\u001b[0m obj_num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask\u001b[39m.\u001b[39;49mcategory_names)\n\u001b[1;32m     51\u001b[0m goal_num \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mgoal_num\n\u001b[1;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone_hot_action \u001b[39m=\u001b[39m one_hot_action\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PutLetterOontheBowl' object has no attribute 'category_names'"
     ]
    }
   ],
   "source": [
    "import ipywidgets\n",
    "env = ResPickOrPlaceEnvWithoutLangReward(\n",
    "                                        task= PutLetterOontheBowl,\n",
    "                                        image_obs=True,\n",
    "                                        residual=True,\n",
    "                                        observation_noise=5,\n",
    "                                        render=False,\n",
    "                                        multi_discrete=False,\n",
    "                                        scale_action=True,\n",
    "                                        ee=\"suction\",\n",
    "                                        scale_obs=True,\n",
    "                                        neglect_steps=False,\n",
    "                                        one_hot_action = True)\n",
    "def show_image(seed=1):\n",
    "    np.random.seed(seed)\n",
    "    env.reset()\n",
    "    img = env.get_image()\n",
    "\n",
    "    image_path = \"tmp/images/PutLetterOontheBowl_step0_seed{}.png\".format(seed)\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(image_path, image)\n",
    "\n",
    "    catagory = [\n",
    "        \"yellow bowl\",\"green bowl\",\"blue bowl\",\n",
    "        \"yellow o shape block\",\"blue o shape block\", \"green o shape block\"]\n",
    "    found_obj,scores,image_det = vild.vild_detect(image_path,catagory,verbose= False)\n",
    "    found_obj = match_bbox_category(found_obj,scores,catagory)\n",
    "    \n",
    "                        \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    visuallizre_res(img,found_obj,scores)\n",
    "    \n",
    "ipywidgets.interact(show_image, seed=(0, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/marunyu/Data/study/DELFT/master_thesis/RA/venv/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:590: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 12.05GB > 7.02GB\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model =LLMSAC.load(\"tmp/llmsac_imgatten_withnoise15.0fixedPutLetterontheBowl_model_arch/rl_model_65000_steps.zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) UHD Graphics (TGL GT1)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 23.0.4-0ubuntu1~22.04.1\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 23.0.4-0ubuntu1~22.04.1\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) UHD Graphics (TGL GT1)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[0.00809538 0.19166946 0.3327887  0.98760843 0.40085638 0.34459805\n",
      " 0.30573088 0.07944274 0.10263133]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.17946436192092896, -0.6660711829802322, -0.03787498904764652]\n",
      "action: [8.09538364e-03 1.74112198e+02 4.54368386e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 174, 48] phase_loss 0.0014241351173998966 dis_reward -0.00013164769390245967\n",
      "picked_obj 2\n",
      "87 22\n",
      "action  [0.00809538 0.19166946 0.3327887  0.98760843 0.40085638 0.34459805\n",
      " 0.30573088 0.07944274 0.10263133] real action [8.09538364e-03 1.74112198e+02 4.54368386e+01]\n",
      "reward -0.0015557828113023564 done:  False\n",
      "observation: [0.36160714 0.52232143 0.58035714 0.79910714 0.03571429 0.5\n",
      " 0.29017857 0.14732143 0.29910714 0.78125    0.80803571 0.58928571] [ True]\n",
      "[0.9922621  0.0309822  0.00938621 0.34699482 0.03157192 0.09897757\n",
      " 0.98936695 0.16424584 0.21861732]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.06160693807907103, -0.6901783129802322, 0.023913039803504947]\n",
      "place_xyz[2] 0.023913039803504947 False\n",
      "desired_action : [1, 178, 132] phase_loss 0.001352135389325294 dis_reward -0.0007490323188007154\n",
      "action  [0.9922621  0.0309822  0.00938621 0.34699482 0.03157192 0.09897757\n",
      " 0.98936695 0.16424584 0.21861732] real action [  0.99226213 183.29944181 135.06064248]\n",
      "reward 0.997898832291874 done:  True\n",
      "observation: [0.36160714 0.52232143 0.58035714 0.79910714 0.78571429 0.59821429\n",
      " 0.29017857 0.14732143 0.29910714 0.78125    0.80803571 0.58928571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00731957  0.09009528  0.93046546  0.09529734  0.10667104  0.12586683\n",
      "  0.06082207 -0.685569    0.193928  ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.20357149192092897, -0.5562498129802322, -0.053500000000000006]\n",
      "action: [7.31956959e-03 1.33402034e+02 3.67149920e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 142, 37] phase_loss 0.0012679245192986702 dis_reward -0.0014801250441887036\n",
      "action  [ 0.00731957  0.09009528  0.93046546  0.09529734  0.10667104  0.12586683\n",
      "  0.06082207 -0.685569    0.193928  ] real action [7.31956959e-03 1.33402034e+02 3.67149920e+01]\n",
      "reward -0.0027480495634873738 done:  False\n",
      "observation: [0.36160714 0.44196429 0.63839286 0.15178571 0.1875     0.70982143\n",
      " 0.45982143 0.77232143 0.34375    0.13392857 0.78571429 0.45535714] [False]\n",
      "[ 0.00642014  0.0854896   0.92837584  0.07032877  0.10697305  0.12822318\n",
      "  0.03686357 -0.83997244  0.24023926]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.20089292192092895, -0.5508926729802321, -0.053500000000000006]\n",
      "action: [6.42013550e-03 1.31240386e+02 3.73633497e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 142, 37] phase_loss 0.0010869755453006597 dis_reward -0.002318026324356271\n",
      "action  [ 0.00642014  0.0854896   0.92837584  0.07032877  0.10697305  0.12822318\n",
      "  0.03686357 -0.83997244  0.24023926] real action [6.42013550e-03 1.31240386e+02 3.73633497e+01]\n",
      "reward -0.0034050018696569306 done:  False\n",
      "observation: [0.36160714 0.44196429 0.63839286 0.15178571 0.1875     0.70982143\n",
      " 0.45982143 0.77232143 0.34375    0.13392857 0.78571429 0.45535714] [False]\n",
      "[ 0.00642014  0.0854896   0.92837584  0.07032877  0.10697305  0.12822318\n",
      "  0.03686357 -0.83997244  0.24023926]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.20089292192092895, -0.5508926729802321, -0.053500000000000006]\n",
      "action: [6.42013550e-03 1.31240386e+02 3.73633497e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 141, 38] phase_loss 0.0010869755453006597 dis_reward -0.0019131077776796354\n",
      "action  [ 0.00642014  0.0854896   0.92837584  0.07032877  0.10697305  0.12822318\n",
      "  0.03686357 -0.83997244  0.24023926] real action [6.42013550e-03 1.31240386e+02 3.73633497e+01]\n",
      "reward -0.003000083322980295 done:  False\n",
      "observation: [0.36160714 0.44196429 0.63839286 0.15178571 0.1875     0.70982143\n",
      " 0.45982143 0.77232143 0.34375    0.13392857 0.78571429 0.45535714] [False]\n",
      "[ 0.00642014  0.0854896   0.92837584  0.07032877  0.10697305  0.12822318\n",
      "  0.03686357 -0.83997244  0.24023926]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.20089292192092895, -0.5508926729802321, -0.053500000000000006]\n",
      "action: [6.42013550e-03 1.31240386e+02 3.73633497e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 141, 38] phase_loss 0.0010869755453006597 dis_reward -0.0019131077776796354\n",
      "action  [ 0.00642014  0.0854896   0.92837584  0.07032877  0.10697305  0.12822318\n",
      "  0.03686357 -0.83997244  0.24023926] real action [6.42013550e-03 1.31240386e+02 3.73633497e+01]\n",
      "reward -0.003000083322980295 done:  False\n",
      "observation: [0.36160714 0.44196429 0.62053571 0.15178571 0.1875     0.70982143\n",
      " 0.45982143 0.77232143 0.34375    0.13392857 0.78571429 0.45535714] [False]\n",
      "[0.00821388 0.5492615  0.9792392  0.7227278  0.53275514 0.4181466\n",
      " 0.36252397 0.9752712  0.3577808 ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.19553578192092896, -0.6071426429802322, -0.03793082928657532]\n",
      "action: [8.21387768e-03 1.52653797e+02 3.90089312e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 141, 39] phase_loss 0.0014480047022543878 dis_reward -0.002716221355420002\n",
      "picked_obj 1\n",
      "76 19\n",
      "action  [0.00821388 0.5492615  0.9792392  0.7227278  0.53275514 0.4181466\n",
      " 0.36252397 0.9752712  0.3577808 ] real action [8.21387768e-03 1.52653797e+02 3.90089312e+01]\n",
      "reward -0.00416422605767439 done:  False\n",
      "observation: [ 0.36160714  0.44196429 -0.03125     0.5         0.1875      0.70982143\n",
      "  0.45982143  0.77232143  0.34375     0.13392857  0.78571429  0.45535714] [ True]\n",
      "[0.9919077  0.01294133 0.01287588 0.49091676 0.98797977 0.08569548\n",
      " 0.03084618 0.1483829  0.01287067]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.16339259807907103, -0.4812498529802322, 0.025612368226051334]\n",
      "place_xyz[2] 0.025612368226051334 False\n",
      "desired_action : [1, 107, 171] phase_loss 0.0014235108002923558 dis_reward -0.00016899535681669134\n",
      "action  [0.9919077  0.01294133 0.01287588 0.49091676 0.98797977 0.08569548\n",
      " 0.03084618 0.1483829  0.01287067] real action [  0.99190772 105.07736063 173.18018937]\n",
      "reward 0.998407493842891 done:  True\n",
      "observation: [0.36160714 0.44196429 0.41964286 0.76785714 0.1875     0.70982143\n",
      " 0.45982143 0.77232143 0.34375    0.13392857 0.78571429 0.45535714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[0.00838166 0.17709827 0.22091743 0.9860804  0.29796395 0.25434643\n",
      " 0.41733417 0.0151068  0.04760981]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.11785725192092897, -0.44910701298023226, -0.053500000000000006]\n",
      "action: [8.38166475e-03 9.32114952e+01 6.86665373e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 94, 68] phase_loss 0.0014818088120019007 dis_reward -2.1320236662678555e-05\n",
      "action  [0.00838166 0.17709827 0.22091743 0.9860804  0.29796395 0.25434643\n",
      " 0.41733417 0.0151068  0.04760981] real action [8.38166475e-03 9.32114952e+01 6.86665373e+01]\n",
      "reward -0.0015031290486645793 done:  False\n",
      "observation: [0.8125     0.44196429 0.54464286 0.51339286 0.41517857 0.30357143\n",
      " 0.79910714 0.68303571 0.50446429 0.75446429 0.20535714 0.46428571] [False]\n",
      "[0.00838166 0.17709827 0.22091743 0.9860804  0.29796395 0.25434643\n",
      " 0.41733417 0.0151068  0.04760981]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.11785725192092897, -0.44910701298023226, -0.053500000000000006]\n",
      "action: [8.38166475e-03 9.32114952e+01 6.86665373e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 94, 68] phase_loss 0.0014818088120019007 dis_reward -2.1320236662678555e-05\n",
      "picked_obj 2\n",
      "46 34\n",
      "action  [0.00838166 0.17709827 0.22091743 0.9860804  0.29796395 0.25434643\n",
      " 0.41733417 0.0151068  0.04760981] real action [8.38166475e-03 9.32114952e+01 6.86665373e+01]\n",
      "reward -0.0015031290486645793 done:  False\n",
      "observation: [0.8125     0.44196429 0.54464286 0.51339286 0.01785714 0.49107143\n",
      " 0.79910714 0.68303571 0.50446429 0.75446429 0.20535714 0.46428571] [ True]\n",
      "[0.9921591  0.02414319 0.00741524 0.1982376  0.9463037  0.15496784\n",
      " 0.02111182 0.2550099  0.0059756 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.10982119807907104, -0.6874997429802322, 0.021540130466222766]\n",
      "place_xyz[2] 0.021540130466222766 False\n",
      "desired_action : [1, 175, 154] phase_loss 0.0013728755673913572 dis_reward -0.0011629335608627903\n",
      "action  [0.9921591  0.02414319 0.00741524 0.1982376  0.9463037  0.15496784\n",
      " 0.02111182 0.2550099  0.0059756 ] real action [  0.99215913 182.57013845 153.08365846]\n",
      "reward 0.9974641908717459 done:  True\n",
      "observation: [0.8125     0.44196429 0.54464286 0.51339286 0.80803571 0.69196429\n",
      " 0.79910714 0.68303571 0.50446429 0.75446429 0.20535714 0.46428571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.00645256  0.36797893  0.96377456  0.28379577  0.29851845  0.3883551\n",
      "  0.3357085   0.94743705 -0.04076928]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.14999974807907102, -0.36607134298023225, -0.053500000000000006]\n",
      "action: [6.45256042e-03 6.22641182e+01 1.68429230e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 53, 171] phase_loss 0.0010934959779937755 dis_reward -0.0018486548766594231\n",
      "action  [ 0.00645256  0.36797893  0.96377456  0.28379577  0.29851845  0.3883551\n",
      "  0.3357085   0.94743705 -0.04076928] real action [6.45256042e-03 6.22641182e+01 1.68429230e+02]\n",
      "reward -0.0029421508546531986 done:  False\n",
      "observation: [0.34821429 0.52678571 0.21875    0.75446429 0.70089286 0.26785714\n",
      " 0.64285714 0.54910714 0.18303571 0.26339286 0.50446429 0.77678571] [False]\n",
      "[ 0.00664485  0.29038748  0.93196183  0.26793057  0.23829901  0.37226903\n",
      "  0.11206299 -0.04192322  0.38077402]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.16607116807907102, -0.32857136298023226, -0.039111042231321336]\n",
      "action: [6.64484501e-03 4.84130749e+01 1.74330836e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 53, 171] phase_loss 0.0011321674715439995 dis_reward -0.0006426870550698393\n",
      "picked_obj 1\n",
      "24 87\n",
      "action  [ 0.00664485  0.29038748  0.93196183  0.26793057  0.23829901  0.37226903\n",
      "  0.11206299 -0.04192322  0.38077402] real action [6.64484501e-03 4.84130749e+01 1.74330836e+02]\n",
      "reward -0.0017748545266138387 done:  False\n",
      "observation: [0.34821429 0.52678571 0.02678571 0.47321429 0.70089286 0.26785714\n",
      " 0.64285714 0.54910714 0.18303571 0.26339286 0.50446429 0.77678571] [ True]\n",
      "[ 0.9927362   0.0057959   0.09751347  0.01504669  0.01831245  0.97387487\n",
      "  0.12637949  0.0749253  -0.00280696]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.14464295192092896, -0.3124999429802322, 0.02272964918613434]\n",
      "place_xyz[2] 0.02272964918613434 False\n",
      "desired_action : [1, 44, 56] phase_loss 0.001256695882867 dis_reward -0.0002514467809229737\n",
      "action  [ 0.9927362   0.0057959   0.09751347  0.01504669  0.01831245  0.97387487\n",
      "  0.12637949  0.0749253  -0.00280696] real action [ 0.99273622 42.04895425 58.96070254]\n",
      "reward 0.99849185733621 done:  True\n",
      "observation: [0.34821429 0.52678571 0.19642857 0.23214286 0.70089286 0.26785714\n",
      " 0.64285714 0.54910714 0.18303571 0.26339286 0.50446429 0.77678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01060197  0.95992994  0.49740398  0.22632408  0.30537248  0.17850727\n",
      "  0.4016611  -0.4859848  -0.28878438]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.184821158079071, -0.45446415298023224, -0.053500000000000006]\n",
      "action: [1.06019676e-02 9.51962128e+01 1.81957019e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 105, 182] phase_loss 0.0019296727397472525 dis_reward -0.0019223218291702687\n",
      "picked_obj 0\n",
      "47 90\n",
      "action  [ 0.01060197  0.95992994  0.49740398  0.22632408  0.30537248  0.17850727\n",
      "  0.4016611  -0.4859848  -0.28878438] real action [1.06019676e-02 9.51962128e+01 1.81957019e+02]\n",
      "reward -0.0038519945689175212 done:  False\n",
      "observation: [0.04910714 0.5        0.6875     0.625      0.54017857 0.33928571\n",
      " 0.17410714 0.69642857 0.1875     0.16964286 0.20535714 0.40625   ] [ True]\n",
      "[ 0.9862164   0.01221547  0.00846878  0.2253828   0.9096784   0.09591466\n",
      "  0.01728797 -0.11100984 -0.15937018]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.10982119807907104, -0.29910709298023225, 0.021483009658753875]\n",
      "place_xyz[2] 0.021483009658753875 False\n",
      "desired_action : [1, 40, 157] phase_loss 0.002573197419233888 dis_reward -0.00033928320519037707\n",
      "action  [ 0.9862164   0.01221547  0.00846878  0.2253828   0.9096784   0.09591466\n",
      "  0.01728797 -0.11100984 -0.15937018] real action [  0.98621643  37.44586229 153.76881742]\n",
      "reward 0.9970875193755757 done:  True\n",
      "observation: [0.1875     0.66071429 0.6875     0.625      0.54017857 0.33928571\n",
      " 0.17410714 0.69642857 0.1875     0.16964286 0.20535714 0.40625   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[ 0.01152369  0.17098534  0.27647582  0.9849154   0.28676927  0.31091422\n",
      "  0.32250133  0.09652936 -0.09770864]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.09642869192092896, -0.6312497729802322, -0.03714136017858982]\n",
      "pick_success 0\n",
      "desired_action : [0, 159, 82] phase_loss 0.002115891890208278 dis_reward -0.0006868741997387192\n",
      "action  [ 0.01152369  0.17098534  0.27647582  0.9849154   0.28676927  0.31091422\n",
      "  0.32250133  0.09652936 -0.09770864] real action [1.15236938e-02 1.61351411e+02 7.66320790e+01]\n",
      "reward -0.0028027660899469973 done:  False\n",
      "observation: [0.26339286 0.32142857 0.5        0.6875     0.71428571 0.34821429\n",
      " 0.70089286 0.75       0.49107143 0.125      0.16964286 0.55357143] [False]\n",
      "[ 0.01142713  0.1682499   0.27542225  0.98492694  0.31153286  0.3500207\n",
      "  0.31799942  0.08458436 -0.0886265 ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.09642869192092896, -0.6312497729802322, -0.03933715245127678]\n",
      "action: [1.14271343e-02 1.61184181e+02 7.67592289e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 159, 82] phase_loss 0.0020963755434731733 dis_reward -0.0006447265556925345\n",
      "picked_obj 2\n",
      "80 38\n",
      "action  [ 0.01142713  0.1682499   0.27542225  0.98492694  0.31153286  0.3500207\n",
      "  0.31799942  0.08458436 -0.0886265 ] real action [1.14271343e-02 1.61184181e+02 7.67592289e+01]\n",
      "reward -0.002741102099165708 done:  False\n",
      "observation: [0.26339286 0.32142857 0.5        0.6875     0.01339286 0.5\n",
      " 0.70089286 0.75       0.49107143 0.125      0.16964286 0.55357143] [ True]\n",
      "[0.99502146 0.00673437 0.3780314  0.3260613  0.4869714  0.9894319\n",
      " 0.08370766 0.7303021  0.24976277]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.21696434192092895, -0.5214284029802323, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 110, 28] phase_loss 0.0007972945989352944 dis_reward -0.002335232761916746\n",
      "action  [0.99502146 0.00673437 0.3780314  0.3260613  0.4869714  0.9894319\n",
      " 0.08370766 0.7303021  0.24976277] real action [  0.99502146 120.22422981  31.49667883]\n",
      "reward 0.996867472639148 done:  True\n",
      "observation: [0.26339286 0.32142857 0.5        0.6875     0.50892857 0.16964286\n",
      " 0.70089286 0.75       0.49107143 0.125      0.16964286 0.55357143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.01014534  0.22505057  0.2860291   0.9871383   0.2266913   0.3874658\n",
      "  0.5444514  -0.00766563  0.16320324]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.01607124807907101, -0.4651784329802322, -0.04057393392920494]\n",
      "action: [1.01453364e-02 9.98926811e+01 1.18284845e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 100, 115] phase_loss 0.0018374823406885421 dis_reward -0.00021603452658608337\n",
      "picked_obj 2\n",
      "49 59\n",
      "action  [ 0.01014534  0.22505057  0.2860291   0.9871383   0.2266913   0.3874658\n",
      "  0.5444514  -0.00766563  0.16320324] real action [1.01453364e-02 9.98926811e+01 1.18284845e+02]\n",
      "reward -0.0020535168672746254 done:  False\n",
      "observation: [0.59821429 0.75       0.42857143 0.23660714 0.02232143 0.48660714\n",
      " 0.19196429 0.54017857 0.66964286 0.38392857 0.16964286 0.26339286] [ True]\n",
      "[0.99343127 0.03140283 0.00940239 0.27855235 0.03424844 0.12693638\n",
      " 0.9893098  0.14520931 0.21654403]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.13392867192092897, -0.3071428029802322, 0.021692450135946277]\n",
      "place_xyz[2] 0.021692450135946277 False\n",
      "desired_action : [1, 41, 62] phase_loss 0.0011168586117380026 dis_reward -1.8724465222404666e-05\n",
      "action  [0.99343127 0.03140283 0.00940239 0.27855235 0.03424844 0.12693638\n",
      " 0.9893098  0.14520931 0.21654403] real action [ 0.99343127 40.03293037 62.03161645]\n",
      "reward 0.9988644169230396 done:  True\n",
      "observation: [0.59821429 0.75       0.42857143 0.23660714 0.16517857 0.25446429\n",
      " 0.19196429 0.54017857 0.66964286 0.38392857 0.16964286 0.26339286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[ 0.01060221  0.20247123  0.20936942  0.9777771   0.46985328  0.19197136\n",
      "  0.39649317 -0.00339633  0.08691025]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-1.7192092893747457e-07, -0.6714283229802323, -0.053500000000000006]\n",
      "action: [1.06022060e-02 1.76952451e+02 1.12216743e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 176, 112] phase_loss 0.0019297208857653163 dis_reward -1.908282604689958e-05\n",
      "picked_obj 2\n",
      "88 56\n",
      "action  [ 0.01060221  0.20247123  0.20936942  0.9777771   0.46985328  0.19197136\n",
      "  0.39649317 -0.00339633  0.08691025] real action [1.06022060e-02 1.76952451e+02 1.12216743e+02]\n",
      "reward -0.001948803711812216 done:  False\n",
      "observation: [0.3125     0.21428571 0.46428571 0.8125     0.02678571 0.48660714\n",
      " 0.28571429 0.58928571 0.81696429 0.74107143 0.51339286 0.37946429] [ True]\n",
      "[ 0.9947048   0.00545949  0.22652474  0.03761876  0.1063295   0.96758974\n",
      "  0.05750003  0.23113441 -0.1780029 ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.136606898079071, -0.6982140229802323, 0.028249784350395206]\n",
      "place_xyz[2] 0.028249784350395206 False\n",
      "desired_action : [1, 183, 167] phase_loss 0.0008608935962555516 dis_reward -0.0004533055769847852\n",
      "action  [ 0.9947048   0.00545949  0.22652474  0.03761876  0.1063295   0.96758974\n",
      "  0.05750003  0.23113441 -0.1780029 ] real action [  0.99470478 186.23588181 163.50795937]\n",
      "reward 0.9986858008267596 done:  True\n",
      "observation: [0.3125     0.21428571 0.46428571 0.8125     0.83035714 0.73660714\n",
      " 0.28571429 0.58928571 0.81696429 0.74107143 0.51339286 0.37946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[ 0.00758758  0.18331254  0.1990568   0.9842553   0.3703239   0.2830843\n",
      "  0.3506897   0.0577184  -0.04416829]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.10178583192092897, -0.6982140229802323, -0.03894996999204159]\n",
      "action: [7.58758187e-03 1.86808058e+02 7.43816439e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 185, 72] phase_loss 0.001321875151158626 dis_reward -0.0001788259943400945\n",
      "picked_obj 2\n",
      "93 37\n",
      "action  [ 0.00758758  0.18331254  0.1990568   0.9842553   0.3703239   0.2830843\n",
      "  0.3506897   0.0577184  -0.04416829] real action [7.58758187e-03 1.86808058e+02 7.43816439e+01]\n",
      "reward -0.0015007011454987204 done:  False\n",
      "observation: [0.17857143 0.74553571 0.49107143 0.74107143 0.02232143 0.46875\n",
      " 0.58482143 0.40625    0.20089286 0.30357143 0.59375    0.14732143] [ True]\n",
      "[0.99180484 0.01912731 0.006787   0.24791455 0.97134113 0.12204123\n",
      " 0.01847214 0.21667242 0.00268614]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.056250141920928975, -0.5589283829802323, 0.024132066383957866]\n",
      "place_xyz[2] 0.024132066383957866 False\n",
      "desired_action : [1, 127, 92] phase_loss 0.0014442343671083636 dis_reward -0.0010079022623136836\n",
      "action  [0.99180484 0.01912731 0.006787   0.24791455 0.97134113 0.12204123\n",
      " 0.01847214 0.21667242 0.00268614] real action [  0.99180484 134.03341389  91.037606  ]\n",
      "reward 0.997547863370578 done:  True\n",
      "observation: [0.17857143 0.74553571 0.49107143 0.74107143 0.58482143 0.36607143\n",
      " 0.58482143 0.40625    0.20089286 0.30357143 0.59375    0.14732143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.00755847  0.25133404  0.9416996   0.46575186  0.13646984  0.34673744\n",
      "  0.06228709 -0.66848105  0.60368   ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.010714108079071027, -0.6285712029802322, -0.053500000000000006]\n",
      "action: [7.55846500e-03 1.60641265e+02 1.16451520e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 167, 111] phase_loss 0.001316013246929763 dis_reward -0.0014030516363268911\n",
      "picked_obj 1\n",
      "80 58\n",
      "action  [ 0.00755847  0.25133404  0.9416996   0.46575186  0.13646984  0.34673744\n",
      "  0.06228709 -0.66848105  0.60368   ] real action [7.55846500e-03 1.60641265e+02 1.16451520e+02]\n",
      "reward -0.0027190648832566542 done:  False\n",
      "observation: [0.49553571 0.16517857 0.03125    0.46875    0.24107143 0.28571429\n",
      " 0.80357143 0.76785714 0.45535714 0.59821429 0.17857143 0.5       ] [ True]\n",
      "[0.99190027 0.00559676 0.12196857 0.01471901 0.01678586 0.9801142\n",
      " 0.08959746 0.02885556 0.02530706]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.058928368079071036, -0.47321414298023223, 0.026132022939622405]\n",
      "place_xyz[2] 0.026132022939622405 False\n",
      "desired_action : [1, 101, 132] phase_loss 0.0014250115658584511 dis_reward -0.0001502775368636833\n",
      "action  [0.99190027 0.00559676 0.12196857 0.01471901 0.01678586 0.9801142\n",
      " 0.08959746 0.02885556 0.02530706] real action [  0.99190027 102.40397787 134.35429883]\n",
      "reward 0.9984247108972779 done:  True\n",
      "observation: [0.49553571 0.16517857 0.46875    0.57142857 0.24107143 0.28571429\n",
      " 0.80357143 0.76785714 0.45535714 0.59821429 0.17857143 0.5       ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01080534  0.95195055  0.48147374  0.17841765  0.297401    0.26294866\n",
      "  0.40242055 -0.42747742 -0.26369977]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.09107120807907104, -0.6687497529802322, -0.03724672256410122]\n",
      "pick_success 0\n",
      "desired_action : [0, 184, 153] phase_loss 0.001970745505354119 dis_reward -0.0025100938109732353\n",
      "action  [ 0.01080534  0.95195055  0.48147374  0.17841765  0.297401    0.26294866\n",
      "  0.40242055 -0.42747742 -0.26369977] real action [1.08053386e-02 1.75015316e+02 1.46308203e+02]\n",
      "reward -0.004480839316327354 done:  False\n",
      "observation: [0.80803571 0.66964286 0.32142857 0.57589286 0.32142857 0.28571429\n",
      " 0.75892857 0.22767857 0.53125    0.79910714 0.55357143 0.41517857] [False]\n",
      "[ 0.01080534  0.95195055  0.48147374  0.17841765  0.297401    0.26294866\n",
      "  0.40242055 -0.42747742 -0.26369977]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.09107120807907104, -0.6687497529802322, -0.034563951030373574]\n",
      "pick_success 0\n",
      "desired_action : [0, 184, 153] phase_loss 0.001970745505354119 dis_reward -0.0025100938109732353\n",
      "action  [ 0.01080534  0.95195055  0.48147374  0.17841765  0.297401    0.26294866\n",
      "  0.40242055 -0.42747742 -0.26369977] real action [1.08053386e-02 1.75015316e+02 1.46308203e+02]\n",
      "reward -0.004480839316327354 done:  False\n",
      "observation: [0.80803571 0.66964286 0.32142857 0.57589286 0.32142857 0.28571429\n",
      " 0.75892857 0.22767857 0.53125    0.79910714 0.55357143 0.41517857] [False]\n",
      "[ 0.01080534  0.95195055  0.48147374  0.17841765  0.297401    0.26294866\n",
      "  0.40242055 -0.42747742 -0.26369977]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.09107120807907104, -0.6687497529802322, -0.03846875189244747]\n",
      "action: [1.08053386e-02 1.75015316e+02 1.46308203e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 184, 153] phase_loss 0.001970745505354119 dis_reward -0.0025100938109732353\n",
      "picked_obj 0\n",
      "87 73\n",
      "action  [ 0.01080534  0.95195055  0.48147374  0.17841765  0.297401    0.26294866\n",
      "  0.40242055 -0.42747742 -0.26369977] real action [1.08053386e-02 1.75015316e+02 1.46308203e+02]\n",
      "reward -0.004480839316327354 done:  False\n",
      "observation: [0.07589286 0.53571429 0.32142857 0.57589286 0.32142857 0.28571429\n",
      " 0.75892857 0.22767857 0.53125    0.79910714 0.55357143 0.41517857] [ True]\n",
      "[ 0.9818827   0.00923708  0.00654304  0.17106885  0.88727     0.09106803\n",
      "  0.01400286 -0.03416604 -0.13807529]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.16875008192092897, -0.6526783329802321, 0.01922166065871716]\n",
      "place_xyz[2] 0.01922166065871716 False\n",
      "desired_action : [1, 173, 53] phase_loss 0.003453100661570891 dis_reward -0.0005513531204949806\n",
      "action  [ 0.9818827   0.00923708  0.00654304  0.17106885  0.88727     0.09106803\n",
      "  0.01400286 -0.03416604 -0.13807529] real action [  0.98188269 169.52167547  49.06694591]\n",
      "reward 0.9959955462179342 done:  True\n",
      "observation: [0.79910714 0.23660714 0.32142857 0.57589286 0.32142857 0.28571429\n",
      " 0.75892857 0.22767857 0.53125    0.79910714 0.55357143 0.41517857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "[ 0.01154169  0.929167    0.46976644  0.20299643  0.3119371   0.20746389\n",
      "  0.2612803  -0.07052308 -0.80953896]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15267866192092897, -0.6821426029802322, -0.0359328275769949]\n",
      "pick_success 0\n",
      "desired_action : [0, 184, 64] phase_loss 0.0021195303333615494 dis_reward -0.0017069345940511156\n",
      "action  [ 0.01154169  0.929167    0.46976644  0.20299643  0.3119371   0.20746389\n",
      "  0.2612803  -0.07052308 -0.80953896] real action [1.15416944e-02 1.80012677e+02 5.56664543e+01]\n",
      "reward -0.003826464927412665 done:  False\n",
      "observation: [0.80803571 0.29910714 0.34821429 0.45982143 0.51339286 0.19196429\n",
      " 0.26339286 0.73660714 0.75       0.60267857 0.20535714 0.20982143] [False]\n",
      "[ 0.01123163  0.92432535  0.47718048  0.21478498  0.28105915  0.21197462\n",
      "  0.2404482  -0.08218485 -0.83107114]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15267866192092897, -0.6794640329802322, -0.036500749945640565]\n",
      "pick_success 0\n",
      "desired_action : [0, 184, 64] phase_loss 0.002056866795396137 dis_reward -0.0018358108624906392\n",
      "action  [ 0.01123163  0.92432535  0.47718048  0.21478498  0.28105915  0.21197462\n",
      "  0.2404482  -0.08218485 -0.83107114] real action [1.12316310e-02 1.79849412e+02 5.53650036e+01]\n",
      "reward -0.003892677657886776 done:  False\n",
      "observation: [0.80803571 0.29910714 0.34821429 0.45982143 0.51339286 0.19196429\n",
      " 0.26339286 0.73660714 0.75       0.60267857 0.20535714 0.20982143] [False]\n",
      "[ 0.01123163  0.92432535  0.47718048  0.21478498  0.28105915  0.21197462\n",
      "  0.2404482  -0.08218485 -0.83107114]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15267866192092897, -0.6794640329802322, -0.03529396077990532]\n",
      "pick_success 0\n",
      "desired_action : [0, 184, 64] phase_loss 0.002056866795396137 dis_reward -0.0018358108624906392\n",
      "action  [ 0.01123163  0.92432535  0.47718048  0.21478498  0.28105915  0.21197462\n",
      "  0.2404482  -0.08218485 -0.83107114] real action [1.12316310e-02 1.79849412e+02 5.53650036e+01]\n",
      "reward -0.003892677657886776 done:  False\n",
      "observation: [0.80803571 0.29910714 0.34821429 0.45982143 0.51339286 0.19196429\n",
      " 0.26339286 0.73660714 0.75       0.60267857 0.20535714 0.20982143] [False]\n",
      "[ 0.01123163  0.92432535  0.47718048  0.21478498  0.28105915  0.21197462\n",
      "  0.2404482  -0.08218485 -0.83107114]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15267866192092897, -0.6794640329802322, -0.037126846447587014]\n",
      "pick_success 0\n",
      "desired_action : [0, 184, 64] phase_loss 0.002056866795396137 dis_reward -0.0018358108624906392\n",
      "action  [ 0.01123163  0.92432535  0.47718048  0.21478498  0.28105915  0.21197462\n",
      "  0.2404482  -0.08218485 -0.83107114] real action [1.12316310e-02 1.79849412e+02 5.53650036e+01]\n",
      "reward -0.003892677657886776 done:  False\n",
      "observation: [0.80803571 0.29910714 0.34821429 0.45982143 0.51339286 0.19196429\n",
      " 0.26339286 0.73660714 0.75       0.60267857 0.20535714 0.20982143] [False]\n",
      "[ 0.01123163  0.92432535  0.47718048  0.21478498  0.28105915  0.21197462\n",
      "  0.2404482  -0.08218485 -0.83107114]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15267866192092897, -0.6794640329802322, -0.03891078552603722]\n",
      "action: [1.12316310e-02 1.79849412e+02 5.53650036e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 184, 64] phase_loss 0.002056866795396137 dis_reward -0.0018358108624906392\n",
      "picked_obj 0\n",
      "89 27\n",
      "action  [ 0.01123163  0.92432535  0.47718048  0.21478498  0.28105915  0.21197462\n",
      "  0.2404482  -0.08218485 -0.83107114] real action [1.12316310e-02 1.79849412e+02 5.53650036e+01]\n",
      "reward -0.003892677657886776 done:  False\n",
      "observation: [0.04017857 0.54017857 0.34821429 0.45982143 0.51339286 0.19196429\n",
      " 0.26339286 0.73660714 0.75       0.60267857 0.20535714 0.20982143] [ True]\n",
      "[ 0.9943279   0.00456193  0.22179031  0.01359743  0.04978815  0.96173555\n",
      "  0.1609      0.13216901 -0.3874184 ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.045535518079071025, -0.6526783329802321, 0.023667090550065044]\n",
      "place_xyz[2] 0.023667090550065044 False\n",
      "desired_action : [1, 170, 137] phase_loss 0.0009366091133562265 dis_reward -0.0011027210656893158\n",
      "action  [ 0.9943279   0.00456193  0.22179031  0.01359743  0.04978815  0.96173555\n",
      "  0.1609      0.13216901 -0.3874184 ] real action [  0.9943279  169.85036612 129.57614231]\n",
      "reward 0.9979606698209544 done:  True\n",
      "observation: [0.78571429 0.59821429 0.34821429 0.45982143 0.51339286 0.19196429\n",
      " 0.26339286 0.73660714 0.75       0.60267857 0.20535714 0.20982143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[0.00742105 0.53147084 0.98032373 0.7627281  0.45900488 0.35076064\n",
      " 0.37911612 0.97981787 0.4055885 ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.17678544807907104, -0.7089283029802322, -0.03648012860119343]\n",
      "pick_success 0\n",
      "desired_action : [0, 182, 172] phase_loss 0.0012883500175782745 dis_reward -0.0024118562272844794\n",
      "action  [0.00742105 0.53147084 0.98032373 0.7627281  0.45900488 0.35076064\n",
      " 0.37911612 0.97981787 0.4055885 ] real action [7.42104650e-03 1.90717450e+02 1.78678239e+02]\n",
      "reward -0.003700206244862754 done:  False\n",
      "observation: [0.32589286 0.25892857 0.8125     0.77232143 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "[0.00752088 0.54489416 0.9801948  0.8202245  0.5477065  0.3881404\n",
      " 0.3852442  0.9797642  0.47334146]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.17946401807907103, -0.7223211529802323, -0.03355242481827736]\n",
      "pick_success 0\n",
      "desired_action : [0, 182, 172] phase_loss 0.0013084476245136419 dis_reward -0.004926312577392037\n",
      "action  [0.00752088 0.54489416 0.9801948  0.8202245  0.5477065  0.3881404\n",
      " 0.3852442  0.9797642  0.47334146] real action [7.52088428e-03 1.95716700e+02 1.79626781e+02]\n",
      "reward -0.0062347602019056795 done:  False\n",
      "observation: [0.32589286 0.25892857 0.8125     0.77232143 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "[0.00752088 0.54489416 0.9801948  0.8202245  0.5477065  0.3881404\n",
      " 0.3852442  0.9797642  0.47334146]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.17946401807907103, -0.7223211529802323, -0.036459041595458985]\n",
      "pick_success 0\n",
      "desired_action : [0, 182, 172] phase_loss 0.0013084476245136419 dis_reward -0.004926312577392037\n",
      "action  [0.00752088 0.54489416 0.9801948  0.8202245  0.5477065  0.3881404\n",
      " 0.3852442  0.9797642  0.47334146] real action [7.52088428e-03 1.95716700e+02 1.79626781e+02]\n",
      "reward -0.0062347602019056795 done:  False\n",
      "observation: [0.32589286 0.25892857 0.8125     0.77232143 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "[0.00752088 0.54489416 0.9801948  0.8202245  0.5477065  0.3881404\n",
      " 0.3852442  0.9797642  0.47334146]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.17946401807907103, -0.7223211529802323, -0.034306291326880456]\n",
      "pick_success 0\n",
      "desired_action : [0, 182, 172] phase_loss 0.0013084476245136419 dis_reward -0.004926312577392037\n",
      "action  [0.00752088 0.54489416 0.9801948  0.8202245  0.5477065  0.3881404\n",
      " 0.3852442  0.9797642  0.47334146] real action [7.52088428e-03 1.95716700e+02 1.79626781e+02]\n",
      "reward -0.0062347602019056795 done:  False\n",
      "observation: [0.32589286 0.25892857 0.8125     0.77232143 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "[0.00752088 0.54489416 0.9801948  0.8202245  0.5477065  0.3881404\n",
      " 0.3852442  0.9797642  0.47334146]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.17946401807907103, -0.7223211529802323, -0.0374747978746891]\n",
      "action: [7.52088428e-03 1.95716700e+02 1.79626781e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 182, 172] phase_loss 0.0013084476245136419 dis_reward -0.004926312577392037\n",
      "picked_obj 1\n",
      "97 89\n",
      "action  [0.00752088 0.54489416 0.9801948  0.8202245  0.5477065  0.3881404\n",
      " 0.3852442  0.9797642  0.47334146] real action [7.52088428e-03 1.95716700e+02 1.79626781e+02]\n",
      "reward -0.0062347602019056795 done:  False\n",
      "observation: [ 0.32589286  0.25892857 -0.05357143  0.46875     0.24553571  0.80357143\n",
      "  0.49107143  0.47767857  0.76339286  0.20982143  0.52232143  0.74107143] [ True]\n",
      "[0.98752165 0.01398432 0.01490322 0.3913855  0.9849161  0.08812982\n",
      " 0.02714041 0.1348325  0.07896304]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.010714451920928958, -0.4973212729802322, 0.023672047980129722]\n",
      "place_xyz[2] 0.023672047980129722 False\n",
      "desired_action : [1, 114, 110] phase_loss 0.002308947270260108 dis_reward -0.0001610239515350861\n",
      "action  [0.98752165 0.01398432 0.01490322 0.3913855  0.9849161  0.08812982\n",
      " 0.02714041 0.1348325  0.07896304] real action [  0.98752165 111.88765502 108.10548258]\n",
      "reward -0.0024699712217951942 done:  False\n",
      "observation: [0.32589286 0.25892857 0.42410714 0.45982143 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "[ 0.03417987  0.00486252  0.9829119   0.93268484  0.704212    0.914869\n",
      "  0.80042946 -0.21749127  0.79882336]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.005356968079071045, -0.4437498729802322, -0.004740098327398301]\n",
      "action: [3.41798663e-02 9.19551222e+01 1.14183527e+02]\n",
      "pick_success 0\n",
      "desired_action : [False, 97, 101] phase_loss 0.006748561058194054 dis_reward -0.003985123513189593\n",
      "action  [ 0.03417987  0.00486252  0.9829119   0.93268484  0.704212    0.914869\n",
      "  0.80042946 -0.21749127  0.79882336] real action [3.41798663e-02 9.19551222e+01 1.14183527e+02]\n",
      "reward -0.010733684571383647 done:  False\n",
      "observation: [0.32589286 0.25892857 0.42410714 0.45982143 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "[ 0.03417987  0.00486252  0.9829119   0.93268484  0.704212    0.914869\n",
      "  0.80042946 -0.21749127  0.79882336]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.005356968079071045, -0.4437498729802322, -0.053500000000000006]\n",
      "action: [3.41798663e-02 9.19551222e+01 1.14183527e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 97, 101] phase_loss 0.006748561058194054 dis_reward -0.003985123513189593\n",
      "action  [ 0.03417987  0.00486252  0.9829119   0.93268484  0.704212    0.914869\n",
      "  0.80042946 -0.21749127  0.79882336] real action [3.41798663e-02 9.19551222e+01 1.14183527e+02]\n",
      "reward 0.9892663154286163 done:  True\n",
      "observation: [0.32589286 0.25892857 0.42410714 0.45982143 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[0.01142067 0.15737677 0.25686342 0.98720837 0.22768044 0.43432653\n",
      " 0.21294594 0.01089144 0.01394856]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.17678579192092897, -0.5883926529802322, -0.053500000000000006]\n",
      "action: [1.14206672e-02 1.45152480e+02 4.61952798e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 142, 43] phase_loss 0.002095068498171073 dis_reward -0.0004029588835149127\n",
      "action  [0.01142067 0.15737677 0.25686342 0.98720837 0.22768044 0.43432653\n",
      " 0.21294594 0.01089144 0.01394856] real action [1.14206672e-02 1.45152480e+02 4.61952798e+01]\n",
      "reward -0.0024980273816859857 done:  False\n",
      "observation: [0.66071429 0.69642857 0.20089286 0.71875    0.64732143 0.20535714\n",
      " 0.25892857 0.15625    0.43303571 0.375      0.74553571 0.38392857] [False]\n",
      "[0.01142067 0.15737677 0.25686342 0.98720837 0.22768044 0.43432653\n",
      " 0.21294594 0.01089144 0.01394856]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.17678579192092897, -0.5883926529802322, -0.053500000000000006]\n",
      "action: [1.14206672e-02 1.45152480e+02 4.61952798e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 142, 43] phase_loss 0.002095068498171073 dis_reward -0.0004029588835149127\n",
      "picked_obj 2\n",
      "72 23\n",
      "action  [0.01142067 0.15737677 0.25686342 0.98720837 0.22768044 0.43432653\n",
      " 0.21294594 0.01089144 0.01394856] real action [1.14206672e-02 1.45152480e+02 4.61952798e+01]\n",
      "reward -0.0024980273816859857 done:  False\n",
      "observation: [0.66071429 0.69642857 0.20089286 0.71875    0.00446429 0.46875\n",
      " 0.25892857 0.15625    0.43303571 0.375      0.74553571 0.38392857] [ True]\n",
      "[0.98943084 0.01922712 0.01071626 0.31356835 0.9813944  0.12581056\n",
      " 0.02901855 0.20272636 0.0134393 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.20625006192092896, -0.36071420298023227, 0.022266305029392246]\n",
      "place_xyz[2] 0.022266305029392246 False\n",
      "desired_action : [1, 59, 37] phase_loss 0.001923046754569157 dis_reward -0.0001332333089626462\n",
      "action  [0.98943084 0.01922712 0.01071626 0.31356835 0.9813944  0.12581056\n",
      " 0.02901855 0.20272636 0.0134393 ] real action [ 0.98943084 60.8381691  35.18815017]\n",
      "reward 0.9979437199364682 done:  True\n",
      "observation: [0.66071429 0.69642857 0.20089286 0.71875    0.22321429 0.14732143\n",
      " 0.25892857 0.15625    0.43303571 0.375      0.74553571 0.38392857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01244313  0.96055263  0.4701025   0.26910612  0.2960506   0.15529323\n",
      "  0.42298657 -0.5596135  -0.23134267]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.0026787419209289842, -0.37142848298023223, -0.03925385496020317]\n",
      "action: [1.24431252e-02 6.41654105e+01 1.11761203e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 71, 114] phase_loss 0.0023018203211473947 dis_reward -0.0010344765458859529\n",
      "picked_obj 0\n",
      "32 55\n",
      "action  [ 0.01244313  0.96055263  0.4701025   0.26910612  0.2960506   0.15529323\n",
      "  0.42298657 -0.5596135  -0.23134267] real action [1.24431252e-02 6.41654105e+01 1.11761203e+02]\n",
      "reward -0.0033362968670333478 done:  False\n",
      "observation: [0.04464286 0.51339286 0.82589286 0.72321429 0.61160714 0.49553571\n",
      " 0.70089286 0.22321429 0.16964286 0.73660714 0.28571429 0.1875    ] [ True]\n",
      "[ 0.9876188   0.01192117  0.00601968  0.28348535  0.93459547  0.08862329\n",
      "  0.02087435 -0.12386942 -0.20918512]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.17410722192092895, -0.6151783529802322, 0.02802825437486172]\n",
      "place_xyz[2] 0.02802825437486172 False\n",
      "desired_action : [1, 156, 48] phase_loss 0.0022892914949822533 dis_reward -2.8025818570786217e-05\n",
      "action  [ 0.9876188   0.01192117  0.00601968  0.28348535  0.93459547  0.08862329\n",
      "  0.02087435 -0.12386942 -0.20918512] real action [  0.9876188  155.26582813  47.07140827]\n",
      "reward 0.997682682686447 done:  True\n",
      "observation: [0.71875    0.22767857 0.82589286 0.72321429 0.61160714 0.49553571\n",
      " 0.70089286 0.22321429 0.16964286 0.73660714 0.28571429 0.1875    ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.00920215  0.2166324   0.27336192  0.9885012   0.22417861  0.4215495\n",
      "  0.5360053  -0.01000178  0.15790987]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.08839263807907105, -0.35267849298023224, -0.053500000000000006]\n",
      "action: [9.20215249e-03 5.78599751e+01 1.45210738e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 57, 145] phase_loss 0.0016471950432855244 dis_reward -1.56793550650141e-05\n",
      "action  [ 0.00920215  0.2166324   0.27336192  0.9885012   0.22417861  0.4215495\n",
      "  0.5360053  -0.01000178  0.15790987] real action [9.20215249e-03 5.78599751e+01 1.45210738e+02]\n",
      "reward -0.0016628743983505385 done:  False\n",
      "observation: [0.71428571 0.72321429 0.60714286 0.20982143 0.25892857 0.63839286\n",
      " 0.3125     0.34375    0.82589286 0.32142857 0.42857143 0.76785714] [False]\n",
      "[ 0.00920215  0.2166324   0.27336192  0.9885012   0.22417861  0.4215495\n",
      "  0.5360053  -0.01000178  0.15790987]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.08839263807907105, -0.35267849298023224, -0.053500000000000006]\n",
      "action: [9.20215249e-03 5.78599751e+01 1.45210738e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 57, 145] phase_loss 0.0016471950432855244 dis_reward -1.56793550650141e-05\n",
      "action  [ 0.00920215  0.2166324   0.27336192  0.9885012   0.22417861  0.4215495\n",
      "  0.5360053  -0.01000178  0.15790987] real action [9.20215249e-03 5.78599751e+01 1.45210738e+02]\n",
      "reward -0.0016628743983505385 done:  False\n",
      "observation: [0.71428571 0.72321429 0.60714286 0.20982143 0.25892857 0.63839286\n",
      " 0.3125     0.34375    0.82589286 0.32142857 0.42857143 0.76785714] [False]\n",
      "[ 0.00920215  0.2166324   0.27336192  0.9885012   0.22417861  0.4215495\n",
      "  0.5360053  -0.01000178  0.15790987]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.08839263807907105, -0.35267849298023224, -0.053500000000000006]\n",
      "action: [9.20215249e-03 5.78599751e+01 1.45210738e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 58, 145] phase_loss 0.0016471950432855244 dis_reward -1.280351082469866e-06\n",
      "picked_obj 2\n",
      "28 72\n",
      "action  [ 0.00920215  0.2166324   0.27336192  0.9885012   0.22417861  0.4215495\n",
      "  0.5360053  -0.01000178  0.15790987] real action [9.20215249e-03 5.78599751e+01 1.45210738e+02]\n",
      "reward -0.0016484753943679944 done:  False\n",
      "observation: [0.71428571 0.72321429 0.60714286 0.20982143 0.00892857 0.49553571\n",
      " 0.3125     0.34375    0.82589286 0.32142857 0.42857143 0.76785714] [ True]\n",
      "[0.99375343 0.02712438 0.00838456 0.28288418 0.03906298 0.12884918\n",
      " 0.988486   0.0978173  0.23048615]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.168749738079071, -0.4598212929802322, 0.02433567398786545]\n",
      "place_xyz[2] 0.02433567398786545 False\n",
      "desired_action : [1, 95, 176] phase_loss 0.001052075666788704 dis_reward -0.00012424170327224258\n",
      "action  [0.99375343 0.02712438 0.00838456 0.28288418 0.03906298 0.12884918\n",
      " 0.988486   0.0978173  0.23048615] real action [  0.99375343  97.36944222 175.22680616]\n",
      "reward 0.998823682629939 done:  True\n",
      "observation: [0.71428571 0.72321429 0.60714286 0.20982143 0.42857143 0.78571429\n",
      " 0.3125     0.34375    0.82589286 0.32142857 0.42857143 0.76785714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[0.00727829 0.19892639 0.25986552 0.98997355 0.20063013 0.41972655\n",
      " 0.5064824  0.03941154 0.05763519]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.16875008192092897, -0.32857136298023226, -0.053500000000000006]\n",
      "action: [7.27829337e-03 4.85517616e+01 4.98068926e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 46, 48] phase_loss 0.0012596169471684833 dis_reward -0.00019552696781618696\n",
      "action  [0.00727829 0.19892639 0.25986552 0.98997355 0.20063013 0.41972655\n",
      " 0.5064824  0.03941154 0.05763519] real action [7.27829337e-03 4.85517616e+01 4.98068926e+01]\n",
      "reward -0.0014551439149846702 done:  False\n",
      "observation: [0.49553571 0.31696429 0.79910714 0.55357143 0.21428571 0.21875\n",
      " 0.52678571 0.57589286 0.29017857 0.77232143 0.76339286 0.73660714] [False]\n",
      "[0.00740722 0.2027199  0.27123952 0.9895805  0.19007063 0.40808612\n",
      " 0.52989924 0.04156137 0.07338297]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.16607151192092895, -0.32857136298023226, -0.040870258420705796]\n",
      "action: [7.40721822e-03 4.85818591e+01 5.00273616e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 45, 49] phase_loss 0.001285566508263491 dis_reward -0.0002777037323668594\n",
      "action  [0.00740722 0.2027199  0.27123952 0.9895805  0.19007063 0.40808612\n",
      " 0.52989924 0.04156137 0.07338297] real action [7.40721822e-03 4.85818591e+01 5.00273616e+01]\n",
      "reward -0.0015632702406303503 done:  False\n",
      "observation: [0.49553571 0.31696429 0.79910714 0.55357143 0.21428571 0.21875\n",
      " 0.52678571 0.57589286 0.29017857 0.77232143 0.76339286 0.73660714] [False]\n",
      "[0.00740722 0.2027199  0.27123952 0.9895805  0.19007063 0.40808612\n",
      " 0.52989924 0.04156137 0.07338297]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.16607151192092895, -0.32857136298023226, -0.04134052975475788]\n",
      "action: [7.40721822e-03 4.85818591e+01 5.00273616e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 45, 49] phase_loss 0.001285566508263491 dis_reward -0.0002777037323668594\n",
      "picked_obj 2\n",
      "24 25\n",
      "action  [0.00740722 0.2027199  0.27123952 0.9895805  0.19007063 0.40808612\n",
      " 0.52989924 0.04156137 0.07338297] real action [7.40721822e-03 4.85818591e+01 5.00273616e+01]\n",
      "reward -0.0015632702406303503 done:  False\n",
      "observation: [0.49553571 0.31696429 0.79910714 0.55357143 0.00446429 0.5\n",
      " 0.52678571 0.57589286 0.29017857 0.77232143 0.76339286 0.73660714] [ True]\n",
      "[0.9919429  0.03502101 0.00732079 0.35683966 0.04887903 0.10741931\n",
      " 0.98995197 0.12619793 0.22177446]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.14999974807907102, -0.6607140429802323, 0.026362255193293098]\n",
      "place_xyz[2] 0.026362255193293098 False\n",
      "desired_action : [1, 171, 168] phase_loss 0.0014164273388374735 dis_reward -6.26494395279519e-05\n",
      "action  [0.9919429  0.03502101 0.00732079 0.35683966 0.04887903 0.10741931\n",
      " 0.98995197 0.12619793 0.22177446] real action [  0.99194288 172.76677108 168.10484242]\n",
      "reward 0.9985209232216345 done:  True\n",
      "observation: [0.49553571 0.31696429 0.79910714 0.55357143 0.74553571 0.71875\n",
      " 0.52678571 0.57589286 0.29017857 0.77232143 0.76339286 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01225996  0.9608326   0.41854388  0.23695388  0.2980887   0.14717096\n",
      "  0.4139369  -0.514059   -0.28387618]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.09642869192092896, -0.4758927129802322, -0.051175294280052186]\n",
      "action: [1.22599602e-02 1.03803174e+02 7.60257335e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 107, 81] phase_loss 0.002264766690492672 dis_reward -0.0006992604771210108\n",
      "picked_obj 0\n",
      "51 38\n",
      "action  [ 0.01225996  0.9608326   0.41854388  0.23695388  0.2980887   0.14717096\n",
      "  0.4139369  -0.514059   -0.28387618] real action [1.22599602e-02 1.03803174e+02 7.60257335e+01]\n",
      "reward -0.0029640271676136826 done:  False\n",
      "observation: [0.02678571 0.52232143 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [ True]\n",
      "[ 0.98631454  0.01183116  0.00630182  0.24429557  0.91751456  0.0965139\n",
      "  0.0196971  -0.09627378 -0.19036514]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.14999974807907102, -0.6794640329802322, 0.02619566207379103]\n",
      "place_xyz[2] 0.02619566207379103 False\n",
      "desired_action : [1, 178, 169] phase_loss 0.0025533224722582236 dis_reward -6.34406012711736e-05\n",
      "action  [ 0.98631454  0.01183116  0.00630182  0.24429557  0.91751456  0.0965139\n",
      "  0.0196971  -0.09627378 -0.19036514] real action [  0.98631454 179.65216708 168.33488798]\n",
      "reward 0.9973832369264706 done:  True\n",
      "observation: [0.81696429 0.79017857 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "[ 0.01297104  0.934062    0.36145097  0.22475544  0.3503804   0.29725158\n",
      "  0.22941497 -0.22381532 -0.7344042 ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.18750007192092896, -0.5857140829802322, -0.04018205015361309]\n",
      "action: [1.29710436e-02 1.44866585e+02 4.27183409e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 153, 51] phase_loss 0.0024086547106294647 dis_reward -0.002694766188503519\n",
      "picked_obj 0\n",
      "72 21\n",
      "action  [ 0.01297104  0.934062    0.36145097  0.22475544  0.3503804   0.29725158\n",
      "  0.22941497 -0.22381532 -0.7344042 ] real action [1.29710436e-02 1.44866585e+02 4.27183409e+01]\n",
      "reward -0.005103420899132984 done:  False\n",
      "observation: [0.06696429 0.53571429 0.19196429 0.54910714 0.35267857 0.24553571\n",
      " 0.49553571 0.60714286 0.75446429 0.77678571 0.82142857 0.40178571] [ True]\n",
      "[ 0.9929813   0.0044201   0.22143453  0.01197174  0.05172545  0.9575715\n",
      "  0.12717524  0.17525876 -0.38931692]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.14999974807907102, -0.6580354729802322, 0.026301098965108398]\n",
      "place_xyz[2] 0.026301098965108398 False\n",
      "desired_action : [1, 168, 172] phase_loss 0.0012073741263818746 dis_reward -0.00047666043196528457\n",
      "action  [ 0.9929813   0.0044201   0.22143453  0.01197174  0.05172545  0.9575715\n",
      "  0.12717524  0.17525876 -0.38931692] real action [  0.99298131 171.45362258 168.54956341]\n",
      "reward 0.9983159654416528 done:  True\n",
      "observation: [0.79017857 0.80357143 0.19196429 0.54910714 0.35267857 0.24553571\n",
      " 0.49553571 0.60714286 0.75446429 0.77678571 0.82142857 0.40178571] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "[ 0.01342186  0.9547829   0.31344903  0.2660119   0.3465986   0.23770735\n",
      "  0.32996446 -0.37107426 -0.60476875]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10178583192092897, -0.5883926529802322, -0.03686021065711975]\n",
      "pick_success 0\n",
      "desired_action : [0, 153, 87] phase_loss 0.002499931916539323 dis_reward -0.0041437753057693046\n",
      "action  [ 0.01342186  0.9547829   0.31344903  0.2660119   0.3465986   0.23770735\n",
      "  0.32996446 -0.37107426 -0.60476875] real action [1.34218633e-02 1.45804960e+02 7.45332375e+01]\n",
      "reward -0.006643707222308628 done:  False\n",
      "observation: [0.67410714 0.37053571 0.48214286 0.59821429 0.18303571 0.28571429\n",
      " 0.79464286 0.625      0.19196429 0.73660714 0.44196429 0.26339286] [False]\n",
      "[ 0.01342186  0.9547829   0.31344903  0.2660119   0.3465986   0.23770735\n",
      "  0.32996446 -0.37107426 -0.60476875]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10178583192092897, -0.5883926529802322, -0.03717277555167675]\n",
      "pick_success 0\n",
      "desired_action : [0, 153, 87] phase_loss 0.002499931916539323 dis_reward -0.0041437753057693046\n",
      "action  [ 0.01342186  0.9547829   0.31344903  0.2660119   0.3465986   0.23770735\n",
      "  0.32996446 -0.37107426 -0.60476875] real action [1.34218633e-02 1.45804960e+02 7.45332375e+01]\n",
      "reward -0.006643707222308628 done:  False\n",
      "observation: [0.67410714 0.37053571 0.48214286 0.59821429 0.18303571 0.28571429\n",
      " 0.79464286 0.625      0.19196429 0.73660714 0.44196429 0.26339286] [False]\n",
      "[ 0.01342186  0.9547829   0.31344903  0.2660119   0.3465986   0.23770735\n",
      "  0.32996446 -0.37107426 -0.60476875]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10178583192092897, -0.5883926529802322, -0.03635166196525097]\n",
      "pick_success 0\n",
      "desired_action : [0, 153, 87] phase_loss 0.002499931916539323 dis_reward -0.0041437753057693046\n",
      "action  [ 0.01342186  0.9547829   0.31344903  0.2660119   0.3465986   0.23770735\n",
      "  0.32996446 -0.37107426 -0.60476875] real action [1.34218633e-02 1.45804960e+02 7.45332375e+01]\n",
      "reward -0.006643707222308628 done:  False\n",
      "observation: [0.67410714 0.37053571 0.48214286 0.59821429 0.18303571 0.28571429\n",
      " 0.79464286 0.625      0.19196429 0.73660714 0.44196429 0.26339286] [False]\n",
      "[ 0.01342186  0.9547829   0.31344903  0.2660119   0.3465986   0.23770735\n",
      "  0.32996446 -0.37107426 -0.60476875]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.10178583192092897, -0.5883926529802322, -0.04084687477350235]\n",
      "action: [1.34218633e-02 1.45804960e+02 7.45332375e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 153, 87] phase_loss 0.002499931916539323 dis_reward -0.0041437753057693046\n",
      "picked_obj 0\n",
      "72 37\n",
      "action  [ 0.01342186  0.9547829   0.31344903  0.2660119   0.3465986   0.23770735\n",
      "  0.32996446 -0.37107426 -0.60476875] real action [1.34218633e-02 1.45804960e+02 7.45332375e+01]\n",
      "reward -0.006643707222308628 done:  False\n",
      "observation: [0.0625     0.54464286 0.48214286 0.59821429 0.18303571 0.28571429\n",
      " 0.79464286 0.625      0.19196429 0.73660714 0.44196429 0.26339286] [ True]\n",
      "[ 0.9913678   0.10835075  0.02538893  0.50630236  0.02143574  0.11632141\n",
      "  0.99404544 -0.23335254 -0.48867142]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.16071437192092897, -0.45446415298023224, 0.021817659936845306]\n",
      "place_xyz[2] 0.021817659936845306 False\n",
      "desired_action : [1, 98, 58] phase_loss 0.0015322914459581988 dis_reward -0.000785219052532685\n",
      "action  [ 0.9913678   0.10835075  0.02538893  0.50630236  0.02143574  0.11632141\n",
      "  0.99404544 -0.23335254 -0.48867142] real action [ 0.99136782 95.73306441 52.15859985]\n",
      "reward 0.9976824895015091 done:  True\n",
      "observation: [0.45982143 0.27678571 0.48214286 0.59821429 0.18303571 0.28571429\n",
      " 0.79464286 0.625      0.19196429 0.73660714 0.44196429 0.26339286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "[ 0.01458469  0.93124175  0.31786835  0.23899412  0.3101173   0.18251818\n",
      "  0.2356416  -0.17468047 -0.75455487]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.008035538079071036, -0.3258927929802322, -0.040480121806263925]\n",
      "action: [1.45846903e-02 4.75544734e+01 1.15436232e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 53, 125] phase_loss 0.0027355613005327507 dis_reward -0.0024223885141436085\n",
      "picked_obj 0\n",
      "23 57\n",
      "action  [ 0.01458469  0.93124175  0.31786835  0.23899412  0.3101173   0.18251818\n",
      "  0.2356416  -0.17468047 -0.75455487] real action [1.45846903e-02 4.75544734e+01 1.15436232e+02]\n",
      "reward -0.00515794981467636 done:  False\n",
      "observation: [0.02232143 0.5625     0.37053571 0.19196429 0.49553571 0.41071429\n",
      " 0.70982143 0.5625     0.78125    0.30803571 0.48660714 0.73660714] [ True]\n",
      "[ 0.99187815  0.00542459  0.21717477  0.01575434  0.06829873  0.94950056\n",
      "  0.16036856  0.12113023 -0.4181984 ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.13125010192092895, -0.6714283229802323, 0.025167916879057887]\n",
      "place_xyz[2] 0.025167916879057887 False\n",
      "desired_action : [1, 177, 68] phase_loss 0.0014294659043731705 dis_reward -0.0004732278228669838\n",
      "action  [ 0.99187815  0.00542459  0.21717477  0.01575434  0.06829873  0.94950056\n",
      "  0.16036856  0.12113023 -0.4181984 ] real action [  0.99187815 176.69582319  63.14522219]\n",
      "reward 0.9980973062727598 done:  True\n",
      "observation: [0.82142857 0.33482143 0.37053571 0.19196429 0.49553571 0.41071429\n",
      " 0.70982143 0.5625     0.78125    0.30803571 0.48660714 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[0.0091182  0.44596183 0.9702623  0.5188155  0.25238287 0.37906635\n",
      " 0.27655292 0.9766947  0.17279792]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.01607159192092894, -0.6687497529802322, -0.03800537607073784]\n",
      "action: [9.11819935e-03 1.75673726e+02 1.06419171e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 164, 102] phase_loss 0.0016302662730994526 dis_reward -0.003116099033854939\n",
      "picked_obj 1\n",
      "87 53\n",
      "action  [0.0091182  0.44596183 0.9702623  0.5188155  0.25238287 0.37906635\n",
      " 0.27655292 0.9766947  0.17279792] real action [9.11819935e-03 1.75673726e+02 1.06419171e+02]\n",
      "reward -0.004746365306954391 done:  False\n",
      "observation: [ 0.43303571  0.44196429 -0.04464286  0.47321429  0.60714286  0.73660714\n",
      "  0.76339286  0.125       0.30357143  0.69642857  0.21875     0.17857143] [ True]\n",
      "[0.9884887  0.04491544 0.01214346 0.49481642 0.03847048 0.06013823\n",
      " 0.9947542  0.37650645 0.18037832]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [-0.18750007192092896, -0.3446427829802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 53, 37] phase_loss 0.0021133920048816 dis_reward -0.0006428914386982901\n",
      "action  [0.9884887  0.04491544 0.01214346 0.49481642 0.03847048 0.06013823\n",
      " 0.9947542  0.37650645 0.18037832] real action [ 0.98848867 54.27109051 42.52529645]\n",
      "reward 0.9972437165564201 done:  True\n",
      "observation: [0.43303571 0.44196429 0.16964286 0.19196429 0.60714286 0.73660714\n",
      " 0.76339286 0.125      0.30357143 0.69642857 0.21875    0.17857143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[0.00826415 0.1995304  0.21629775 0.985072   0.30487046 0.22042781\n",
      " 0.43981338 0.0063616  0.06965816]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.12321404807907105, -0.4008927529802322, -0.053500000000000006]\n",
      "action: [8.26415420e-03 7.50890625e+01 1.58975214e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 75, 159] phase_loss 0.0014581333271068708 dis_reward -1.7092908331733273e-07\n",
      "picked_obj 2\n",
      "37 79\n",
      "action  [0.00826415 0.1995304  0.21629775 0.985072   0.30487046 0.22042781\n",
      " 0.43981338 0.0063616  0.06965816] real action [8.26415420e-03 7.50890625e+01 1.58975214e+02]\n",
      "reward -0.001458304256190188 done:  False\n",
      "observation: [0.49553571 0.29464286 0.25446429 0.44642857 0.00892857 0.50892857\n",
      " 0.82142857 0.26785714 0.64732143 0.58035714 0.20982143 0.15625   ] [ True]\n",
      "[ 0.99302614  0.02187538  0.00667337  0.20826238  0.95160794  0.14506882\n",
      "  0.01977128  0.26035833 -0.01985639]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.14196438192092897, -0.7008925929802322, 0.026785881236195568]\n",
      "place_xyz[2] 0.026785881236195568 False\n",
      "desired_action : [1, 186, 56] phase_loss 0.0011983555097095184 dis_reward -0.00033118883914800364\n",
      "action  [ 0.99302614  0.02187538  0.00667337  0.20826238  0.95160794  0.14506882\n",
      "  0.01977128  0.26035833 -0.01985639] real action [  0.99302614 187.64501667  59.72201049]\n",
      "reward 0.9984704556511425 done:  True\n",
      "observation: [0.49553571 0.29464286 0.25446429 0.44642857 0.82589286 0.26339286\n",
      " 0.82142857 0.26785714 0.64732143 0.58035714 0.20982143 0.15625   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[0.00972819 0.19160378 0.4091556  0.986675   0.340489   0.45338994\n",
      " 0.26984513 0.20695984 0.00214195]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.07232121807907105, -0.6928568829802322, -0.03648301570117474]\n",
      "pick_success 0\n",
      "desired_action : [0, 180, 141] phase_loss 0.0017533014130103762 dis_reward -0.0005573169402212818\n",
      "action  [0.00972819 0.19160378 0.4091556  0.986675   0.340489   0.45338994\n",
      " 0.26984513 0.20695984 0.00214195] real action [9.72819328e-03 1.84897438e+02 1.39029987e+02]\n",
      "reward -0.002310618353231658 done:  False\n",
      "observation: [0.35267857 0.22321429 0.61160714 0.79017857 0.8125     0.62053571\n",
      " 0.61607143 0.17410714 0.28125    0.49553571 0.19196429 0.72321429] [False]\n",
      "[0.00972819 0.19160378 0.4091556  0.986675   0.340489   0.45338994\n",
      " 0.26984513 0.20695984 0.00214195]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.07232121807907105, -0.6928568829802322, -0.038415752187371255]\n",
      "action: [9.72819328e-03 1.84897438e+02 1.39029987e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 180, 141] phase_loss 0.0017533014130103762 dis_reward -0.0005573169402212818\n",
      "picked_obj 2\n",
      "92 69\n",
      "action  [0.00972819 0.19160378 0.4091556  0.986675   0.340489   0.45338994\n",
      " 0.26984513 0.20695984 0.00214195] real action [9.72819328e-03 1.84897438e+02 1.39029987e+02]\n",
      "reward -0.002310618353231658 done:  False\n",
      "observation: [ 0.35267857  0.22321429  0.61160714  0.79017857 -0.01785714  0.51785714\n",
      "  0.61607143  0.17410714  0.28125     0.49553571  0.19196429  0.72321429] [ True]\n",
      "[ 0.9959631   0.00434515  0.26427716  0.05339834  0.1576013   0.96726704\n",
      "  0.07046294  0.4260819  -0.2328313 ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.01339302192092895, -0.3821427629802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 62, 110] phase_loss 0.0006083048259941924 dis_reward -0.0010723846327112643\n",
      "action  [ 0.9959631   0.00434515  0.26427716  0.05339834  0.1576013   0.96726704\n",
      "  0.07046294  0.4260819  -0.2328313 ] real action [  0.9959631   68.96514654 107.74036169]\n",
      "reward 0.9983193105412945 done:  True\n",
      "observation: [0.35267857 0.22321429 0.61160714 0.79017857 0.29017857 0.48214286\n",
      " 0.61607143 0.17410714 0.28125    0.49553571 0.19196429 0.72321429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01150647  0.9619533   0.42228994  0.20994568  0.29615796  0.12013274\n",
      "  0.41555265 -0.5168892  -0.2575724 ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.18214258807907102, -0.38749990298023224, -0.04160126468539238]\n",
      "action: [1.15064681e-02 7.07635508e+01 1.80393986e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 82, 181] phase_loss 0.002112410130757777 dis_reward -0.0025325008851049143\n",
      "picked_obj 0\n",
      "35 90\n",
      "action  [ 0.01150647  0.9619533   0.42228994  0.20994568  0.29615796  0.12013274\n",
      "  0.41555265 -0.5168892  -0.2575724 ] real action [1.15064681e-02 7.07635508e+01 1.80393986e+02]\n",
      "reward -0.004644911015862691 done:  False\n",
      "observation: [0.0625     0.51785714 0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [ True]\n",
      "[ 0.98481154  0.01068422  0.00670668  0.20294052  0.89958173  0.09891284\n",
      "  0.01584774 -0.09945363 -0.1389401 ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.17410722192092895, -0.5321426829802323, 0.021561953216791156]\n",
      "place_xyz[2] 0.021561953216791156 False\n",
      "desired_action : [1, 129, 48] phase_loss 0.0028580148138013044 dis_reward -0.00040372150902681615\n",
      "action  [ 0.98481154  0.01068422  0.00670668  0.20294052  0.89958173  0.09891284\n",
      "  0.01584774 -0.09945363 -0.1389401 ] real action [  0.98481154 124.60764921  47.05483866]\n",
      "reward 0.9967382636771719 done:  True\n",
      "observation: [0.58482143 0.20535714 0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.00893104  0.96367216  0.5066214   0.14450836  0.3240512   0.12965596\n",
      "  0.43483695 -0.42811823 -0.30836356]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.12321404807907105, -0.4464284429802322, -0.03887471726536751]\n",
      "action: [8.93104076e-03 9.20063448e+01 1.58682910e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 100, 167] phase_loss 0.0015925317508655404 dis_reward -0.0026614502034904217\n",
      "picked_obj 0\n",
      "46 79\n",
      "action  [ 0.00893104  0.96367216  0.5066214   0.14450836  0.3240512   0.12965596\n",
      "  0.43483695 -0.42811823 -0.30836356] real action [8.93104076e-03 9.20063448e+01 1.58682910e+02]\n",
      "reward -0.004253981954355962 done:  False\n",
      "observation: [0.04017857 0.52678571 0.70982143 0.37053571 0.42857143 0.46875\n",
      " 0.16071429 0.37053571 0.35267857 0.14285714 0.78125    0.59375   ] [ True]\n",
      "[ 0.98507166  0.01289862  0.01123792  0.30745512  0.93456084  0.09824491\n",
      "  0.02120823 -0.03740495 -0.1630131 ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.08571441192092896, -0.2937499529802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 38, 85] phase_loss 0.0028052500920680928 dis_reward -0.0004941200359021118\n",
      "action  [ 0.98507166  0.01289862  0.01123792  0.30745512  0.93456084  0.09824491\n",
      "  0.02120823 -0.03740495 -0.1630131 ] real action [ 0.98507166 35.47633064 80.71781659]\n",
      "reward 0.9967006298720298 done:  True\n",
      "observation: [0.18303571 0.37946429 0.70982143 0.37053571 0.42857143 0.46875\n",
      " 0.16071429 0.37053571 0.35267857 0.14285714 0.78125    0.59375   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[ 0.01190552  0.16887271  0.3010315   0.9848608   0.29545957  0.35268262\n",
      "  0.35275233  0.07964516 -0.04002398]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.13392867192092897, -0.35267849298023224, -0.04257502390444279]\n",
      "action: [1.19055212e-02 5.71150322e+01 6.24396642e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 53, 63] phase_loss 0.0021930844500210583 dis_reward -0.00034494932266415873\n",
      "picked_obj 2\n",
      "28 31\n",
      "action  [ 0.01190552  0.16887271  0.3010315   0.9848608   0.29545957  0.35268262\n",
      "  0.35275233  0.07964516 -0.04002398] real action [1.19055212e-02 5.71150322e+01 6.24396642e+01]\n",
      "reward -0.002538033772685217 done:  False\n",
      "observation: [0.49107143 0.21428571 0.41071429 0.52678571 0.00446429 0.49107143\n",
      " 0.74553571 0.32589286 0.69196429 0.74107143 0.16964286 0.64285714] [ True]\n",
      "[ 0.9947313   0.00525895  0.28215992  0.06280732  0.13985199  0.9709787\n",
      "  0.07179368  0.4576769  -0.17450011]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.136606898079071, -0.6312497729802322, 0.024493806041777137]\n",
      "place_xyz[2] 0.024493806041777137 False\n",
      "desired_action : [1, 155, 167] phase_loss 0.0008555659702152469 dis_reward -0.0010582002705623846\n",
      "action  [ 0.9947313   0.00525895  0.28215992  0.06280732  0.13985199  0.9709787\n",
      "  0.07179368  0.4576769  -0.17450011] real action [  0.99473131 161.40747643 163.55699849]\n",
      "reward 0.9980862337592223 done:  True\n",
      "observation: [0.49107143 0.21428571 0.41071429 0.52678571 0.70089286 0.75446429\n",
      " 0.74553571 0.32589286 0.69196429 0.74107143 0.16964286 0.64285714] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[0.00625774 0.42906392 0.9776683  0.5977083  0.27174705 0.33918142\n",
      " 0.30858648 0.98015714 0.21126294]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.10178548807907101, -0.5749998029802322, -0.03699861077964306]\n",
      "pick_success 0\n",
      "desired_action : [0, 124, 148] phase_loss 0.0010543226424315055 dis_reward -0.0057675972792633964\n",
      "action  [0.00625774 0.42906392 0.9776683  0.5977083  0.27174705 0.33918142\n",
      " 0.30858648 0.98015714 0.21126294] real action [6.25774264e-03 1.40722200e+02 1.50957681e+02]\n",
      "reward -0.006821919921694902 done:  False\n",
      "observation: [0.1875     0.41964286 0.56696429 0.66071429 0.21875    0.82142857\n",
      " 0.79910714 0.70535714 0.48214286 0.20982143 0.77678571 0.25      ] [False]\n",
      "[0.00625774 0.42906392 0.9776683  0.5977083  0.27174705 0.33918142\n",
      " 0.30858648 0.98015714 0.21126294]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.10178548807907101, -0.5749998029802322, -0.03990235722064972]\n",
      "action: [6.25774264e-03 1.40722200e+02 1.50957681e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 124, 148] phase_loss 0.0010543226424315055 dis_reward -0.0057675972792633964\n",
      "picked_obj 1\n",
      "70 75\n",
      "action  [0.00625774 0.42906392 0.9776683  0.5977083  0.27174705 0.33918142\n",
      " 0.30858648 0.98015714 0.21126294] real action [6.25774264e-03 1.40722200e+02 1.50957681e+02]\n",
      "reward -0.006821919921694902 done:  False\n",
      "observation: [ 0.1875      0.41964286 -0.04464286  0.47767857  0.21875     0.82142857\n",
      "  0.79910714  0.70535714  0.48214286  0.20982143  0.77678571  0.25      ] [ True]\n",
      "[0.9939121  0.00478229 0.11652005 0.01416957 0.01353368 0.9843958\n",
      " 0.08159643 0.00738263 0.0160768 ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.17410722192092895, -0.48928556298023224, 0.023243576265871528]\n",
      "place_xyz[2] 0.023243576265871528 False\n",
      "desired_action : [1, 107, 48] phase_loss 0.0010201773276929068 dis_reward -3.635809377044097e-05\n",
      "action  [0.9939121  0.00478229 0.11652005 0.01416957 0.01353368 0.9843958\n",
      " 0.08159643 0.00738263 0.0160768 ] real action [  0.9939121  108.10335684  47.22507524]\n",
      "reward 0.9989434645785367 done:  True\n",
      "observation: [0.1875     0.41964286 0.41071429 0.18303571 0.21875    0.82142857\n",
      " 0.79910714 0.70535714 0.48214286 0.20982143 0.77678571 0.25      ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "action: [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 127, 56] phase_loss 0.0016259156243201751 dis_reward -0.004268366961065479\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.005894282585385654 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "action: [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 127, 56] phase_loss 0.0016259156243201751 dis_reward -0.004268366961065479\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.005894282585385654 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "action: [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 127, 56] phase_loss 0.0016259156243201751 dis_reward -0.004268366961065479\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.005894282585385654 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "action: [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 127, 56] phase_loss 0.0016259156243201751 dis_reward -0.004268366961065479\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.005894282585385654 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "action: [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 126, 56] phase_loss 0.0016259156243201751 dis_reward -0.0048706737847959486\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.0064965894091161235 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 126, 56] phase_loss 0.0016259156243201751 dis_reward -0.0048706737847959486\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.0064965894091161235 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 126, 56] phase_loss 0.0016259156243201751 dis_reward -0.0048706737847959486\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.0064965894091161235 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 126, 56] phase_loss 0.0016259156243201751 dis_reward -0.0048706737847959486\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.0064965894091161235 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 126, 56] phase_loss 0.0016259156243201751 dis_reward -0.0048706737847959486\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.0064965894091161235 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 126, 56] phase_loss 0.0016259156243201751 dis_reward -0.0048706737847959486\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.0064965894091161235 done:  False\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "[ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15535723192092896, -0.5776783729802322, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 126, 56] phase_loss 0.0016259156243201751 dis_reward -0.0048706737847959486\n",
      "action  [ 0.00909662  0.31236258  0.9647347   0.48805398  0.284577    0.3148049\n",
      "  0.38334706  0.968405   -0.01583642] real action [9.09662247e-03 1.41557671e+02 5.47782902e+01]\n",
      "reward -0.0064965894091161235 done:  True\n",
      "observation: [0.46875    0.66071429 0.57142857 0.24553571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01002875  0.95146644  0.52021766  0.19274485  0.29902866  0.22469899\n",
      "  0.371494   -0.4192809  -0.34365726]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.136606898079071, -0.5669640929802322, -0.045216040521860124]\n",
      "action: [1.00287497e-02 1.37130068e+02 1.63188798e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 144, 166] phase_loss 0.0018139511749091287 dis_reward -0.0011019764473101214\n",
      "picked_obj 0\n",
      "68 81\n",
      "action  [ 0.01002875  0.95146644  0.52021766  0.19274485  0.29902866  0.22469899\n",
      "  0.371494   -0.4192809  -0.34365726] real action [1.00287497e-02 1.37130068e+02 1.63188798e+02]\n",
      "reward -0.00291592762221925 done:  False\n",
      "observation: [0.01785714 0.51339286 0.32142857 0.20535714 0.47767857 0.46428571\n",
      " 0.26339286 0.60267857 0.84375    0.29017857 0.60714286 0.14732143] [ True]\n",
      "[ 0.98000574  0.01291749  0.00962669  0.1830273   0.89206445  0.09337112\n",
      "  0.01513171 -0.05847311 -0.1618678 ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.053571228079071054, -0.35535706298023223, 0.02414838967472315]\n",
      "place_xyz[2] 0.02414838967472315 False\n",
      "desired_action : [1, 60, 137] phase_loss 0.003835393424112099 dis_reward -0.00043014838512621736\n",
      "action  [ 0.98000574  0.01291749  0.00962669  0.1830273   0.89206445  0.09337112\n",
      "  0.01513171 -0.05847311 -0.1618678 ] real action [  0.98000574  58.18137646 132.73385096]\n",
      "reward 0.9957344581907617 done:  True\n",
      "observation: [0.28571429 0.59375    0.32142857 0.20535714 0.47767857 0.46428571\n",
      " 0.26339286 0.60267857 0.84375    0.29017857 0.60714286 0.14732143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00724629  0.46540987  0.96793365  0.08302027  0.2450411   0.4217587\n",
      "  0.45209146  0.965086   -0.1211853 ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.6446426229802322, -0.0402523966729641]\n",
      "action: [7.24628568e-03 1.66511204e+02 1.83303406e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 152, 185] phase_loss 0.0012531750674028813 dis_reward -0.004269069334878878\n",
      "picked_obj 1\n",
      "83 91\n",
      "action  [ 0.00724629  0.46540987  0.96793365  0.08302027  0.2450411   0.4217587\n",
      "  0.45209146  0.965086   -0.1211853 ] real action [7.24628568e-03 1.66511204e+02 1.83303406e+02]\n",
      "reward -0.005522244402281759 done:  False\n",
      "observation: [ 0.5625      0.60267857 -0.04464286  0.49553571  0.46875     0.25892857\n",
      "  0.32589286  0.46428571  0.16071429  0.26339286  0.29017857  0.75446429] [ True]\n",
      "[ 0.98947287  0.01512954  0.00648338  0.35652435  0.9748334   0.06875208\n",
      "  0.0226908   0.17284179 -0.03021604]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.02410730192092897, -0.4008927529802322, 0.023234299361705783]\n",
      "place_xyz[2] 0.023234299361705783 False\n",
      "desired_action : [1, 72, 105] phase_loss 0.0019145614810360805 dis_reward -0.0002743985685889701\n",
      "action  [ 0.98947287  0.01512954  0.00648338  0.35652435  0.9748334   0.06875208\n",
      "  0.0226908   0.17284179 -0.03021604] real action [  0.98947287  75.41978502 103.57697546]\n",
      "reward 0.9978110399503749 done:  True\n",
      "observation: [0.5625     0.60267857 0.27232143 0.49107143 0.46875    0.25892857\n",
      " 0.32589286 0.46428571 0.16071429 0.26339286 0.29017857 0.75446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[ 0.00901657  0.16563779  0.20691472  0.98416924  0.3302009   0.30196676\n",
      "  0.3149738   0.04289758 -0.02567679]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.12321439192092895, -0.6473211929802323, -0.053500000000000006]\n",
      "action: [9.01657343e-03 1.67600566e+02 6.66405250e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 166, 68] phase_loss 0.0016097757845246379 dis_reward -8.819968634585764e-05\n",
      "picked_obj 2\n",
      "83 33\n",
      "action  [ 0.00901657  0.16563779  0.20691472  0.98416924  0.3302009   0.30196676\n",
      "  0.3149738   0.04289758 -0.02567679] real action [9.01657343e-03 1.67600566e+02 6.66405250e+01]\n",
      "reward -0.0016979754708704956 done:  False\n",
      "observation: [0.1875     0.34375    0.18303571 0.66964286 0.02232143 0.52232143\n",
      " 0.78125    0.71875    0.46875    0.17410714 0.53571429 0.58035714] [ True]\n",
      "[0.98997647 0.02424234 0.01313856 0.36734128 0.98126364 0.13313001\n",
      " 0.03819242 0.15667343 0.06034338]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.13124975807907102, -0.6741068929802323, 0.02510295526683331]\n",
      "place_xyz[2] 0.02510295526683331 False\n",
      "desired_action : [1, 176, 164] phase_loss 0.0018128985928706092 dis_reward -0.00012138251374618563\n",
      "action  [0.98997647 0.02424234 0.01313856 0.36734128 0.98126364 0.13313001\n",
      " 0.03819242 0.15667343 0.06034338] real action [  0.98997647 177.19342804 161.84480739]\n",
      "reward 0.9980657188933832 done:  True\n",
      "observation: [0.1875     0.34375    0.18303571 0.66964286 0.79910714 0.72321429\n",
      " 0.78125    0.71875    0.46875    0.17410714 0.53571429 0.58035714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.01029405  0.22014225  0.30512577  0.9865941   0.2508602   0.40842503\n",
      "  0.52431333 -0.03379279  0.1255486 ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.14732152192092896, -0.3258927929802322, -0.03997285833954811]\n",
      "action: [1.02940500e-02 4.75269009e+01 5.77576804e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 48, 52] phase_loss 0.0018675018289586905 dis_reward -0.0006674941308856502\n",
      "picked_obj 2\n",
      "23 28\n",
      "action  [ 0.01029405  0.22014225  0.30512577  0.9865941   0.2508602   0.40842503\n",
      "  0.52431333 -0.03379279  0.1255486 ] real action [1.02940500e-02 4.75269009e+01 5.77576804e+01]\n",
      "reward -0.0025349959598443407 done:  False\n",
      "observation: [0.58928571 0.72767857 0.19196429 0.54464286 0.02232143 0.47321429\n",
      " 0.60714286 0.16964286 0.80803571 0.51785714 0.47321429 0.45089286] [ True]\n",
      "[0.99396145 0.02888194 0.00874868 0.28393465 0.03708643 0.13732588\n",
      " 0.98922276 0.12609708 0.21701062]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.02142873192092898, -0.48660699298023224, 0.020261182427406314]\n",
      "place_xyz[2] 0.020261182427406314 False\n",
      "desired_action : [1, 108, 102] phase_loss 0.0010102565674960115 dis_reward -8.418212414909476e-05\n",
      "action  [0.99396145 0.02888194 0.00874868 0.28393465 0.03708643 0.13732588\n",
      " 0.98922276 0.12609708 0.21701062] real action [  0.99396145 107.76535916 104.03814864]\n",
      "reward 0.9989055613083548 done:  True\n",
      "observation: [0.58928571 0.72767857 0.19196429 0.54464286 0.48660714 0.45982143\n",
      " 0.60714286 0.16964286 0.80803571 0.51785714 0.47321429 0.45089286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 159, 167] phase_loss 0.002933752405578547 dis_reward -4.087868809402267e-05\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.0029746310936725694 done:  False\n",
      "observation: [0.54910714 0.33482143 0.70982143 0.73660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 159, 167] phase_loss 0.002933752405578547 dis_reward -4.087868809402267e-05\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.0029746310936725694 done:  False\n",
      "observation: [0.54910714 0.33482143 0.70982143 0.73660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 159, 167] phase_loss 0.002933752405578547 dis_reward -4.087868809402267e-05\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.0029746310936725694 done:  False\n",
      "observation: [0.54910714 0.33482143 0.70982143 0.73660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 158, 167] phase_loss 0.002933752405578547 dis_reward -8.589334606826584e-05\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.0030196457516468126 done:  False\n",
      "observation: [0.54910714 0.33482143 0.70982143 0.73660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 158, 168] phase_loss 0.002933752405578547 dis_reward -5.446804165542403e-05\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.002988220447233971 done:  False\n",
      "observation: [0.54910714 0.33482143 0.70982143 0.73660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 157, 168] phase_loss 0.002933752405578547 dis_reward -0.00013948269962966723\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.0030732351052082142 done:  False\n",
      "observation: [0.54910714 0.33482143 0.70982143 0.73660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 156, 168] phase_loss 0.002933752405578547 dis_reward -0.0002644973576039104\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.003198249763182457 done:  False\n",
      "observation: [0.54910714 0.33482143 0.70982143 0.73660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 155, 168] phase_loss 0.002933752405578547 dis_reward -0.0004295120155781535\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.0033632644211567 done:  False\n",
      "observation: [0.54910714 0.33482143 0.70982143 0.73660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6258926329802322, -0.053500000000000006]\n",
      "action: [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 155, 168] phase_loss 0.002933752405578547 dis_reward -0.0004295120155781535\n",
      "action  [0.0155617  0.13290611 0.9420891  0.16554558 0.07164869 0.21203482\n",
      " 0.07361859 0.04466903 0.23468804] real action [1.55616999e-02 1.59625366e+02 1.68285633e+02]\n",
      "reward -0.0033632644211567 done:  False\n",
      "observation: [0.54910714 0.33482143 0.67857143 0.74107143 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "[ 0.01335591  0.01222491  0.97362334  0.0330376   0.01431826  0.02338856\n",
      "  0.01788428 -0.3805352   0.2362777 ]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.152678318079071, -0.5910712229802322, -0.03828504851460457]\n",
      "action: [1.33559108e-02 1.46672507e+02 1.69307888e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 154, 168] phase_loss 0.002486575942998011 dis_reward -0.0011080543990134003\n",
      "picked_obj 1\n",
      "73 84\n",
      "action  [ 0.01335591  0.01222491  0.97362334  0.0330376   0.01431826  0.02338856\n",
      "  0.01788428 -0.3805352   0.2362777 ] real action [1.33559108e-02 1.46672507e+02 1.69307888e+02]\n",
      "reward -0.003594630342011411 done:  False\n",
      "observation: [0.54910714 0.33482143 0.04017857 0.48660714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [ True]\n",
      "[0.9913939  0.03572679 0.0086368  0.4532099  0.03758499 0.0883584\n",
      " 0.994376   0.3318156  0.23602617]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [-0.08035727192092895, -0.6741068929802323, 0.022286618106067184]\n",
      "place_xyz[2] 0.022286618106067184 False\n",
      "desired_action : [1, 175, 81] phase_loss 0.0015270299913708843 dis_reward -0.00017399217708728544\n",
      "action  [0.9913939  0.03572679 0.0086368  0.4532099  0.03758499 0.0883584\n",
      " 0.994376   0.3318156  0.23602617] real action [  0.99139392 177.64541817  82.30436635]\n",
      "reward 0.9982989778315419 done:  True\n",
      "observation: [0.54910714 0.33482143 0.81696429 0.36160714 0.1875     0.17410714\n",
      " 0.35267857 0.52232143 0.27232143 0.77678571 0.77232143 0.35267857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.00693217  0.32176715  0.93281597  0.47353232  0.15305805  0.32729584\n",
      "  0.12996632 -0.01428699  0.44828367]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.5964283629802323, -0.053500000000000006]\n",
      "action: [6.93216920e-03 1.48799982e+02 1.06275971e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 149, 101] phase_loss 0.0011899668822715039 dis_reward -0.0005575176303828812\n",
      "action  [ 0.00693217  0.32176715  0.93281597  0.47353232  0.15305805  0.32729584\n",
      "  0.12996632 -0.01428699  0.44828367] real action [6.93216920e-03 1.48799982e+02 1.06275971e+02]\n",
      "reward -0.0017474845126543852 done:  False\n",
      "observation: [0.3125     0.1875     0.66517857 0.44642857 0.40178571 0.75\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "[ 0.00702667  0.3212628   0.931677    0.4695705   0.15759164  0.32592392\n",
      "  0.12484846 -0.15294951  0.46249294]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.5910712229802322, -0.053500000000000006]\n",
      "action: [7.02667236e-03 1.46858707e+02 1.06474901e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 149, 101] phase_loss 0.0012089812098092351 dis_reward -0.0006911935812726779\n",
      "action  [ 0.00702667  0.3212628   0.931677    0.4695705   0.15759164  0.32592392\n",
      "  0.12484846 -0.15294951  0.46249294] real action [7.02667236e-03 1.46858707e+02 1.06474901e+02]\n",
      "reward -0.001900174791081913 done:  False\n",
      "observation: [0.3125     0.1875     0.66517857 0.44642857 0.41964286 0.75892857\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "[0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.6124997829802322, -0.053500000000000006]\n",
      "action: [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 149, 101] phase_loss 0.0011336780411962373 dis_reward -0.0012204919297332528\n",
      "action  [0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618] real action [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "reward -0.00235416997092949 done:  False\n",
      "observation: [0.3125     0.1875     0.66517857 0.44642857 0.41964286 0.75892857\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "[0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.6124997829802322, -0.053189950831234456]\n",
      "action: [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 148, 101] phase_loss 0.0011336780411962373 dis_reward -0.001478854051315284\n",
      "action  [0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618] real action [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "reward -0.0026125320925115213 done:  False\n",
      "observation: [0.3125     0.1875     0.66517857 0.44642857 0.41964286 0.75892857\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "[0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.6124997829802322, -0.053500000000000006]\n",
      "action: [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 147, 102] phase_loss 0.0011336780411962373 dis_reward -0.0015951695115203617\n",
      "action  [0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618] real action [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "reward -0.002728847552716599 done:  False\n",
      "observation: [0.3125     0.1875     0.66517857 0.44642857 0.41964286 0.75892857\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "[0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.6124997829802322, -0.053500000000000006]\n",
      "action: [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 147, 102] phase_loss 0.0011336780411962373 dis_reward -0.0015951695115203617\n",
      "action  [0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618] real action [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "reward -0.002728847552716599 done:  False\n",
      "observation: [0.3125     0.1875     0.66517857 0.44642857 0.41964286 0.75892857\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "[0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.6124997829802322, -0.053500000000000006]\n",
      "action: [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 146, 102] phase_loss 0.0011336780411962373 dis_reward -0.001933531633102393\n",
      "action  [0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618] real action [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "reward -0.0030672096742986304 done:  False\n",
      "observation: [0.3125     0.1875     0.66517857 0.44642857 0.41964286 0.75892857\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "[0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.6124997829802322, -0.053500000000000006]\n",
      "action: [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 145, 102] phase_loss 0.0011336780411962373 dis_reward -0.0023118937546844245\n",
      "action  [0.00665236 0.34778166 0.9421165  0.48728174 0.19165596 0.32224828\n",
      " 0.1794548  0.42564666 0.43222618] real action [6.65235519e-03 1.54959053e+02 1.06051167e+02]\n",
      "reward -0.003445571795880662 done:  False\n",
      "observation: [0.3125     0.1875     0.65625    0.46428571 0.41964286 0.75892857\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "[0.00703767 0.43956122 0.9726701  0.5824642  0.26107484 0.35447943\n",
      " 0.31513512 0.9770653  0.16509604]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.01607159192092894, -0.6285712029802322, -0.04221352545917034]\n",
      "action: [7.03766942e-03 1.60678915e+02 1.06311345e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 144, 103] phase_loss 0.0012111939689427049 dis_reward -0.005783024191745651\n",
      "picked_obj 1\n",
      "80 53\n",
      "action  [0.00703767 0.43956122 0.9726701  0.5824642  0.26107484 0.35447943\n",
      " 0.31513512 0.9770653  0.16509604] real action [7.03766942e-03 1.60678915e+02 1.06311345e+02]\n",
      "reward -0.006994218160688356 done:  False\n",
      "observation: [ 0.3125      0.1875     -0.08482143  0.47321429  0.41964286  0.75892857\n",
      "  0.78125     0.76339286  0.80803571  0.16964286  0.31696429  0.43303571] [ True]\n",
      "[0.9922904  0.00577238 0.09450698 0.01730415 0.01533866 0.9751343\n",
      " 0.12424475 0.01804745 0.02392137]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.19821435192092896, -0.6848211729802323, 0.023526607990264896]\n",
      "place_xyz[2] 0.023526607990264896 False\n",
      "desired_action : [1, 182, 40] phase_loss 0.0013464466191391536 dis_reward -6.662142648739291e-05\n",
      "action  [0.9922904  0.00577238 0.09450698 0.01730415 0.01533866 0.9751343\n",
      " 0.12424475 0.01804745 0.02392137] real action [  0.99229038 181.25266433  38.33489919]\n",
      "reward 0.9985869319543734 done:  True\n",
      "observation: [0.3125     0.1875     0.71875    0.17410714 0.41964286 0.75892857\n",
      " 0.78125    0.76339286 0.80803571 0.16964286 0.31696429 0.43303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.0103901   0.1930933   0.2774021   0.98704785  0.26967496  0.38353768\n",
      "  0.5112646  -0.02165598  0.16488886]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.085714068079071, -0.43035702298023226, -0.03943763843178749]\n",
      "action: [1.03901029e-02 8.66968163e+01 1.44308444e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 85, 139] phase_loss 0.0018868935650654902 dis_reward -0.0006211752717630545\n",
      "picked_obj 2\n",
      "43 72\n",
      "action  [ 0.0103901   0.1930933   0.2774021   0.98704785  0.26967496  0.38353768\n",
      "  0.5112646  -0.02165598  0.16488886] real action [1.03901029e-02 8.66968163e+01 1.44308444e+02]\n",
      "reward -0.002508068836828545 done:  False\n",
      "observation: [0.60714286 0.47321429 0.75       0.69642857 0.00446429 0.47321429\n",
      " 0.17857143 0.32589286 0.67410714 0.15625    0.19642857 0.78125   ] [ True]\n",
      "[0.994105   0.0229075  0.00756249 0.29445243 0.03750482 0.11575031\n",
      " 0.98914397 0.09444952 0.2562548 ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.17678544807907104, -0.32053565298023223, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 47, 172] phase_loss 0.0009814076843926531 dis_reward -0.0009242148002277022\n",
      "action  [0.994105   0.0229075  0.00756249 0.29445243 0.03750482 0.11575031\n",
      " 0.98914397 0.09444952 0.2562548 ] real action [  0.99410498  45.32229328 178.58756709]\n",
      "reward 0.9980943775153797 done:  True\n",
      "observation: [0.60714286 0.47321429 0.75       0.69642857 0.19642857 0.76785714\n",
      " 0.17857143 0.32589286 0.67410714 0.15625    0.19642857 0.78125   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.00755104  0.20094806  0.27659947  0.9897822   0.23294714  0.39680493\n",
      "  0.52420247 -0.01449209  0.17469358]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.05892871192092897, -0.35267849298023224, -0.03854652664065361]\n",
      "action: [7.55104423e-03 5.77971107e+01 9.04457102e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 55, 89] phase_loss 0.0013145192988115268 dis_reward -0.00019827812137925883\n",
      "picked_obj 2\n",
      "28 45\n",
      "action  [ 0.00755104  0.20094806  0.27659947  0.9897822   0.23294714  0.39680493\n",
      "  0.52420247 -0.01449209  0.17469358] real action [7.55104423e-03 5.77971107e+01 9.04457102e+01]\n",
      "reward -0.0015127974201907856 done:  False\n",
      "observation: [ 0.48660714  0.5625      0.65178571  0.19642857 -0.00892857  0.47767857\n",
      "  0.30357143  0.69196429  0.71875     0.76785714  0.82142857  0.50892857] [ True]\n",
      "[0.9945177  0.02738577 0.00636268 0.33485413 0.03744659 0.09351093\n",
      " 0.9919143  0.13132846 0.29506564]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.01607124807907101, -0.6955354529802322, 0.027082069754600528]\n",
      "place_xyz[2] 0.027082069754600528 False\n",
      "desired_action : [1, 185, 112] phase_loss 0.000898478343034261 dis_reward -0.000765828299239971\n",
      "action  [0.9945177  0.02738577 0.00636268 0.33485413 0.03744659 0.09351093\n",
      " 0.9919143  0.13132846 0.29506564] real action [  0.99451768 185.83859849 118.13091898]\n",
      "reward 0.9983356933577258 done:  True\n",
      "observation: [0.48660714 0.5625     0.65178571 0.19642857 0.79910714 0.51339286\n",
      " 0.30357143 0.69196429 0.71875    0.76785714 0.82142857 0.50892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00729799  0.01888984  0.97976553  0.03430641  0.03231904  0.0206213\n",
      "  0.01834175 -0.8392223   0.07894242]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.12589296192092897, -0.43035702298023226, -0.037266960203647614]\n",
      "action: [7.29799271e-03 8.62508879e+01 6.51051939e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 100, 66] phase_loss 0.0012635817454067072 dis_reward -0.0037967752476332148\n",
      "picked_obj 1\n",
      "43 32\n",
      "action  [ 0.00729799  0.01888984  0.97976553  0.03430641  0.03231904  0.0206213\n",
      "  0.01834175 -0.8392223   0.07894242] real action [7.29799271e-03 8.62508879e+01 6.51051939e+01]\n",
      "reward -0.005060356993039922 done:  False\n",
      "observation: [0.52678571 0.81696429 0.08482143 0.49107143 0.37053571 0.58928571\n",
      " 0.75892857 0.14285714 0.82142857 0.55803571 0.22321429 0.73660714] [ True]\n",
      "[0.98946095 0.01215988 0.01055953 0.37401778 0.9758717  0.08734006\n",
      " 0.03097036 0.20962882 0.03064156]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.21428577192092896, -0.6607140429802323, 0.02456227128952742]\n",
      "place_xyz[2] 0.02456227128952742 False\n",
      "desired_action : [1, 167, 36] phase_loss 0.0019169686142553523 dis_reward -0.0009594812707257417\n",
      "action  [0.98946095 0.01215988 0.01055953 0.37401778 0.9758717  0.08734006\n",
      " 0.03097036 0.20962882 0.03064156] real action [  0.98946095 172.93480349  32.42898178]\n",
      "reward 0.9971235501150189 done:  True\n",
      "observation: [0.51785714 0.80803571 0.82589286 0.14285714 0.37053571 0.58928571\n",
      " 0.75892857 0.14285714 0.82142857 0.55803571 0.22321429 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[0.01020512 0.17961615 0.20169088 0.9841521  0.3270219  0.2372562\n",
      " 0.37997463 0.02724659 0.03382337]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.11250011192092896, -0.5374998229802322, -0.03889161331951618]\n",
      "action: [1.02051198e-02 1.26381452e+02 7.04735272e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 129, 67] phase_loss 0.0018495497537013102 dis_reward -0.0003784436620583916\n",
      "picked_obj 2\n",
      "63 35\n",
      "action  [0.01020512 0.17961615 0.20169088 0.9841521  0.3270219  0.2372562\n",
      " 0.37997463 0.02724659 0.03382337] real action [1.02051198e-02 1.26381452e+02 7.04735272e+01]\n",
      "reward -0.002227993415759702 done:  False\n",
      "observation: [0.25892857 0.40178571 0.35267857 0.78125    0.02678571 0.47767857\n",
      " 0.51785714 0.55357143 0.82589286 0.13392857 0.81696429 0.62946429] [ True]\n",
      "[0.991655   0.01751101 0.00729805 0.28466392 0.97552264 0.11856055\n",
      " 0.02079511 0.19640684 0.01100612]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.03214266807907101, -0.5160712629802322, 0.02335985561460257]\n",
      "place_xyz[2] 0.02335985561460257 False\n",
      "desired_action : [1, 118, 123] phase_loss 0.0014744230568948292 dis_reward -3.7879148298657555e-05\n",
      "action  [0.991655   0.01751101 0.00729805 0.28466392 0.97552264 0.11856055\n",
      " 0.02079511 0.19640684 0.01100612] real action [  0.99165499 118.74969578 124.15408564]\n",
      "reward 0.9984876977948065 done:  True\n",
      "observation: [0.25892857 0.40178571 0.35267857 0.78125    0.54017857 0.54464286\n",
      " 0.51785714 0.55357143 0.82589286 0.13392857 0.81696429 0.62946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[0.00627711 0.40065318 0.97086775 0.29613417 0.23699892 0.30577257\n",
      " 0.3696491  0.9516823  0.17589152]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.14196403807907104, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.001058217460014772 dis_reward -0.004147115366733115\n",
      "action  [0.00627711 0.40065318 0.97086775 0.29613417 0.23699892 0.30577257\n",
      " 0.3696491  0.9516823  0.17589152] real action [6.27711415e-03 1.81323553e+02 1.65462481e+02]\n",
      "reward -0.005205332826747887 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  False\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "[0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.6848211729802323, -0.053500000000000006]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.000955557444785773 dis_reward -0.004112836023520123\n",
      "action  [0.00576639 0.426278   0.97869986 0.38163787 0.25856906 0.3154204\n",
      " 0.35919434 0.98080003 0.08105171] real action [5.76639175e-03 1.81731200e+02 1.64134724e+02]\n",
      "reward -0.005068393468305897 done:  True\n",
      "observation: [0.29910714 0.53125    0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "[ 0.01321653  0.9278877   0.43925107  0.22727063  0.22431514  0.16077691\n",
      "  0.21216655 -0.00175655 -0.85556376]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.07767870192092896, -0.6848211729802323, -0.03721894866228104]\n",
      "pick_success 0\n",
      "desired_action : [0, 178, 98] phase_loss 0.002458352086130694 dis_reward -0.0048028229254259\n",
      "action  [ 0.01321653  0.9278877   0.43925107  0.22727063  0.22431514  0.16077691\n",
      "  0.21216655 -0.00175655 -0.85556376] real action [1.32165253e-02 1.81975408e+02 8.30221071e+01]\n",
      "reward -0.007261175011556594 done:  False\n",
      "observation: [0.8125     0.42410714 0.625      0.67857143 0.42410714 0.52232143\n",
      " 0.22767857 0.14732143 0.53571429 0.23214286 0.28571429 0.75892857] [False]\n",
      "[ 0.01329908  0.9260337   0.4461679   0.22587496  0.22367159  0.16419825\n",
      "  0.20702752  0.00115764 -0.86004037]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.08035727192092895, -0.6874997429802322, -0.03482533974945545]\n",
      "pick_success 0\n",
      "desired_action : [0, 178, 98] phase_loss 0.0024750674665589213 dis_reward -0.004846970575698452\n",
      "action  [ 0.01329908  0.9260337   0.4461679   0.22587496  0.22367159  0.16419825\n",
      "  0.20702752  0.00115764 -0.86004037] real action [1.32990777e-02 1.82016207e+02 8.29594345e+01]\n",
      "reward -0.007322038042257374 done:  False\n",
      "observation: [0.8125     0.42410714 0.625      0.67857143 0.42410714 0.52232143\n",
      " 0.22767857 0.14732143 0.53571429 0.23214286 0.28571429 0.75892857] [False]\n",
      "[ 0.01329908  0.9260337   0.4461679   0.22587496  0.22367159  0.16419825\n",
      "  0.20702752  0.00115764 -0.86004037]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.08035727192092895, -0.6874997429802322, -0.04126743210852146]\n",
      "action: [1.32990777e-02 1.82016207e+02 8.29594345e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 178, 98] phase_loss 0.0024750674665589213 dis_reward -0.004846970575698452\n",
      "picked_obj 0\n",
      "91 41\n",
      "action  [ 0.01329908  0.9260337   0.4461679   0.22587496  0.22367159  0.16419825\n",
      "  0.20702752  0.00115764 -0.86004037] real action [1.32990777e-02 1.82016207e+02 8.29594345e+01]\n",
      "reward -0.007322038042257374 done:  False\n",
      "observation: [0.00446429 0.56696429 0.625      0.67857143 0.42410714 0.52232143\n",
      " 0.22767857 0.14732143 0.53571429 0.23214286 0.28571429 0.75892857] [ True]\n",
      "[ 0.9928863   0.00548178  0.22068247  0.01643759  0.06583491  0.9629258\n",
      "  0.17616725  0.07529712 -0.34905553]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.17410722192092895, -0.5241069729802322, 0.021880585677921775]\n",
      "place_xyz[2] 0.021880585677921775 False\n",
      "desired_action : [1, 120, 54] phase_loss 0.0012264920601741708 dis_reward -0.0009707791103958242\n",
      "action  [ 0.9928863   0.00548178  0.22068247  0.01643759  0.06583491  0.9629258\n",
      "  0.17616725  0.07529712 -0.34905553] real action [  0.9928863  121.05415964  47.1132226 ]\n",
      "reward 0.99780272882943 done:  True\n",
      "observation: [0.51339286 0.26339286 0.625      0.67857143 0.42410714 0.52232143\n",
      " 0.22767857 0.14732143 0.53571429 0.23214286 0.28571429 0.75892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.01007724  0.14902437  0.95024997  0.40918696  0.07774994  0.19256002\n",
      "  0.049427   -0.6784455   0.4910277 ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.08839263807907105, -0.6660711829802322, -0.04059671035408974]\n",
      "action: [1.00772381e-02 1.74501762e+02 1.45874388e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 180, 138] phase_loss 0.0018237374456654175 dis_reward -0.0018447319822305142\n",
      "picked_obj 1\n",
      "87 72\n",
      "action  [ 0.01007724  0.14902437  0.95024997  0.40918696  0.07774994  0.19256002\n",
      "  0.049427   -0.6784455   0.4910277 ] real action [1.00772381e-02 1.74501762e+02 1.45874388e+02]\n",
      "reward -0.003668469427895932 done:  False\n",
      "observation: [0.81696429 0.33482143 0.04910714 0.45089286 0.44196429 0.24553571\n",
      " 0.56696429 0.73214286 0.34821429 0.52232143 0.19642857 0.27678571] [ True]\n",
      "[0.99127305 0.00593692 0.10271013 0.01567549 0.01638022 0.97624266\n",
      " 0.11127689 0.03953338 0.01441145]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.013392678079071019, -0.4089284629802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 78, 119] phase_loss 0.0015513924101794435 dis_reward -7.079984140613762e-05\n",
      "action  [0.99127305 0.00593692 0.10271013 0.01567549 0.01638022 0.97624266\n",
      " 0.11127689 0.03953338 0.01441145] real action [  0.99127305  78.55346727 117.20176029]\n",
      "reward 0.9983778077484144 done:  True\n",
      "observation: [0.81696429 0.33482143 0.38839286 0.48214286 0.44196429 0.24553571\n",
      " 0.56696429 0.73214286 0.34821429 0.52232143 0.19642857 0.27678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "[ 0.01303598  0.9714213   0.21582797  0.3056153   0.4099438   0.15717179\n",
      "  0.41264915 -0.52425426 -0.42162204]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.06428585192092895, -0.29642852298023226, -0.053500000000000006]\n",
      "action: [1.30359828e-02 3.66604404e+01 8.80972915e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 45, 93] phase_loss 0.002421800356666651 dis_reward -0.0018716960901319956\n",
      "picked_obj 0\n",
      "18 44\n",
      "action  [ 0.01303598  0.9714213   0.21582797  0.3056153   0.4099438   0.15717179\n",
      "  0.41264915 -0.52425426 -0.42162204] real action [1.30359828e-02 3.66604404e+01 8.80972915e+01]\n",
      "reward -0.004293496446798647 done:  False\n",
      "observation: [0.02232143 0.53125    0.43303571 0.67410714 0.73214286 0.28571429\n",
      " 0.69196429 0.67857143 0.47321429 0.31696429 0.30803571 0.13839286] [ True]\n",
      "[ 0.9907646   0.09949908  0.0305379   0.4781358   0.02100846  0.09761143\n",
      "  0.99391955 -0.19780833 -0.45951563]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.23571433192092894, -0.3767856229802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 65, 29] phase_loss 0.0016538960350706653 dis_reward -0.0004233602352490198\n",
      "action  [ 0.9907646   0.09949908  0.0305379   0.4781358   0.02100846  0.09761143\n",
      "  0.99391955 -0.19780833 -0.45951563] real action [ 0.99076462 66.23068333 24.56678104]\n",
      "reward 0.9979227437296803 done:  True\n",
      "observation: [0.32142857 0.13392857 0.43303571 0.67410714 0.73214286 0.28571429\n",
      " 0.69196429 0.67857143 0.47321429 0.31696429 0.30803571 0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[0.00658011 0.42263174 0.97720855 0.5117498  0.23208717 0.36364508\n",
      " 0.31517735 0.9741746  0.14257193]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.07767835807907103, -0.5187498329802323, -0.038894513458013535]\n",
      "action: [6.58011436e-03 1.19638445e+02 1.41996007e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 106, 137] phase_loss 0.0011191482727051928 dis_reward -0.004219345298100324\n",
      "picked_obj 1\n",
      "59 70\n",
      "action  [0.00658011 0.42263174 0.97720855 0.5117498  0.23208717 0.36364508\n",
      " 0.31517735 0.9741746  0.14257193] real action [6.58011436e-03 1.19638445e+02 1.41996007e+02]\n",
      "reward -0.005338493570805517 done:  False\n",
      "observation: [ 0.41964286  0.24107143 -0.05357143  0.48660714  0.8125      0.33928571\n",
      "  0.67857143  0.70089286  0.18303571  0.68303571  0.20089286  0.40178571] [ True]\n",
      "[ 0.9931873   0.00557059  0.10512525  0.01363283  0.0194501   0.97723293\n",
      "  0.13172805  0.09475541 -0.03637356]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.10714262807907105, -0.3124999429802322, 0.022539681732654575]\n",
      "place_xyz[2] 0.022539681732654575 False\n",
      "desired_action : [1, 42, 155] phase_loss 0.001165930226563542 dis_reward -0.0001280577161899376\n",
      "action  [ 0.9931873   0.00557059  0.10512525  0.01363283  0.0194501   0.97723293\n",
      "  0.13172805  0.09475541 -0.03637356] real action [  0.99318731  42.32657576 152.49077022]\n",
      "reward 0.9987060120572465 done:  True\n",
      "observation: [0.41964286 0.24107143 0.125      0.65625    0.8125     0.33928571\n",
      " 0.67857143 0.70089286 0.18303571 0.68303571 0.20089286 0.40178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[ 0.00688297  0.24101782  0.3554467   0.98963535  0.1417506   0.52804863\n",
      "  0.3291682  -0.03085816  0.11448061]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.03214301192092894, -0.6526783329802321, -0.04010744749009609]\n",
      "action: [6.88296556e-03 1.69567986e+02 1.00602729e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 170, 101] phase_loss 0.0011800676751841828 dis_reward -6.889217066520814e-06\n",
      "picked_obj 2\n",
      "84 50\n",
      "action  [ 0.00688297  0.24101782  0.3554467   0.98963535  0.1417506   0.52804863\n",
      "  0.3291682  -0.03085816  0.11448061] real action [6.88296556e-03 1.69567986e+02 1.00602729e+02]\n",
      "reward -0.0011869568922507035 done:  False\n",
      "observation: [0.75446429 0.72767857 0.4375     0.41517857 0.02232143 0.49553571\n",
      " 0.20982143 0.25892857 0.24553571 0.74553571 0.62946429 0.15178571] [ True]\n",
      "[ 0.9926274   0.02241787  0.00648695  0.28277975  0.94771063  0.1259751\n",
      "  0.01972336  0.25760818 -0.10419905]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.15000009192092895, -0.33392850298023224, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 44, 61] phase_loss 0.0012786019057657164 dis_reward -0.0012705362459473095\n",
      "action  [ 0.9926274   0.02241787  0.00648695  0.28277975  0.94771063  0.1259751\n",
      "  0.01972336  0.25760818 -0.10419905] real action [ 0.99262738 50.60651445 56.54121327]\n",
      "reward 0.997450861848287 done:  True\n",
      "observation: [0.75446429 0.72767857 0.4375     0.41517857 0.20982143 0.24553571\n",
      " 0.20982143 0.25892857 0.24553571 0.74553571 0.62946429 0.15178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[0.0072163  0.19027135 0.18233144 0.9861487  0.34505802 0.19191366\n",
      " 0.43123648 0.01829231 0.04593039]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.018750161920928987, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.21630454e-03 1.18256092e+02 1.05643025e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 116, 104] phase_loss 0.001247141241588739 dis_reward -0.00015578969940665164\n",
      "picked_obj 2\n",
      "59 52\n",
      "action  [0.0072163  0.19027135 0.18233144 0.9861487  0.34505802 0.19191366\n",
      " 0.43123648 0.01829231 0.04593039] real action [7.21630454e-03 1.18256092e+02 1.05643025e+02]\n",
      "reward -0.0014029309409953907 done:  False\n",
      "observation: [0.46875    0.80803571 0.76339286 0.34821429 0.         0.48660714\n",
      " 0.76785714 0.66071429 0.24553571 0.19196429 0.18303571 0.45982143] [ True]\n",
      "[0.99407953 0.0268009  0.00655338 0.24042776 0.95283335 0.11862859\n",
      " 0.01763386 0.23545468 0.03100216]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.09642834807907102, -0.6687497529802322, 0.025250046491622928]\n",
      "place_xyz[2] 0.025250046491622928 False\n",
      "desired_action : [1, 176, 150] phase_loss 0.00098652302584393 dis_reward -5.894725258196786e-05\n",
      "action  [0.99407953 0.0268009  0.00655338 0.24042776 0.95283335 0.11862859\n",
      " 0.01763386 0.23545468 0.03100216] real action [  0.99407953 175.2963655  148.43403029]\n",
      "reward 0.9989545297215741 done:  True\n",
      "observation: [0.46875    0.80803571 0.76339286 0.34821429 0.77678571 0.65625\n",
      " 0.76785714 0.66071429 0.24553571 0.19196429 0.18303571 0.45982143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "[ 0.01509967  0.93298763  0.36283416  0.2336976   0.3394535   0.25151423\n",
      "  0.25779286 -0.23884326 -0.7082782 ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.08035692807907102, -0.43035702298023226, -0.040416447281837464]\n",
      "action: [1.50996745e-02 8.66561942e+01 1.42084105e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 92, 154] phase_loss 0.002840003841750917 dis_reward -0.0034108960451016755\n",
      "picked_obj 0\n",
      "43 71\n",
      "action  [ 0.01509967  0.93298763  0.36283416  0.2336976   0.3394535   0.25151423\n",
      "  0.25779286 -0.23884326 -0.7082782 ] real action [1.50996745e-02 8.66561942e+01 1.42084105e+02]\n",
      "reward -0.006250899886852592 done:  False\n",
      "observation: [0.04017857 0.53571429 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67857143 0.73214286 0.82142857 0.18303571] [ True]\n",
      "[ 0.9935775   0.0040873   0.21936858  0.01366338  0.07232252  0.9568765\n",
      "  0.14460015  0.20038831 -0.4197681 ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.12321404807907105, -0.6124997829802322, 0.028339867457747463]\n",
      "place_xyz[2] 0.028339867457747463 False\n",
      "desired_action : [1, 153, 163] phase_loss 0.0010874549816403192 dis_reward -0.0005408464707998029\n",
      "action  [ 0.9935775   0.0040873   0.21936858  0.01366338  0.07232252  0.9568765\n",
      "  0.14460015  0.20038831 -0.4197681 ] real action [  0.99357748 154.80543637 158.12324667]\n",
      "reward 0.9983716985475599 done:  True\n",
      "observation: [0.72767857 0.75446429 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67857143 0.73214286 0.82142857 0.18303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "[ 0.01670778  0.9478204   0.27125728  0.22105855  0.386175    0.23684943\n",
      "  0.3290548  -0.38803387 -0.505539  ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.17946436192092896, -0.28035710298023225, -0.053500000000000006]\n",
      "action: [1.67077780e-02 3.05675259e+01 4.59224539e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 41, 54] phase_loss 0.003166490483438953 dis_reward -0.003481665358427655\n",
      "picked_obj 0\n",
      "15 22\n",
      "action  [ 0.01670778  0.9478204   0.27125728  0.22105855  0.386175    0.23684943\n",
      "  0.3290548  -0.38803387 -0.505539  ] real action [1.67077780e-02 3.05675259e+01 4.59224539e+01]\n",
      "reward -0.006648155841866608 done:  False\n",
      "observation: [0.03125    0.52232143 0.60714286 0.65625    0.28125    0.64732143\n",
      " 0.80803571 0.29464286 0.47321429 0.35267857 0.60267857 0.13392857] [ True]\n",
      "[ 0.99396765  0.0037975   0.22248265  0.01239082  0.05330417  0.9701312\n",
      "  0.13703987  0.15988374 -0.36786807]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.10446440192092896, -0.48928556298023224, 0.023592676945030693]\n",
      "place_xyz[2] 0.023592676945030693 False\n",
      "desired_action : [1, 108, 82] phase_loss 0.0010090105164605808 dis_reward -0.0013296363579752735\n",
      "action  [ 0.99396765  0.0037975   0.22248265  0.01239082  0.05330417  0.9701312\n",
      "  0.13703987  0.15988374 -0.36786807] real action [  0.99396765 108.23837233  73.84984684]\n",
      "reward 0.9976613531255641 done:  True\n",
      "observation: [0.54017857 0.40178571 0.60714286 0.65625    0.28125    0.64732143\n",
      " 0.80803571 0.29464286 0.47321429 0.35267857 0.60267857 0.13392857] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[ 0.01154894  0.5287883   0.9147747   0.12546906  0.40626585  0.5162731\n",
      "  0.35703552  0.8044894  -0.15116978]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.03749980807907105, -0.33660707298023224, -0.042695553809404374]\n",
      "action: [1.15489364e-02 5.12628517e+01 1.26883623e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 43, 132] phase_loss 0.002120994162772405 dis_reward -0.0018890406162260479\n",
      "picked_obj 1\n",
      "25 63\n",
      "action  [ 0.01154894  0.5287883   0.9147747   0.12546906  0.40626585  0.5162731\n",
      "  0.35703552  0.8044894  -0.15116978] real action [1.15489364e-02 5.12628517e+01 1.26883623e+02]\n",
      "reward -0.004010034778998453 done:  False\n",
      "observation: [ 0.45982143  0.24107143 -0.01785714  0.53125     0.58482143  0.66517857\n",
      "  0.80803571  0.17410714  0.21428571  0.18303571  0.82589286  0.75      ] [ True]\n",
      "[0.98666596 0.04791486 0.01575422 0.51440054 0.03582129 0.07066238\n",
      " 0.9945072  0.30870485 0.10515535]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.152678318079071, -0.7062497329802322, 0.026686313539743427]\n",
      "place_xyz[2] 0.026686313539743427 False\n",
      "desired_action : [1, 186, 170] phase_loss 0.0024821462779747645 dis_reward -0.00022626811967445173\n",
      "action  [0.98666596 0.04791486 0.01575422 0.51440054 0.03582129 0.07066238\n",
      " 0.9945072  0.30870485 0.10515535] real action [  0.98666596 189.32186794 169.47217488]\n",
      "reward 0.9972915856023508 done:  True\n",
      "observation: [0.45982143 0.24107143 0.80803571 0.77678571 0.58482143 0.66517857\n",
      " 0.80803571 0.17410714 0.21428571 0.18303571 0.82589286 0.75      ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00714746  0.46277553  0.94899553  0.03297228  0.31990492  0.4857476\n",
      "  0.46192995  0.9654794  -0.2332232 ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.15535688807907105, -0.3821427629802322, -0.03956781870126724]\n",
      "action: [7.14746118e-03 6.85167112e+01 1.70734875e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 54, 176] phase_loss 0.0012332869228646847 dis_reward -0.004769128884367042\n",
      "picked_obj 1\n",
      "34 85\n",
      "action  [ 0.00714746  0.46277553  0.94899553  0.03297228  0.31990492  0.4857476\n",
      "  0.46192995  0.9654794  -0.2332232 ] real action [7.14746118e-03 6.85167112e+01 1.70734875e+02]\n",
      "reward -0.006002415807231727 done:  False\n",
      "observation: [ 0.66964286  0.36160714 -0.05357143  0.53125     0.44642857  0.62053571\n",
      "  0.80357143  0.75        0.22767857  0.29017857  0.44642857  0.17857143] [ True]\n",
      "[ 0.9914392   0.01246727  0.00688455  0.35763562  0.9730199   0.08413589\n",
      "  0.02367672  0.23553538 -0.03268623]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.14732117807907102, -0.6901783129802322, 0.025327987946569923]\n",
      "place_xyz[2] 0.025327987946569923 False\n",
      "desired_action : [1, 178, 172] phase_loss 0.0015179008552307482 dis_reward -0.0009586743942182192\n",
      "action  [ 0.9914392   0.01246727  0.00688455  0.35763562  0.9730199   0.08413589\n",
      "  0.02367672  0.23553538 -0.03268623] real action [  0.99143922 183.29749537 167.54239273]\n",
      "reward 0.997523424750551 done:  True\n",
      "observation: [0.66964286 0.36160714 0.74553571 0.75892857 0.44642857 0.62053571\n",
      " 0.80357143 0.75       0.22767857 0.29017857 0.44642857 0.17857143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[0.01066372 0.1878381  0.29187128 0.98722833 0.19510779 0.47365126\n",
      " 0.2342523  0.00403917 0.02445078]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.15803545807907105, -0.4785712829802322, -0.053500000000000006]\n",
      "action: [1.06637180e-02 1.04056548e+02 1.71342311e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 103, 173] phase_loss 0.001942142945681907 dis_reward -7.728455129737201e-05\n",
      "picked_obj 2\n",
      "52 85\n",
      "action  [0.01066372 0.1878381  0.29187128 0.98722833 0.19510779 0.47365126\n",
      " 0.2342523  0.00403917 0.02445078] real action [1.06637180e-02 1.04056548e+02 1.71342311e+02]\n",
      "reward -0.0020194274969792788 done:  False\n",
      "observation: [0.67857143 0.5        0.16071429 0.43303571 0.00446429 0.50892857\n",
      " 0.41964286 0.3125     0.20982143 0.66517857 0.79017857 0.13839286] [ True]\n",
      "[9.9051619e-01 1.8933445e-02 7.7069402e-03 1.9176894e-01 9.6734029e-01\n",
      " 1.5047276e-01 1.9393116e-02 2.4888623e-01 6.6637993e-05]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.11250011192092896, -0.4598212929802322, 0.022692614212632183]\n",
      "place_xyz[2] 0.022692614212632183 False\n",
      "desired_action : [1, 95, 72] phase_loss 0.0017040013273242243 dis_reward -0.00020337096422270637\n",
      "action  [9.9051619e-01 1.8933445e-02 7.7069402e-03 1.9176894e-01 9.6734029e-01\n",
      " 1.5047276e-01 1.9393116e-02 2.4888623e-01 6.6637993e-05] real action [ 0.99051619 97.48440719 70.00093293]\n",
      "reward 0.9980926277084531 done:  True\n",
      "observation: [0.67857143 0.5        0.16071429 0.43303571 0.42410714 0.3125\n",
      " 0.41964286 0.3125     0.20982143 0.66517857 0.79017857 0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "[ 0.01147562  0.93569034  0.41297287  0.21533841  0.32902896  0.14951676\n",
      "  0.2585985  -0.06852722 -0.807917  ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.010714108079071027, -0.35267849298023224, -0.04149281030893326]\n",
      "action: [1.14756227e-02 5.70406189e+01 1.16689162e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 60, 127] phase_loss 0.0021061756437369184 dis_reward -0.002301426230666128\n",
      "picked_obj 0\n",
      "28 58\n",
      "action  [ 0.01147562  0.93569034  0.41297287  0.21533841  0.32902896  0.14951676\n",
      "  0.2585985  -0.06852722 -0.807917  ] real action [1.14756227e-02 5.70406189e+01 1.16689162e+02]\n",
      "reward -0.004407601874403047 done:  False\n",
      "observation: [0.03571429 0.54910714 0.45089286 0.25892857 0.6875     0.46875\n",
      " 0.82142857 0.74107143 0.44196429 0.73660714 0.19642857 0.15178571] [ True]\n",
      "[ 0.99333453  0.00441381  0.22968507  0.01467249  0.07115269  0.96645725\n",
      "  0.16082346  0.1719737  -0.38588822]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.12589261807907104, -0.47053557298023224, 0.02346113415062428]\n",
      "place_xyz[2] 0.02346113415062428 False\n",
      "desired_action : [1, 100, 165] phase_loss 0.0011363155711153238 dis_reward -0.0006233546938633844\n",
      "action  [ 0.99333453  0.00441381  0.22968507  0.01467249  0.07115269  0.96645725\n",
      "  0.16082346  0.1719737  -0.38588822] real action [  0.99333453 101.40763187 159.5975647 ]\n",
      "reward 0.9982403297350213 done:  True\n",
      "observation: [0.45535714 0.77678571 0.45089286 0.25892857 0.6875     0.46875\n",
      " 0.82142857 0.74107143 0.44196429 0.73660714 0.19642857 0.15178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[ 0.01112697  0.20340675  0.32148218  0.9866565   0.16544425  0.44613504\n",
      "  0.32542318 -0.01951998  0.09384549]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.17678579192092897, -0.3071428029802322, -0.053500000000000006]\n",
      "action: [1.11269653e-02 4.07267202e+01 4.63138368e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 43, 45] phase_loss 0.0020357183679832118 dis_reward -0.00013787936314118185\n",
      "picked_obj 2\n",
      "20 23\n",
      "action  [ 0.01112697  0.20340675  0.32148218  0.9866565   0.16544425  0.44613504\n",
      "  0.32542318 -0.01951998  0.09384549] real action [1.11269653e-02 4.07267202e+01 4.63138368e+01]\n",
      "reward -0.0021735977311243934 done:  False\n",
      "observation: [0.80803571 0.71875    0.43303571 0.29464286 0.00446429 0.48214286\n",
      " 0.46875    0.76339286 0.32589286 0.54017857 0.75446429 0.37053571] [ True]\n",
      "[ 0.993181    0.02139077  0.00665179  0.24402153  0.9501077   0.13517529\n",
      "  0.01924765  0.26158774 -0.078336  ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.152678318079071, -0.48928556298023224, 0.02401241192221642]\n",
      "place_xyz[2] 0.02401241192221642 False\n",
      "desired_action : [1, 109, 174] phase_loss 0.0011672012370399977 dis_reward -0.0003379414680941557\n",
      "action  [ 0.993181    0.02139077  0.00665179  0.24402153  0.9501077   0.13517529\n",
      "  0.01924765  0.26158774 -0.078336  ] real action [  0.99318099 108.66222835 169.90329599]\n",
      "reward 0.9984948572948659 done:  True\n",
      "observation: [0.80803571 0.71875    0.43303571 0.29464286 0.49107143 0.77232143\n",
      " 0.46875    0.76339286 0.32589286 0.54017857 0.75446429 0.37053571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "[ 0.0124104   0.961589    0.311706    0.32193238  0.36393026  0.18738496\n",
      "  0.39457145 -0.38470858 -0.5420636 ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.10714262807907105, -0.4598212929802322, -0.03807977198064327]\n",
      "action: [1.24104023e-02 9.76140800e+01 1.52411110e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 103, 164] phase_loss 0.0022952000832559528 dis_reward -0.003266210158942818\n",
      "picked_obj 0\n",
      "48 76\n",
      "action  [ 0.0124104   0.961589    0.311706    0.32193238  0.36393026  0.18738496\n",
      "  0.39457145 -0.38470858 -0.5420636 ] real action [1.24104023e-02 9.76140800e+01 1.52411110e+02]\n",
      "reward -0.005561410242198771 done:  False\n",
      "observation: [0.01785714 0.5625     0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [ True]\n",
      "[ 0.99105954  0.10459667  0.02938113  0.4931233   0.02119067  0.07175779\n",
      "  0.9947506  -0.15445244 -0.4383356 ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.23303576192092895, -0.29642852298023226, 0.024222059153020385]\n",
      "place_xyz[2] 0.024222059153020385 False\n",
      "desired_action : [1, 40, 36] phase_loss 0.0015944303242432481 dis_reward -0.0022550601789304405\n",
      "action  [ 0.99105954  0.10459667  0.02938113  0.4931233   0.02119067  0.07175779\n",
      "  0.9947506  -0.15445244 -0.4383356 ] real action [ 0.99105954 36.8376658  25.86330175]\n",
      "reward 0.9961505094968263 done:  True\n",
      "observation: [0.17857143 0.16071429 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.00699148  0.35699677  0.9453286   0.08929166  0.3957979   0.484715\n",
      "  0.33699661  0.83347166 -0.19505668]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.20892863192092898, -0.3419642129802323, -0.03854233755171299]\n",
      "action: [6.99147582e-03 5.36686029e+01 3.42692065e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 42, 39] phase_loss 0.0012018993458150762 dis_reward -0.0031707340312950917\n",
      "picked_obj 1\n",
      "26 17\n",
      "action  [ 0.00699148  0.35699677  0.9453286   0.08929166  0.3957979   0.484715\n",
      "  0.33699661  0.83347166 -0.19505668] real action [6.99147582e-03 5.36686029e+01 3.42692065e+01]\n",
      "reward -0.004372633377110168 done:  False\n",
      "observation: [ 0.58482143  0.45089286 -0.03571429  0.51339286  0.33035714  0.69642857\n",
      "  0.8125      0.57142857  0.5625      0.16071429  0.84821429  0.27678571] [ True]\n",
      "[0.9919126  0.00552955 0.09285468 0.01370436 0.01515916 0.9761167\n",
      " 0.09780812 0.03727841 0.02610946]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.20357149192092897, -0.5374998229802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 126, 34] phase_loss 0.0014225263041978409 dis_reward -0.00011736241666386382\n",
      "action  [0.9919126  0.00552955 0.09285468 0.01370436 0.01515916 0.9761167\n",
      " 0.09780812 0.03727841 0.02610946] real action [  0.9919126  126.52189779  36.3655324 ]\n",
      "reward 0.9984601112791383 done:  True\n",
      "observation: [0.58482143 0.45089286 0.50446429 0.17857143 0.33035714 0.69642857\n",
      " 0.8125     0.57142857 0.5625     0.16071429 0.84821429 0.27678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "[ 0.01221761  0.96559817  0.24600717  0.3596043   0.3394029   0.17196989\n",
      "  0.45923337 -0.4051968  -0.46784532]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.17678579192092897, -0.30178566298023224, -0.053500000000000006]\n",
      "action: [1.22176111e-02 3.83272448e+01 4.64501657e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 42, 51] phase_loss 0.002256200597991534 dis_reward -0.0006838024555686936\n",
      "picked_obj 0\n",
      "19 23\n",
      "action  [ 0.01221761  0.96559817  0.24600717  0.3596043   0.3394029   0.17196989\n",
      "  0.45923337 -0.4051968  -0.46784532] real action [1.22176111e-02 3.83272448e+01 4.64501657e+01]\n",
      "reward -0.002940003053560228 done:  False\n",
      "observation: [0.02232143 0.50892857 0.67410714 0.49107143 0.80803571 0.73214286\n",
      " 0.23660714 0.66071429 0.48214286 0.76339286 0.41964286 0.40178571] [ True]\n",
      "[ 0.986526    0.13107464  0.03478828  0.45894268  0.02542013  0.07300395\n",
      "  0.99311346 -0.11992943 -0.36625016]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.07500013192092897, -0.4464284429802322, 0.02483604194223881]\n",
      "place_xyz[2] 0.02483604194223881 False\n",
      "desired_action : [1, 91, 87] phase_loss 0.002510488172398914 dis_reward -0.00012542551550756\n",
      "action  [ 0.986526    0.13107464  0.03478828  0.45894268  0.02542013  0.07300395\n",
      "  0.99311346 -0.11992943 -0.36625016] real action [ 0.98652601 92.32098794 84.87249756]\n",
      "reward 0.9973640863120935 done:  True\n",
      "observation: [0.41964286 0.40625    0.67410714 0.49107143 0.80803571 0.73214286\n",
      " 0.23660714 0.66071429 0.48214286 0.76339286 0.41964286 0.40178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "[ 0.01074752  0.9647416   0.37823302  0.34305942  0.35762036  0.22946662\n",
      "  0.42051882 -0.30672574 -0.5989851 ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.16071402807907104, -0.5482141029802322, -0.03949656507372856]\n",
      "action: [1.07475221e-02 1.30705840e+02 1.72614209e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 137, 184] phase_loss 0.0019590680403408266 dis_reward -0.0033850537484362434\n",
      "picked_obj 0\n",
      "65 86\n",
      "action  [ 0.01074752  0.9647416   0.37823302  0.34305942  0.35762036  0.22946662\n",
      "  0.42051882 -0.30672574 -0.5989851 ] real action [1.07475221e-02 1.30705840e+02 1.72614209e+02]\n",
      "reward -0.00534412178877707 done:  False\n",
      "observation: [0.04017857 0.53571429 0.29017857 0.39732143 0.76785714 0.38839286\n",
      " 0.45982143 0.54910714 0.18303571 0.79464286 0.50446429 0.16964286] [ True]\n",
      "[ 0.99120116  0.11193371  0.02565593  0.502825    0.02272406  0.09197032\n",
      "  0.99513924 -0.20231026 -0.4881389 ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.21696434192092895, -0.4946427029802322, 0.022989653028547767]\n",
      "place_xyz[2] 0.022989653028547767 False\n",
      "desired_action : [1, 112, 40] phase_loss 0.0015658815280213774 dis_reward -0.0016279212734927294\n",
      "action  [ 0.99120116  0.11193371  0.02565593  0.502825    0.02272406  0.09197032\n",
      "  0.99513924 -0.20231026 -0.4881389 ] real action [  0.99120116 110.16765642  31.1660552 ]\n",
      "reward 0.9968061971984858 done:  True\n",
      "observation: [0.53571429 0.17410714 0.29017857 0.39732143 0.76785714 0.38839286\n",
      " 0.45982143 0.54910714 0.18303571 0.79464286 0.50446429 0.16964286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.00867432  0.2335869   0.31811267  0.98758686  0.23160315  0.41610092\n",
      "  0.50308996 -0.01009369  0.10347617]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.13124975807907102, -0.3258927929802322, -0.03993679939210415]\n",
      "action: [8.67432356e-03 4.78586884e+01 1.61448666e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 50, 158] phase_loss 0.00154078454255037 dis_reward -0.0003295703009500461\n",
      "picked_obj 2\n",
      "23 80\n",
      "action  [ 0.00867432  0.2335869   0.31811267  0.98758686  0.23160315  0.41610092\n",
      "  0.50308996 -0.01009369  0.10347617] real action [8.67432356e-03 4.78586884e+01 1.61448666e+02]\n",
      "reward -0.001870354843500416 done:  False\n",
      "observation: [0.68303571 0.23660714 0.45535714 0.53571429 0.         0.46875\n",
      " 0.24553571 0.16517857 0.75       0.42410714 0.71428571 0.73214286] [ True]\n",
      "[0.9938551  0.02909333 0.00882226 0.2716266  0.04712534 0.1516847\n",
      " 0.9875114  0.12474465 0.2681756 ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.14732117807907102, -0.6312497729802322, 0.025425366103649143]\n",
      "place_xyz[2] 0.025425366103649143 False\n",
      "desired_action : [1, 163, 166] phase_loss 0.001031632344111144 dis_reward -9.299148547108871e-05\n",
      "action  [0.9938551  0.02909333 0.00882226 0.2716266  0.04712534 0.1516847\n",
      " 0.9875114  0.12474465 0.2681756 ] real action [  0.99385512 161.74642515 167.75445843]\n",
      "reward 0.9988753761704178 done:  True\n",
      "observation: [0.68303571 0.23660714 0.45535714 0.53571429 0.72321429 0.71875\n",
      " 0.24553571 0.16517857 0.75       0.42410714 0.71428571 0.73214286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.0109252   0.01813185  0.9792192   0.05257797  0.0351117   0.03609142\n",
      "  0.02066159 -0.6926203   0.201769  ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.010714108079071027, -0.6419640529802322, -0.03677445261180401]\n",
      "pick_success 0\n",
      "desired_action : [0, 175, 111] phase_loss 0.0019949573499223492 dis_reward -0.0025590715274001028\n",
      "action  [ 0.0109252   0.01813185  0.9792192   0.05257797  0.0351117   0.03609142\n",
      "  0.02066159 -0.6926203   0.201769  ] real action [1.09252036e-02 1.65303316e+02 1.16824766e+02]\n",
      "reward -0.004554028877322452 done:  False\n",
      "observation: [0.53571429 0.41964286 0.78125    0.50892857 0.16964286 0.69642857\n",
      " 0.58035714 0.64732143 0.19196429 0.16071429 0.71875    0.17857143] [False]\n",
      "[ 0.0109252   0.01813185  0.9792192   0.05257797  0.0351117   0.03609142\n",
      "  0.02066159 -0.6926203   0.201769  ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.010714108079071027, -0.6419640529802322, -0.03793179786205292]\n",
      "action: [1.09252036e-02 1.65303316e+02 1.16824766e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 175, 111] phase_loss 0.0019949573499223492 dis_reward -0.0025590715274001028\n",
      "picked_obj 1\n",
      "82 58\n",
      "action  [ 0.0109252   0.01813185  0.9792192   0.05257797  0.0351117   0.03609142\n",
      "  0.02066159 -0.6926203   0.201769  ] real action [1.09252036e-02 1.65303316e+02 1.16824766e+02]\n",
      "reward -0.004554028877322452 done:  False\n",
      "observation: [0.53571429 0.41964286 0.05803571 0.47767857 0.16964286 0.69642857\n",
      " 0.58035714 0.64732143 0.19196429 0.16071429 0.71875    0.17857143] [ True]\n",
      "[0.993214   0.00471252 0.12191761 0.01374027 0.0149096  0.98386025\n",
      " 0.07291871 0.015275   0.0216223 ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.20357149192092897, -0.31517851298023225, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 45, 33] phase_loss 0.0011605584979091587 dis_reward -0.00028196479271807337\n",
      "action  [0.993214   0.00471252 0.12191761 0.01374027 0.0149096  0.98386025\n",
      " 0.07291871 0.015275   0.0216223 ] real action [ 0.99321401 43.21385002 36.3027122 ]\n",
      "reward 0.9985574767093728 done:  True\n",
      "observation: [0.53571429 0.41964286 0.24107143 0.14285714 0.16964286 0.69642857\n",
      " 0.58035714 0.64732143 0.19196429 0.16071429 0.71875    0.17857143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00681636  0.3121277   0.88986593  0.264781    0.17060494  0.29853892\n",
      "  0.04605287 -0.8560117   0.39965713]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.09107155192092897, -0.44910701298023226, -0.040588751271367074]\n",
      "action: [6.81635737e-03 9.30158367e+01 7.85951996e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 102, 76] phase_loss 0.0011666676514694857 dis_reward -0.001749005016095544\n",
      "picked_obj 1\n",
      "46 39\n",
      "action  [ 0.00681636  0.3121277   0.88986593  0.264781    0.17060494  0.29853892\n",
      "  0.04605287 -0.8560117   0.39965713] real action [6.81635737e-03 9.30158367e+01 7.85951996e+01]\n",
      "reward -0.0029156726675650295 done:  False\n",
      "observation: [0.72321429 0.77678571 0.04910714 0.47767857 0.54910714 0.59375\n",
      " 0.72767857 0.28571429 0.19196429 0.20982143 0.20089286 0.54017857] [ True]\n",
      "[0.98967385 0.012752   0.00794661 0.36525536 0.9738091  0.08573955\n",
      " 0.02758595 0.19189441 0.01907325]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.12857153192092896, -0.6419640529802322, 0.022793689720332626]\n",
      "place_xyz[2] 0.022793689720332626 False\n",
      "desired_action : [1, 167, 63] phase_loss 0.0018739815762876364 dis_reward -6.661157215856861e-05\n",
      "action  [0.98967385 0.012752   0.00794661 0.36525536 0.9738091  0.08573955\n",
      " 0.02758595 0.19189441 0.01907325] real action [  0.98967385 165.68652177  64.26702547]\n",
      "reward 0.9980594068515538 done:  True\n",
      "observation: [0.72321429 0.77678571 0.75892857 0.27678571 0.54910714 0.59375\n",
      " 0.72767857 0.28571429 0.19196429 0.20982143 0.20089286 0.54017857] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.00978851  0.05545643  0.9739057   0.18255365  0.03467873  0.05040583\n",
      "  0.02870715 -0.6633854   0.18712986]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.02946409807907102, -0.42232131298023223, -0.037349793896079064]\n",
      "action: [9.78851318e-03 8.37126045e+01 1.23619818e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 96, 124] phase_loss 0.0017654719873053662 dis_reward -0.003022492519794452\n",
      "picked_obj 1\n",
      "41 61\n",
      "action  [ 0.00978851  0.05545643  0.9739057   0.18255365  0.03467873  0.05040583\n",
      "  0.02870715 -0.6633854   0.18712986] real action [9.78851318e-03 8.37126045e+01 1.23619818e+02]\n",
      "reward -0.004787964507099818 done:  False\n",
      "observation: [0.80357143 0.51785714 0.05803571 0.51339286 0.45535714 0.24107143\n",
      " 0.66071429 0.75       0.82589286 0.12946429 0.24553571 0.76785714] [ True]\n",
      "[ 0.9921851   0.00525436  0.10584155  0.01346716  0.01756886  0.97970605\n",
      "  0.10337323  0.05770051 -0.00837559]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.22500005192092895, -0.6955354529802322, 0.022380595073103908]\n",
      "place_xyz[2] 0.022380595073103908 False\n",
      "desired_action : [1, 186, 31] phase_loss 0.0013676423103258695 dis_reward -9.039440634913375e-05\n",
      "action  [ 0.9921851   0.00525436  0.10584155  0.01346716  0.01756886  0.97970605\n",
      "  0.10337323  0.05770051 -0.00837559] real action [  0.99218512 185.80780721  28.88274181]\n",
      "reward 0.998541963283325 done:  True\n",
      "observation: [0.80357143 0.51785714 0.89732143 0.15178571 0.45535714 0.24107143\n",
      " 0.66071429 0.75       0.82589286 0.12946429 0.24553571 0.76785714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.00928447  0.18184054  0.28525656  0.9880188   0.37332684  0.40495133\n",
      "  0.3946532  -0.00212049  0.09518433]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.08035727192092895, -0.5642855229802322, -0.042761457920074464]\n",
      "action: [9.28446651e-03 1.36970313e+02 8.23325806e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 136, 83] phase_loss 0.001663794682142589 dis_reward -2.7739123168594234e-05\n",
      "picked_obj 2\n",
      "68 41\n",
      "action  [ 0.00928447  0.18184054  0.28525656  0.9880188   0.37332684  0.40495133\n",
      "  0.3946532  -0.00212049  0.09518433] real action [9.28446651e-03 1.36970313e+02 8.23325806e+01]\n",
      "reward -0.0016915338053111832 done:  False\n",
      "observation: [ 0.73214286  0.72321429  0.40625     0.78125    -0.00892857  0.50446429\n",
      "  0.26339286  0.43303571  0.34821429  0.13392857  0.82142857  0.13839286] [ True]\n",
      "[0.99412215 0.02763781 0.00748011 0.2859226  0.04784739 0.16039395\n",
      " 0.98727965 0.09831834 0.2781558 ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.20892863192092898, -0.6955354529802322, 0.024591173954308036]\n",
      "place_xyz[2] 0.024591173954308036 False\n",
      "desired_action : [1, 185, 31] phase_loss 0.000977957598229972 dis_reward -0.00030612734589917183\n",
      "action  [0.99412215 0.02763781 0.00748011 0.2859226  0.04784739 0.16039395\n",
      " 0.98727965 0.09831834 0.2781558 ] real action [  0.99412215 185.37645674  34.89418125]\n",
      "reward 0.9987159150558709 done:  True\n",
      "observation: [0.73214286 0.72321429 0.40625    0.78125    0.82589286 0.15178571\n",
      " 0.26339286 0.43303571 0.34821429 0.13392857 0.82142857 0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01129246  0.95518285  0.37544033  0.17027423  0.30986816  0.14274272\n",
      "  0.41423059 -0.5020524  -0.2720204 ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.20357149192092897, -0.48928556298023224, -0.03919902613759041]\n",
      "action: [1.12924576e-02 1.08971266e+02 3.61917143e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 114, 42] phase_loss 0.0020691582387348056 dis_reward -0.0011804870130461649\n",
      "picked_obj 0\n",
      "54 18\n",
      "action  [ 0.01129246  0.95518285  0.37544033  0.17027423  0.30986816  0.14274272\n",
      "  0.41423059 -0.5020524  -0.2720204 ] real action [1.12924576e-02 1.08971266e+02 3.61917143e+01]\n",
      "reward -0.0032496452517809704 done:  False\n",
      "observation: [0.02232143 0.51785714 0.55357143 0.73660714 0.20089286 0.33482143\n",
      " 0.82589286 0.53571429 0.81696429 0.25892857 0.24553571 0.72767857] [ True]\n",
      "[ 0.9829054   0.01040515  0.00779396  0.23291141  0.9132198   0.09589472\n",
      "  0.01737237 -0.06491166 -0.13278985]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.01607124807907101, -0.6928568829802322, 0.025982410624623302]\n",
      "place_xyz[2] 0.025982410624623302 False\n",
      "desired_action : [1, 184, 124] phase_loss 0.0032451074165410414 dis_reward -0.000686737673029086\n",
      "action  [ 0.9829054   0.01040515  0.00779396  0.23291141  0.9132198   0.09589472\n",
      "  0.01737237 -0.06491166 -0.13278985] real action [  0.98290539 184.09123671 118.1409421 ]\n",
      "reward 0.9960681549104299 done:  True\n",
      "observation: [0.84821429 0.55357143 0.55357143 0.73660714 0.20089286 0.33482143\n",
      " 0.82589286 0.53571429 0.81696429 0.25892857 0.24553571 0.72767857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "[ 0.00823095  0.9629413   0.42882678  0.36452508  0.2883296   0.22273046\n",
      "  0.38813177 -0.24775904 -0.664459  ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.01339302192092895, -0.5348212529802323, -0.039902394473552705]\n",
      "action: [8.23095441e-03 1.25531374e+02 1.07697575e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 127, 120] phase_loss 0.0014514448949026768 dis_reward -0.003070130682716013\n",
      "picked_obj 0\n",
      "62 53\n",
      "action  [ 0.00823095  0.9629413   0.42882678  0.36452508  0.2883296   0.22273046\n",
      "  0.38813177 -0.24775904 -0.664459  ] real action [8.23095441e-03 1.25531374e+02 1.07697575e+02]\n",
      "reward -0.00452157557761869 done:  False\n",
      "observation: [0.01785714 0.55803571 0.49553571 0.19196429 0.83035714 0.53571429\n",
      " 0.22321429 0.76339286 0.21875    0.15625    0.5625     0.75892857] [ True]\n",
      "[ 0.9878634   0.13649344  0.03202948  0.4701615   0.0258773   0.07679999\n",
      "  0.99383247 -0.13112187 -0.37733567]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [0.13928546807907105, -0.5321426829802323, 0.02364395742863417]\n",
      "place_xyz[2] 0.02364395742863417 False\n",
      "desired_action : [1, 127, 172] phase_loss 0.0022398109059257928 dis_reward -0.0012215788618042689\n",
      "action  [ 0.9878634   0.13649344  0.03202948  0.4701615   0.0258773   0.07679999\n",
      "  0.99383247 -0.13112187 -0.37733567] real action [  0.98786342 124.16429377 164.71730042]\n",
      "reward 0.99653861023227 done:  True\n",
      "observation: [0.55357143 0.79017857 0.49553571 0.19196429 0.83035714 0.53571429\n",
      " 0.22321429 0.76339286 0.21875    0.15625    0.5625     0.75892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[0.00898051 0.3957203  0.97338104 0.3780843  0.25860286 0.38508445\n",
      " 0.2956184  0.97651815 0.08201337]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.03749980807907105, -0.6687497529802322, -0.039372190669178964]\n",
      "action: [8.98051262e-03 1.75671254e+02 1.26148187e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 162, 124] phase_loss 0.0016025054705871942 dis_reward -0.003830357966593643\n",
      "picked_obj 1\n",
      "87 63\n",
      "action  [0.00898051 0.3957203  0.97338104 0.3780843  0.25860286 0.38508445\n",
      " 0.2956184  0.97651815 0.08201337] real action [8.98051262e-03 1.75671254e+02 1.26148187e+02]\n",
      "reward -0.005432863437180837 done:  False\n",
      "observation: [ 0.44642857  0.41517857 -0.02232143  0.47321429  0.70089286  0.20089286\n",
      "  0.375       0.71875     0.22767857  0.17857143  0.67410714  0.75446429] [ True]\n",
      "[0.99188626 0.03762567 0.00839591 0.47609115 0.03621551 0.07295421\n",
      " 0.99545157 0.35824    0.19078803]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.15803545807907105, -0.6178569229802322, 0.024352914631366733]\n",
      "place_xyz[2] 0.024352914631366733 False\n",
      "desired_action : [1, 149, 172] phase_loss 0.0014278330356101692 dis_reward -0.0009864698777673812\n",
      "action  [0.99188626 0.03762567 0.00839591 0.47609115 0.03621551 0.07295421\n",
      " 0.99545157 0.35824    0.19078803] real action [  0.99188626 156.01535988 171.67103243]\n",
      "reward 0.9975856970866225 done:  True\n",
      "observation: [0.44642857 0.41517857 0.625      0.75       0.70089286 0.20089286\n",
      " 0.375      0.71875    0.22767857 0.17857143 0.67410714 0.75446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[0.00893    0.21038681 0.2667854  0.9806407  0.3866157  0.22361183\n",
      " 0.40116164 0.03655827 0.05592251]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.10714297192092898, -0.5026784129802322, -0.053500000000000006]\n",
      "action: [8.92999768e-03 1.13511816e+02 7.27829151e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 111, 72] phase_loss 0.0015923214669481774 dis_reward -0.00013844349244938826\n",
      "picked_obj 2\n",
      "56 36\n",
      "action  [0.00893    0.21038681 0.2667854  0.9806407  0.3866157  0.22361183\n",
      " 0.40116164 0.03655827 0.05592251] real action [8.92999768e-03 1.13511816e+02 7.27829151e+01]\n",
      "reward -0.0017307649593975658 done:  False\n",
      "observation: [0.81696429 0.30357143 0.29910714 0.63392857 0.00892857 0.46875\n",
      " 0.74107143 0.62053571 0.19642857 0.19196429 0.49553571 0.77232143] [ True]\n",
      "[ 0.9933539   0.00767925  0.26232272  0.05089197  0.14727247  0.9578352\n",
      "  0.07425645  0.37283587 -0.19922811]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.19285721192092897, -0.3312499329802322, 0.02017949984967709]\n",
      "place_xyz[2] 0.02017949984967709 False\n",
      "desired_action : [1, 48, 43] phase_loss 0.0011324192323604082 dis_reward -0.00018534549340788547\n",
      "action  [ 0.9933539   0.00767925  0.26232272  0.05089197  0.14727247  0.9578352\n",
      "  0.07425645  0.37283587 -0.19922811] real action [ 0.9933539  49.21970224 40.21080637]\n",
      "reward 0.9986822352742317 done:  True\n",
      "observation: [0.81696429 0.30357143 0.29910714 0.63392857 0.18303571 0.16964286\n",
      " 0.74107143 0.62053571 0.19642857 0.19196429 0.49553571 0.77232143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.11249976807907103, -0.46785700298023225, -0.053500000000000006]\n",
      "action: [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 103, 151] phase_loss 0.0018150338364995274 dis_reward -0.0004232742750419129\n",
      "action  [0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608] real action [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "reward -0.00223830811154144 done:  False\n",
      "observation: [0.75446429 0.26785714 0.375      0.39732143 0.44196429 0.6875\n",
      " 0.70535714 0.75892857 0.44196429 0.11607143 0.19196429 0.78571429] [False]\n",
      "[0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.11249976807907103, -0.46785700298023225, -0.053500000000000006]\n",
      "action: [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 103, 151] phase_loss 0.0018150338364995274 dis_reward -0.0004232742750419129\n",
      "action  [0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608] real action [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "reward -0.00223830811154144 done:  False\n",
      "observation: [0.75446429 0.26785714 0.375      0.39732143 0.44196429 0.6875\n",
      " 0.70535714 0.75892857 0.44196429 0.11607143 0.19196429 0.78571429] [False]\n",
      "[0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.11249976807907103, -0.46785700298023225, -0.053500000000000006]\n",
      "action: [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 102, 151] phase_loss 0.0018150338364995274 dis_reward -0.00032814419386515515\n",
      "action  [0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608] real action [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "reward -0.0021431780303646825 done:  False\n",
      "observation: [0.75446429 0.26785714 0.375      0.39732143 0.44196429 0.6875\n",
      " 0.70535714 0.75892857 0.44196429 0.11607143 0.19196429 0.78571429] [False]\n",
      "[0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.11249976807907103, -0.46785700298023225, -0.053500000000000006]\n",
      "action: [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 102, 151] phase_loss 0.0018150338364995274 dis_reward -0.00032814419386515515\n",
      "action  [0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608] real action [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "reward -0.0021431780303646825 done:  False\n",
      "observation: [0.75446429 0.26785714 0.375      0.39732143 0.44196429 0.6875\n",
      " 0.70535714 0.75892857 0.44196429 0.11607143 0.19196429 0.78571429] [False]\n",
      "[0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.11249976807907103, -0.46785700298023225, -0.053500000000000006]\n",
      "action: [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 103, 151] phase_loss 0.0018150338364995274 dis_reward -0.0004232742750419129\n",
      "action  [0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608] real action [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "reward -0.00223830811154144 done:  False\n",
      "observation: [0.75446429 0.26785714 0.375      0.39732143 0.44196429 0.6875\n",
      " 0.70535714 0.75892857 0.44196429 0.11607143 0.19196429 0.78571429] [False]\n",
      "[0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.11249976807907103, -0.46785700298023225, -0.053500000000000006]\n",
      "action: [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 103, 151] phase_loss 0.0018150338364995274 dis_reward -0.0004232742750419129\n",
      "picked_obj 2\n",
      "50 77\n",
      "action  [0.01003411 0.19475156 0.37632453 0.98514646 0.33204395 0.42482764\n",
      " 0.33631897 0.08012486 0.04205608] real action [1.00341141e-02 1.00121748e+02 1.54588785e+02]\n",
      "reward -0.00223830811154144 done:  False\n",
      "observation: [ 0.75446429  0.26785714  0.375       0.39732143 -0.00892857  0.45535714\n",
      "  0.70535714  0.75892857  0.44196429  0.11607143  0.19196429  0.78571429] [ True]\n",
      "[ 0.99514437  0.00616181  0.21942914  0.03263432  0.13876384  0.95472777\n",
      "  0.0796088   0.3052883  -0.2642578 ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.24107147192092895, -0.4758927129802322, 0.024198317877948287]\n",
      "place_xyz[2] 0.024198317877948287 False\n",
      "desired_action : [1, 103, 28] phase_loss 0.0007726169790598737 dis_reward -0.0006512127835061541\n",
      "action  [ 0.99514437  0.00616181  0.21942914  0.03263432  0.13876384  0.95472777\n",
      "  0.0796088   0.3052883  -0.2642578 ] real action [  0.99514437 103.27403641  22.30039096]\n",
      "reward 0.998576170237434 done:  True\n",
      "observation: [0.75446429 0.26785714 0.375      0.39732143 0.45982143 0.07589286\n",
      " 0.70535714 0.75892857 0.44196429 0.11607143 0.19196429 0.78571429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "[ 0.01383561  0.93702185  0.36267233  0.21041867  0.35034907  0.13798004\n",
      "  0.29519242 -0.15819746 -0.73770976]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.02410730192092897, -0.34732135298023226, -0.040693862199783326]\n",
      "action: [1.38356090e-02 5.57852354e+01 1.03672064e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 58, 119] phase_loss 0.002583739429053798 dis_reward -0.004797016190383818\n",
      "picked_obj 0\n",
      "27 51\n",
      "action  [ 0.01383561  0.93702185  0.36267233  0.21041867  0.35034907  0.13798004\n",
      "  0.29519242 -0.15819746 -0.73770976] real action [1.38356090e-02 5.57852354e+01 1.03672064e+02]\n",
      "reward -0.007380755619437617 done:  False\n",
      "observation: [0.01339286 0.56696429 0.60714286 0.61160714 0.58035714 0.20982143\n",
      " 0.82142857 0.29910714 0.20089286 0.15625    0.4375     0.75      ] [ True]\n",
      "[ 0.9929466   0.00396812  0.21818161  0.01408163  0.0569956   0.96990395\n",
      "  0.13985318  0.15376699 -0.34756112]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.21964291192092894, -0.3258927929802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 44, 34] phase_loss 0.0012143542392068912 dis_reward -0.0004976919246702857\n",
      "action  [ 0.9929466   0.00396812  0.21818161  0.01408163  0.0569956   0.96990395\n",
      "  0.13985318  0.15376699 -0.34756112] real action [ 0.99294662 47.15273786 30.13414431]\n",
      "reward 0.9982879538361228 done:  True\n",
      "observation: [0.20089286 0.20982143 0.60714286 0.61160714 0.58035714 0.20982143\n",
      " 0.82142857 0.29910714 0.20089286 0.15625    0.4375     0.75      ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[0.00902745 0.22152025 0.29722968 0.98832405 0.2129004  0.38305008\n",
      " 0.52971435 0.01574719 0.18640316]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.085714068079071, -0.31517851298023225, -0.053500000000000006]\n",
      "action: [9.02745128e-03 4.32204607e+01 1.44609644e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 47, 142] phase_loss 0.0016119689476405694 dis_reward -0.000421903207822254\n",
      "action  [0.00902745 0.22152025 0.29722968 0.98832405 0.2129004  0.38305008\n",
      " 0.52971435 0.01574719 0.18640316] real action [9.02745128e-03 4.32204607e+01 1.44609644e+02]\n",
      "reward -0.0020338721554628235 done:  False\n",
      "observation: [0.8125     0.35267857 0.61607143 0.56696429 0.19196429 0.63392857\n",
      " 0.47321429 0.75892857 0.49107143 0.14285714 0.16071429 0.12946429] [False]\n",
      "[0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.085714068079071, -0.31517851298023225, -0.053500000000000006]\n",
      "action: [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 46, 142] phase_loss 0.0014826254650851217 dis_reward -0.00027022840519904203\n",
      "action  [0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628] real action [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "reward -0.0017528538702841637 done:  False\n",
      "observation: [0.8125     0.35267857 0.61607143 0.56696429 0.19196429 0.63392857\n",
      " 0.47321429 0.75892857 0.49107143 0.14285714 0.16071429 0.12946429] [False]\n",
      "[0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.085714068079071, -0.31517851298023225, -0.053500000000000006]\n",
      "action: [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 45, 142] phase_loss 0.0014826254650851217 dis_reward -0.00017818125744818763\n",
      "action  [0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628] real action [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "reward -0.0016608067225333094 done:  False\n",
      "observation: [0.8125     0.35267857 0.61607143 0.56696429 0.19196429 0.63392857\n",
      " 0.47321429 0.75892857 0.49107143 0.14285714 0.16071429 0.12946429] [False]\n",
      "[0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.085714068079071, -0.31517851298023225, -0.053500000000000006]\n",
      "action: [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 46, 142] phase_loss 0.0014826254650851217 dis_reward -0.00027022840519904203\n",
      "action  [0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628] real action [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "reward -0.0017528538702841637 done:  False\n",
      "observation: [0.8125     0.35267857 0.61607143 0.56696429 0.19196429 0.63392857\n",
      " 0.47321429 0.75892857 0.49107143 0.14285714 0.16071429 0.12946429] [False]\n",
      "[0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.085714068079071, -0.31517851298023225, -0.053500000000000006]\n",
      "action: [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 47, 142] phase_loss 0.0014826254650851217 dis_reward -0.0004022755529498966\n",
      "action  [0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628] real action [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "reward -0.0018849010180350184 done:  False\n",
      "observation: [0.8125     0.35267857 0.61607143 0.56696429 0.19196429 0.63392857\n",
      " 0.47321429 0.75892857 0.49107143 0.14285714 0.16071429 0.12946429] [False]\n",
      "[0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.085714068079071, -0.31517851298023225, -0.053500000000000006]\n",
      "action: [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 48, 142] phase_loss 0.0014826254650851217 dis_reward -0.0005743227007007512\n",
      "action  [0.00838572 0.22958791 0.2877739  0.9893422  0.2130473  0.40954483\n",
      " 0.5285056  0.01420152 0.17000628] real action [8.38571787e-03 4.31988213e+01 1.44380088e+02]\n",
      "reward -0.0020569481657858727 done:  False\n",
      "observation: [0.8125     0.35267857 0.61607143 0.56696429 0.22321429 0.63392857\n",
      " 0.47321429 0.75892857 0.49107143 0.14285714 0.16071429 0.12946429] [False]\n",
      "[0.00752994 0.22917718 0.29603827 0.99026984 0.16893387 0.36026996\n",
      " 0.55999726 0.03518081 0.13157403]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.08303549807907101, -0.33392850298023224, -0.040607638493180276]\n",
      "action: [7.52994418e-03 5.04925313e+01 1.43842036e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 49, 142] phase_loss 0.0013102715073055474 dis_reward -0.00011241496189611667\n",
      "picked_obj 2\n",
      "25 71\n",
      "action  [0.00752994 0.22917718 0.29603827 0.99026984 0.16893387 0.36026996\n",
      " 0.55999726 0.03518081 0.13157403] real action [7.52994418e-03 5.04925313e+01 1.43842036e+02]\n",
      "reward -0.0014226864692016641 done:  False\n",
      "observation: [0.8125     0.35267857 0.61607143 0.56696429 0.01339286 0.46875\n",
      " 0.47321429 0.75892857 0.49107143 0.14285714 0.16071429 0.12946429] [ True]\n",
      "[0.9934933  0.03002739 0.0072684  0.29555777 0.04851183 0.13382563\n",
      " 0.98902017 0.09422421 0.29280353]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.21160720192092897, -0.29910709298023225, 0.02060027883946896]\n",
      "place_xyz[2] 0.02060027883946896 False\n",
      "desired_action : [1, 38, 32] phase_loss 0.001104379820820649 dis_reward -3.343841716291535e-05\n",
      "action  [0.9934933  0.03002739 0.0072684  0.29555777 0.04851183 0.13382563\n",
      " 0.98902017 0.09422421 0.29280353] real action [ 0.99349332 37.319139   33.09924936]\n",
      "reward 0.9988621817620165 done:  True\n",
      "observation: [0.8125     0.35267857 0.61607143 0.56696429 0.14285714 0.13392857\n",
      " 0.47321429 0.75892857 0.49107143 0.14285714 0.16071429 0.12946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[0.00657374 0.43264043 0.9765205  0.5417148  0.23122188 0.33619225\n",
      " 0.30181134 0.97844887 0.13702619]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.01607124807907101, -0.6312497729802322, -0.040926927536726]\n",
      "action: [6.57373667e-03 1.61698284e+02 1.18918367e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 149, 121] phase_loss 0.0011178655798243383 dis_reward -0.0033115923530218703\n",
      "picked_obj 1\n",
      "80 59\n",
      "action  [0.00657374 0.43264043 0.9765205  0.5417148  0.23122188 0.33619225\n",
      " 0.30181134 0.97844887 0.13702619] real action [6.57373667e-03 1.61698284e+02 1.18918367e+02]\n",
      "reward -0.004429457932846209 done:  False\n",
      "observation: [ 0.30357143  0.37053571 -0.01785714  0.5         0.77678571  0.24553571\n",
      "  0.37053571  0.55803571  0.63392857  0.79464286  0.52232143  0.19196429] [ True]\n",
      "[0.99281836 0.00556606 0.09486902 0.01638961 0.0166958  0.9760783\n",
      " 0.13797271 0.05916739 0.01261902]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.17678544807907104, -0.5803569429802322, 0.023572285637259487]\n",
      "place_xyz[2] 0.023572285637259487 False\n",
      "desired_action : [1, 142, 175] phase_loss 0.0012401659819440587 dis_reward -0.00021554722600079912\n",
      "action  [0.99281836 0.00556606 0.09486902 0.01638961 0.0166958  0.9760783\n",
      " 0.13797271 0.05916739 0.01261902] real action [  0.99281836 142.82834339 178.17666626]\n",
      "reward 0.9985442867920551 done:  True\n",
      "observation: [0.30357143 0.37053571 0.59375    0.79464286 0.77678571 0.24553571\n",
      " 0.37053571 0.55803571 0.63392857 0.79464286 0.52232143 0.19196429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[0.00865054 0.22698385 0.96816874 0.35879278 0.27054018 0.345438\n",
      " 0.30184183 0.9693996  0.09432089]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.07232156192092895, -0.6821426029802322, -0.03965610994398594]\n",
      "action: [8.65054131e-03 1.80571594e+02 8.53204925e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 165, 85] phase_loss 0.0015359913644940745 dis_reward -0.004851545251361869\n",
      "picked_obj 1\n",
      "90 42\n",
      "action  [0.00865054 0.22698385 0.96816874 0.35879278 0.27054018 0.345438\n",
      " 0.30184183 0.9693996  0.09432089] real action [8.65054131e-03 1.80571594e+02 8.53204925e+01]\n",
      "reward -0.006387536615855944 done:  False\n",
      "observation: [ 0.23660714  0.77232143 -0.04464286  0.5         0.53571429  0.73214286\n",
      "  0.36607143  0.13839286  0.48214286  0.44642857  0.8125      0.68303571] [ True]\n",
      "[0.9926647  0.04226914 0.00831097 0.4849761  0.03232816 0.11170858\n",
      " 0.9950633  0.26395464 0.10761631]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.11249976807907103, -0.6955354529802322, 0.026234832569956783]\n",
      "place_xyz[2] 0.026234832569956783 False\n",
      "desired_action : [1, 179, 154] phase_loss 0.0012710916845829511 dis_reward -0.0009016916810117265\n",
      "action  [0.9926647  0.04226914 0.00831097 0.4849761  0.03232816 0.11170858\n",
      " 0.9950633  0.26395464 0.10761631] real action [  0.99266469 185.69536495 154.50662827]\n",
      "reward 0.9978272166344053 done:  True\n",
      "observation: [0.23660714 0.77232143 0.75       0.67857143 0.53571429 0.73214286\n",
      " 0.36607143 0.13839286 0.48214286 0.44642857 0.8125     0.68303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.01140857  0.03146365  0.97665125  0.12279889  0.02915969  0.04675081\n",
      "  0.02350372 -0.59356177  0.21050453]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.136606898079071, -0.6017855029802321, -0.03777701950073242]\n",
      "action: [1.14085674e-02 1.50690135e+02 1.63947063e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 157, 162] phase_loss 0.0020926230815145447 dis_reward -0.0008721090470838137\n",
      "picked_obj 1\n",
      "75 81\n",
      "action  [ 0.01140857  0.03146365  0.97665125  0.12279889  0.02915969  0.04675081\n",
      "  0.02350372 -0.59356177  0.21050453] real action [1.14085674e-02 1.50690135e+02 1.63947063e+02]\n",
      "reward -0.0029647321285983584 done:  False\n",
      "observation: [0.56696429 0.29464286 0.03125    0.49107143 0.29910714 0.76339286\n",
      " 0.22767857 0.20535714 0.37946429 0.48660714 0.81696429 0.45535714] [ True]\n",
      "[0.99201494 0.005633   0.10075468 0.01494247 0.01652214 0.97536665\n",
      " 0.09781671 0.04634249 0.02462959]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.008035881920928967, -0.4276784529802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 85, 108] phase_loss 0.0014019130295038012 dis_reward -4.458920623011296e-05\n",
      "action  [0.99201494 0.005633   0.10075468 0.01494247 0.01652214 0.97536665\n",
      " 0.09781671 0.04634249 0.02462959] real action [  0.99201494  85.64879489 109.3448143 ]\n",
      "reward 0.998553497764266 done:  True\n",
      "observation: [0.56696429 0.29464286 0.40625    0.48660714 0.29910714 0.76339286\n",
      " 0.22767857 0.20535714 0.37946429 0.48660714 0.81696429 0.45535714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00788534  0.43418342  0.9660324   0.33132476  0.36164373  0.35841265\n",
      "  0.35035777  0.97609043 -0.02189201]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.013392678079071019, -0.5883926529802322, -0.03892024217545986]\n",
      "action: [7.88533688e-03 1.45665266e+02 1.17693512e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 132, 117] phase_loss 0.001381830035844666 dis_reward -0.0037444090907793\n",
      "picked_obj 1\n",
      "72 58\n",
      "action  [ 0.00788534  0.43418342  0.9660324   0.33132476  0.36164373  0.35841265\n",
      "  0.35035777  0.97609043 -0.02189201] real action [7.88533688e-03 1.45665266e+02 1.17693512e+02]\n",
      "reward -0.005126239126623966 done:  False\n",
      "observation: [ 0.37946429  0.22767857 -0.05357143  0.49107143  0.19642857  0.45535714\n",
      "  0.78571429  0.18303571  0.79910714  0.65178571  0.24107143  0.68303571] [ True]\n",
      "[0.98798275 0.01349771 0.01153028 0.3852923  0.98020494 0.08576369\n",
      " 0.03032839 0.18272877 0.05928755]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.19017864192092895, -0.6767854629802322, 0.02327112199366093]\n",
      "place_xyz[2] 0.02327112199366093 False\n",
      "desired_action : [1, 179, 38] phase_loss 0.0022156778867432315 dis_reward -0.00029728562941987554\n",
      "action  [0.98798275 0.01349771 0.01153028 0.3852923  0.98020494 0.08576369\n",
      " 0.03032839 0.18272877 0.05928755] real action [  0.98798275 178.55820274  41.83002567]\n",
      "reward 0.9974870364838369 done:  True\n",
      "observation: [0.37946429 0.22767857 0.73214286 0.17857143 0.19642857 0.45535714\n",
      " 0.78571429 0.18303571 0.79910714 0.65178571 0.24107143 0.68303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[ 0.00974855  0.18193954  0.36900198  0.98672664  0.38501298  0.4554637\n",
      "  0.283989    0.11031008 -0.01918846]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.17142830807907106, -0.6499997629802322, -0.03670588864386082]\n",
      "pick_success 0\n",
      "desired_action : [0, 171, 175] phase_loss 0.0017574082977300943 dis_reward -0.0001805574673596678\n",
      "action  [ 0.00974855  0.18193954  0.36900198  0.98672664  0.38501298  0.4554637\n",
      "  0.283989    0.11031008 -0.01918846] real action [9.74854827e-03 1.68544341e+02 1.76731362e+02]\n",
      "reward -0.0019379657650897622 done:  False\n",
      "observation: [0.46875    0.60267857 0.46875    0.33928571 0.74553571 0.79017857\n",
      " 0.19196429 0.78571429 0.70982143 0.20535714 0.23214286 0.51339286] [False]\n",
      "[ 0.00974855  0.18193954  0.36900198  0.98672664  0.38501298  0.4554637\n",
      "  0.283989    0.11031008 -0.01918846]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.17142830807907106, -0.6499997629802322, -0.037271246150135995]\n",
      "pick_success 0\n",
      "desired_action : [0, 171, 175] phase_loss 0.0017574082977300943 dis_reward -0.0001805574673596678\n",
      "action  [ 0.00974855  0.18193954  0.36900198  0.98672664  0.38501298  0.4554637\n",
      "  0.283989    0.11031008 -0.01918846] real action [9.74854827e-03 1.68544341e+02 1.76731362e+02]\n",
      "reward -0.0019379657650897622 done:  False\n",
      "observation: [0.46875    0.60267857 0.46875    0.33928571 0.74553571 0.79017857\n",
      " 0.19196429 0.78571429 0.70982143 0.20535714 0.23214286 0.51339286] [False]\n",
      "[ 0.00974855  0.18193954  0.36900198  0.98672664  0.38501298  0.4554637\n",
      "  0.283989    0.11031008 -0.01918846]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.17142830807907106, -0.6499997629802322, -0.03778632341325283]\n",
      "action: [9.74854827e-03 1.68544341e+02 1.76731362e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 171, 175] phase_loss 0.0017574082977300943 dis_reward -0.0001805574673596678\n",
      "picked_obj 2\n",
      "84 88\n",
      "action  [ 0.00974855  0.18193954  0.36900198  0.98672664  0.38501298  0.4554637\n",
      "  0.283989    0.11031008 -0.01918846] real action [9.74854827e-03 1.68544341e+02 1.76731362e+02]\n",
      "reward -0.0019379657650897622 done:  False\n",
      "observation: [0.46875    0.60267857 0.46875    0.33928571 0.04017857 0.48214286\n",
      " 0.19196429 0.78571429 0.70982143 0.20535714 0.23214286 0.51339286] [ True]\n",
      "[ 0.99479604  0.00589398  0.26036656  0.05082595  0.17076018  0.95667714\n",
      "  0.0788106   0.35160792 -0.22168148]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.18750007192092896, -0.6366069129802322, 0.024545786879956726]\n",
      "place_xyz[2] 0.024545786879956726 False\n",
      "desired_action : [1, 155, 46] phase_loss 0.0008425647639961073 dis_reward -0.0017848633793021524\n",
      "action  [ 0.99479604  0.00589398  0.26036656  0.05082595  0.17076018  0.95667714\n",
      "  0.0788106   0.35160792 -0.22168148] real action [  0.99479604 163.9225111   42.89645934]\n",
      "reward 0.9973725718567017 done:  True\n",
      "observation: [0.46875    0.60267857 0.46875    0.33928571 0.72767857 0.19642857\n",
      " 0.19196429 0.78571429 0.70982143 0.20535714 0.23214286 0.51339286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01035535  0.9671359   0.4611361   0.25629464  0.31720504  0.15777546\n",
      "  0.42081696 -0.58158326 -0.22528607]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.12589296192092897, -0.3633927729802322, -0.03961657530069351]\n",
      "action: [1.03553534e-02 6.18578339e+01 6.58459949e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 70, 68] phase_loss 0.0018798779076343566 dis_reward -0.0014186921434419493\n",
      "picked_obj 0\n",
      "30 32\n",
      "action  [ 0.01035535  0.9671359   0.4611361   0.25629464  0.31720504  0.15777546\n",
      "  0.42081696 -0.58158326 -0.22528607] real action [1.03553534e-02 6.18578339e+01 6.58459949e+01]\n",
      "reward -0.003298570051076306 done:  False\n",
      "observation: [0.02678571 0.48660714 0.59375    0.74107143 0.73660714 0.21428571\n",
      " 0.28571429 0.65625    0.47767857 0.45982143 0.79910714 0.55357143] [ True]\n",
      "[ 0.9831934   0.01197585  0.00997299  0.16289312  0.8527009   0.11428845\n",
      "  0.01552334 -0.09979874 -0.11750728]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.08839263807907105, -0.36607134298023225, 0.028567922279238704]\n",
      "place_xyz[2] 0.028567922279238704 False\n",
      "desired_action : [1, 65, 146] phase_loss 0.0031865718089288428 dis_reward -0.000123252793294335\n",
      "action  [ 0.9831934   0.01197585  0.00997299  0.16289312  0.8527009   0.11428845\n",
      "  0.01552334 -0.09979874 -0.11750728] real action [  0.9831934   62.60281765 145.3548981 ]\n",
      "reward 0.9966901753977768 done:  True\n",
      "observation: [0.29017857 0.64285714 0.59375    0.74107143 0.73660714 0.21428571\n",
      " 0.28571429 0.65625    0.47767857 0.45982143 0.79910714 0.55357143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[ 0.01021802  0.42692098  0.92259413  0.25625247  0.05992988  0.15929884\n",
      "  0.06078109 -0.52196306  0.04191828]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14196403807907104, -0.30178566298023224, -0.043584389448165894]\n",
      "action: [1.02180243e-02 3.86925173e+01 1.65586856e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 48, 170] phase_loss 0.0018521546298242112 dis_reward -0.002122101510447428\n",
      "picked_obj 1\n",
      "19 82\n",
      "action  [ 0.01021802  0.42692098  0.92259413  0.25625247  0.05992988  0.15929884\n",
      "  0.06078109 -0.52196306  0.04191828] real action [1.02180243e-02 3.86925173e+01 1.65586856e+02]\n",
      "reward -0.00397425614027164 done:  False\n",
      "observation: [0.78125    0.54464286 0.05357143 0.52678571 0.47767857 0.62946429\n",
      " 0.41071429 0.25       0.74107143 0.79910714 0.81696429 0.23214286] [ True]\n",
      "[0.9891812  0.04243839 0.01082918 0.45311132 0.03866729 0.0759581\n",
      " 0.9945043  0.35913014 0.220227  ]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [-0.15267866192092897, -0.7035711629802323, 0.024597790069878105]\n",
      "place_xyz[2] 0.024597790069878105 False\n",
      "desired_action : [1, 185, 55] phase_loss 0.0019734603126833404 dis_reward -0.00018349249515166777\n",
      "action  [0.9891812  0.04243839 0.01082918 0.45311132 0.03866729 0.0759581\n",
      " 0.9945043  0.35913014 0.220227  ] real action [  0.98918122 188.02782202  55.08317804]\n",
      "reward 0.997843047192165 done:  True\n",
      "observation: [0.78125    0.54464286 0.88392857 0.26339286 0.47767857 0.62946429\n",
      " 0.41071429 0.25       0.74107143 0.79910714 0.81696429 0.23214286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00672844  0.02636176  0.9663862   0.03452682  0.0458903   0.03669301\n",
      "  0.02302319 -0.84367996  0.06944621]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.07500013192092897, -0.5803569429802322, -0.03984827345609665]\n",
      "action: [6.72844052e-03 1.42188480e+02 8.49722469e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 158, 87] phase_loss 0.0011489821937316353 dis_reward -0.005082318709529056\n",
      "picked_obj 1\n",
      "71 42\n",
      "action  [ 0.00672844  0.02636176  0.9663862   0.03452682  0.0458903   0.03669301\n",
      "  0.02302319 -0.84367996  0.06944621] real action [6.72844052e-03 1.42188480e+02 8.49722469e+01]\n",
      "reward -0.0062313009032606914 done:  False\n",
      "observation: [0.29464286 0.37946429 0.07589286 0.5        0.28125    0.74553571\n",
      " 0.72767857 0.70089286 0.54017857 0.16964286 0.47767857 0.54910714] [ True]\n",
      "[0.9905304  0.01333541 0.02224469 0.46240348 0.98861516 0.10860214\n",
      " 0.04234317 0.1593194  0.09208727]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.12321404807907105, -0.6419640529802322, 0.02563078606128693]\n",
      "place_xyz[2] 0.02563078606128693 False\n",
      "desired_action : [1, 162, 156] phase_loss 0.0017011398906315437 dis_reward -0.0003135296622522946\n",
      "action  [0.9905304  0.01333541 0.02224469 0.46240348 0.98861516 0.10860214\n",
      " 0.04234317 0.1593194  0.09208727] real action [  0.99053037 165.23047161 158.28922176]\n",
      "reward 0.9979853304471161 done:  True\n",
      "observation: [0.29464286 0.37946429 0.79464286 0.71428571 0.28125    0.74553571\n",
      " 0.72767857 0.70089286 0.54017857 0.16964286 0.47767857 0.54910714] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[0.00730798 0.4502654  0.96950483 0.35476744 0.34100333 0.34384388\n",
      " 0.37185678 0.97989666 0.01624072]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.16339259807907103, -0.6339283429802323, -0.04103579169511795]\n",
      "action: [7.30797648e-03 1.62718554e+02 1.73227370e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 151, 173] phase_loss 0.0012655911663559884 dis_reward -0.0027475238853995245\n",
      "picked_obj 1\n",
      "81 86\n",
      "action  [0.00730798 0.4502654  0.96950483 0.35476744 0.34100333 0.34384388\n",
      " 0.37185678 0.97989666 0.01624072] real action [7.30797648e-03 1.62718554e+02 1.73227370e+02]\n",
      "reward -0.0040131150517555125 done:  False\n",
      "observation: [ 0.45535714  0.52232143 -0.03571429  0.49107143  0.36160714  0.1875\n",
      "  0.15625     0.55803571  0.72767857  0.48660714  0.68303571  0.14285714] [ True]\n",
      "[0.9877801  0.01212755 0.0099194  0.32593036 0.980168   0.07409641\n",
      " 0.02375239 0.18453217 0.0520184 ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.03482123807907106, -0.29910709298023225, 0.02137003836780787]\n",
      "place_xyz[2] 0.02137003836780787 False\n",
      "desired_action : [1, 40, 125] phase_loss 0.0022566647610899942 dis_reward -0.00012740143164443455\n",
      "action  [0.9877801  0.01212755 0.0099194  0.32593036 0.980168   0.07409641\n",
      " 0.02375239 0.18453217 0.0520184 ] real action [  0.98778009  37.58345032 125.72825766]\n",
      "reward 0.9976159338072655 done:  True\n",
      "observation: [0.45535714 0.52232143 0.10267857 0.54464286 0.36160714 0.1875\n",
      " 0.15625    0.55803571 0.72767857 0.48660714 0.68303571 0.14285714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 120, 181] phase_loss 0.0012835388900902535 dis_reward -7.149459811544743e-05\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.001355033488205701 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.53125    0.80803571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 120, 182] phase_loss 0.0012835388900902535 dis_reward -3.906582805013983e-05\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.0013226047181403933 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.53125    0.80803571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 119, 182] phase_loss 0.0012835388900902535 dis_reward -4.560856545928402e-06\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.001288099746636182 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.53125    0.80803571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 119, 182] phase_loss 0.0012835388900902535 dis_reward -4.560856545928402e-06\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.001288099746636182 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.53125    0.80803571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 119, 182] phase_loss 0.0012835388900902535 dis_reward -4.560856545928402e-06\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.001288099746636182 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.53125    0.80803571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 119, 182] phase_loss 0.0012835388900902535 dis_reward -4.560856545928402e-06\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.001288099746636182 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.53125    0.80803571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 119, 182] phase_loss 0.0012835388900902535 dis_reward -4.560856545928402e-06\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.001288099746636182 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.53125    0.80803571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 119, 181] phase_loss 0.0012835388900902535 dis_reward -3.698962661123601e-05\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.0013205285167014896 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.53125    0.80803571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "[ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.5160712629802322, -0.053500000000000006]\n",
      "action: [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 119, 181] phase_loss 0.0012835388900902535 dis_reward -3.698962661123601e-05\n",
      "picked_obj 2\n",
      "59 91\n",
      "action  [ 0.00739715  0.22848964  0.18968287  0.98382974  0.3753299   0.1497817\n",
      "  0.48083144 -0.02590173  0.0936228 ] real action [7.39714503e-03 1.18637376e+02 1.82310719e+02]\n",
      "reward -0.0013205285167014896 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.         0.49553571\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [ True]\n",
      "[ 0.99434483  0.01926488  0.00578505  0.2521175   0.96508396  0.12123665\n",
      "  0.01726401  0.24345863 -0.00244123]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.06428585192092895, -0.6553569029802322, 0.02311899231374264]\n",
      "place_xyz[2] 0.02311899231374264 False\n",
      "desired_action : [1, 164, 86] phase_loss 0.0009332077066190177 dis_reward -0.0009972792428011772\n",
      "action  [ 0.99434483  0.01926488  0.00578505  0.2521175   0.96508396  0.12123665\n",
      "  0.01726401  0.24345863 -0.00244123] real action [  0.99434483 170.4084208   88.96582282]\n",
      "reward 0.9980695130505798 done:  True\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.74553571 0.39732143\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[ 0.01067567  0.16939682  0.31128693  0.9864406   0.3870453   0.47437873\n",
      "  0.28612334  0.0179652  -0.05055869]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.19553578192092896, -0.6098212129802323, -0.04232094606757164]\n",
      "action: [1.06756687e-02 1.53251513e+02 3.92921784e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 153, 40] phase_loss 0.0019445564295866955 dis_reward -1.1285401991474374e-05\n",
      "picked_obj 2\n",
      "76 19\n",
      "action  [ 0.01067567  0.16939682  0.31128693  0.9864406   0.3870453   0.47437873\n",
      "  0.28612334  0.0179652  -0.05055869] real action [1.06756687e-02 1.53251513e+02 3.92921784e+01]\n",
      "reward -0.00195584183157817 done:  False\n",
      "observation: [0.51785714 0.5        0.29017857 0.67857143 0.00446429 0.48214286\n",
      " 0.83035714 0.48214286 0.36160714 0.125      0.50892857 0.75446429] [ True]\n",
      "[ 0.99549484  0.00451022  0.29252064  0.0887315   0.1251201   0.978541\n",
      "  0.05744597  0.5823873  -0.14890641]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.23303576192092895, -0.43839273298023224, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 84, 29] phase_loss 0.000702262985586507 dis_reward -0.0007214614401985682\n",
      "action  [ 0.99549484  0.00451022  0.29252064  0.0887315   0.1251201   0.978541\n",
      "  0.05744597  0.5823873  -0.14890641] real action [ 0.99549484 89.15342236 25.91531038]\n",
      "reward 0.9985762755742149 done:  True\n",
      "observation: [0.51785714 0.5        0.29017857 0.67857143 0.40625    0.12053571\n",
      " 0.83035714 0.48214286 0.36160714 0.125      0.50892857 0.75446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01186252  0.9597457   0.45446402  0.2511066   0.2793134   0.20017636\n",
      "  0.41478324 -0.5510211  -0.18574685]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-1.7192092893747457e-07, -0.4089284629802322, -0.053500000000000006]\n",
      "action: [1.18625164e-02 7.82857046e+01 1.12399544e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 82, 115] phase_loss 0.0021843888567784696 dis_reward -0.0004111672077713834\n",
      "picked_obj 0\n",
      "39 56\n",
      "action  [ 0.01186252  0.9597457   0.45446402  0.2511066   0.2793134   0.20017636\n",
      "  0.41478324 -0.5510211  -0.18574685] real action [1.18625164e-02 7.82857046e+01 1.12399544e+02]\n",
      "reward -0.002595556064549853 done:  False\n",
      "observation: [0.01785714 0.51339286 0.38839286 0.78571429 0.625      0.29017857\n",
      " 0.79017857 0.78125    0.63392857 0.57589286 0.27678571 0.17410714] [ True]\n",
      "[ 0.98381054  0.00962901  0.00622886  0.14349908  0.86058635  0.10230458\n",
      "  0.01374784 -0.0332213  -0.15249372]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.16071402807907104, -0.6714283229802323, 0.02226262909919024]\n",
      "place_xyz[2] 0.02226262909919024 False\n",
      "desired_action : [1, 175, 177] phase_loss 0.003061199482506329 dis_reward -0.00038906841418823244\n",
      "action  [ 0.98381054  0.00962901  0.00622886  0.14349908  0.86058635  0.10230458\n",
      "  0.01374784 -0.0332213  -0.15249372] real action [  0.98381054 176.53490174 172.86508799]\n",
      "reward 0.9965497321033054 done:  True\n",
      "observation: [0.79910714 0.78125    0.38839286 0.78571429 0.625      0.29017857\n",
      " 0.79017857 0.78125    0.63392857 0.57589286 0.27678571 0.17410714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.00985742  0.9593008   0.53321856  0.19017428  0.28014454  0.24349064\n",
      "  0.42292863 -0.46361238 -0.16288984]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.07767870192092896, -0.5401783929802322, -0.043837347835302354]\n",
      "action: [9.85741615e-03 1.27509427e+02 8.37195423e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 136, 90] phase_loss 0.0017793752491712018 dis_reward -0.0022306797225659434\n",
      "picked_obj 0\n",
      "63 41\n",
      "action  [ 0.00985742  0.9593008   0.53321856  0.19017428  0.28014454  0.24349064\n",
      "  0.42292863 -0.46361238 -0.16288984] real action [9.85741615e-03 1.27509427e+02 8.37195423e+01]\n",
      "reward -0.0040100549717371455 done:  False\n",
      "observation: [0.08482143 0.50446429 0.24107143 0.78571429 0.78571429 0.73214286\n",
      " 0.3125     0.1875     0.47321429 0.64285714 0.16964286 0.39732143] [ True]\n",
      "[ 0.97656745  0.01220429  0.00964162  0.14031395  0.88275707  0.07936886\n",
      "  0.01096433 -0.08176214 -0.15725744]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.19553578192092896, -0.3821427629802322, 0.02262373732030392]\n",
      "place_xyz[2] 0.02262373732030392 False\n",
      "desired_action : [1, 69, 41] phase_loss 0.004537597964941384 dis_reward -2.929563714674175e-05\n",
      "action  [ 0.97656745  0.01220429  0.00964162  0.14031395  0.88275707  0.07936886\n",
      "  0.01096433 -0.08176214 -0.15725744] real action [ 0.97656745 68.85533011 39.79839587]\n",
      "reward 0.9954331063979118 done:  True\n",
      "observation: [0.33928571 0.20089286 0.24107143 0.78571429 0.78571429 0.73214286\n",
      " 0.3125     0.1875     0.47321429 0.64285714 0.16964286 0.39732143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.053500000000000006]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 62, 186] phase_loss 0.0022923362048955275 dis_reward -0.00027984361454875054\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.002572179819444278 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.04124776443839073]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.053500000000000006]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.04269787093997002]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.041969716385006905]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.04358151166141033]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.04129160365462303]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.040647141471505166]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.053500000000000006]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.040078501984477044]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 0\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  False\n",
      "observation: [0.39732143 0.34821429 0.33035714 0.58035714 0.28125    0.81696429\n",
      " 0.75892857 0.26785714 0.82142857 0.58928571 0.55803571 0.66071429] [False]\n",
      "[0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.37142848298023223, -0.04117549566924572]\n",
      "action: [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 61, 186] phase_loss 0.0022923362048955275 dis_reward -0.00039540923878581105\n",
      "picked_obj 2\n",
      "32 91\n",
      "action  [0.01239625 0.15772092 0.24272856 0.98654515 0.25690508 0.2760597\n",
      " 0.27472073 0.09922433 0.00869811] real action [1.23962462e-02 6.43891406e+01 1.83121773e+02]\n",
      "reward -0.0026877454436813387 done:  True\n",
      "observation: [ 0.39732143  0.34821429  0.33035714  0.58035714 -0.00446429  0.54017857\n",
      "  0.75892857  0.26785714  0.82142857  0.58928571  0.55803571  0.66071429] [ True]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "[ 0.01217535  0.9590719   0.43539083  0.2117925   0.29577374  0.18246937\n",
      "  0.41542637 -0.48822355 -0.23513848]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.20357149192092897, -0.47053557298023224, -0.03799982538819313]\n",
      "action: [1.21753514e-02 1.01164870e+02 3.67080612e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 110, 40] phase_loss 0.002247652955846275 dis_reward -0.0017779275685484938\n",
      "picked_obj 0\n",
      "50 18\n",
      "action  [ 0.01217535  0.9590719   0.43539083  0.2117925   0.29577374  0.18246937\n",
      "  0.41542637 -0.48822355 -0.23513848] real action [1.21753514e-02 1.01164870e+02 3.67080612e+01]\n",
      "reward -0.004025580524394769 done:  False\n",
      "observation: [0.04464286 0.5        0.42410714 0.78125    0.1875     0.625\n",
      " 0.44196429 0.38392857 0.73660714 0.42857143 0.70535714 0.71875   ] [ True]\n",
      "[ 0.97849315  0.01364252  0.01395258  0.14124978  0.8785586   0.10724568\n",
      "  0.0141305  -0.07976979 -0.14677691]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.07767870192092896, -0.4598212929802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 103, 88] phase_loss 0.00414400617045358 dis_reward -0.0008524686680987522\n",
      "action  [ 0.97849315  0.01364252  0.01395258  0.14124978  0.8785586   0.10724568\n",
      "  0.0141305  -0.07976979 -0.14677691] real action [ 0.97849315 97.88322294 83.9451232 ]\n",
      "reward 0.9950035251614476 done:  True\n",
      "observation: [0.45535714 0.40178571 0.42410714 0.78125    0.1875     0.625\n",
      " 0.44196429 0.38392857 0.73660714 0.42857143 0.70535714 0.71875   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.00837073  0.04288825  0.98052573  0.26859576  0.02022785  0.05096304\n",
      "  0.01784247 -0.5787523   0.39935088]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.21160685807907098, -0.6151783529802322, -0.038206538021564485]\n",
      "action: [8.37072730e-03 1.55897469e+02 1.91590912e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 167, 185] phase_loss 0.0014796050662781702 dis_reward -0.0033341265944793162\n",
      "picked_obj 1\n",
      "77 95\n",
      "action  [ 0.00837073  0.04288825  0.98052573  0.26859576  0.02022785  0.05096304\n",
      "  0.01784247 -0.5787523   0.39935088] real action [8.37072730e-03 1.55897469e+02 1.91590912e+02]\n",
      "reward -0.004813731660757487 done:  False\n",
      "observation: [0.58035714 0.19642857 0.07589286 0.44642857 0.72767857 0.43303571\n",
      " 0.47767857 0.54910714 0.27232143 0.70982143 0.17410714 0.16964286] [ True]\n",
      "[0.9914404  0.00648266 0.09563404 0.01641142 0.01764628 0.9716588\n",
      " 0.12566513 0.05340481 0.01665819]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.12589261807907104, -0.3633927729802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 58, 160] phase_loss 0.001517660620433175 dis_reward -0.00029265940220045205\n",
      "action  [0.9914404  0.00648266 0.09563404 0.01641142 0.01764628 0.9716588\n",
      " 0.12566513 0.05340481 0.01665819] real action [  0.99144042  61.74766731 159.23321462]\n",
      "reward 0.9981896799773664 done:  True\n",
      "observation: [0.58035714 0.19642857 0.34375    0.67410714 0.72767857 0.43303571\n",
      " 0.47767857 0.54910714 0.27232143 0.70982143 0.17410714 0.16964286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[ 0.012429    0.00859466  0.97477126  0.02797416  0.0127919   0.01686624\n",
      "  0.01488435 -0.45377123  0.20614696]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.184821158079071, -0.5857140829802322, -0.04188680446147919]\n",
      "action: [1.24289989e-02 1.44647202e+02 1.81886057e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 153, 176] phase_loss 0.0022989623773623964 dis_reward -0.002088297953147253\n",
      "picked_obj 1\n",
      "72 90\n",
      "action  [ 0.012429    0.00859466  0.97477126  0.02797416  0.0127919   0.01686624\n",
      "  0.01488435 -0.45377123  0.20614696] real action [1.24289989e-02 1.44647202e+02 1.81886057e+02]\n",
      "reward -0.00438726033050965 done:  False\n",
      "observation: [0.49553571 0.58482143 0.0625     0.49107143 0.23660714 0.43303571\n",
      " 0.6875     0.25892857 0.44642857 0.10714286 0.375      0.79464286] [ True]\n",
      "[0.99290633 0.03970131 0.0076749  0.46480197 0.03491321 0.08866876\n",
      " 0.9947238  0.27997315 0.1769073 ]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.18214258807907102, -0.4330355929802322, 0.022432266712188724]\n",
      "place_xyz[2] 0.022432266712188724 False\n",
      "desired_action : [1, 87, 174] phase_loss 0.0012224620300244002 dis_reward -0.0008558676005373547\n",
      "action  [0.99290633 0.03970131 0.0076749  0.46480197 0.03491321 0.08866876\n",
      " 0.9947238  0.27997315 0.1769073 ] real action [  0.99290633  87.91962409 180.47670221]\n",
      "reward 0.9979216703694382 done:  True\n",
      "observation: [0.49553571 0.58482143 0.43303571 0.79464286 0.23660714 0.43303571\n",
      " 0.6875     0.25892857 0.44642857 0.10714286 0.375      0.79464286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00826696  0.11423177  0.97073364  0.3443754   0.05780518  0.1296317\n",
      "  0.02792716 -0.81183493  0.4526763 ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.17678579192092897, -0.6339283429802323, -0.03813800758123398]\n",
      "action: [8.26695561e-03 1.62634311e+02 4.63374681e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 174, 42] phase_loss 0.0014586977113323376 dis_reward -0.0029598504536942714\n",
      "picked_obj 1\n",
      "81 23\n",
      "action  [ 0.00826696  0.11423177  0.97073364  0.3443754   0.05780518  0.1296317\n",
      "  0.02792716 -0.81183493  0.4526763 ] real action [8.26695561e-03 1.62634311e+02 4.63374681e+01]\n",
      "reward -0.004418548165026609 done:  False\n",
      "observation: [0.83035714 0.79017857 0.05803571 0.46428571 0.54910714 0.37946429\n",
      " 0.28571429 0.11160714 0.40625    0.58928571 0.17857143 0.73660714] [ True]\n",
      "[ 0.9908738   0.01506212  0.00701609  0.42351094  0.9661977   0.08446622\n",
      "  0.02824605  0.22155559 -0.11539894]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.23839290192092896, -0.37946419298023226, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 63, 28] phase_loss 0.0016318767582504355 dis_reward -0.0007625642355652434\n",
      "action  [ 0.9908738   0.01506212  0.00701609  0.42351094  0.9661977   0.08446622\n",
      "  0.02824605  0.22155559 -0.11539894] real action [ 0.99087381 67.10177827 23.38441479]\n",
      "reward 0.9976055590061843 done:  True\n",
      "observation: [0.83035714 0.79017857 0.35267857 0.10714286 0.54910714 0.37946429\n",
      " 0.28571429 0.11160714 0.40625    0.58928571 0.17857143 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00655338  0.3751077   0.97476995  0.12018678  0.27079433  0.38791335\n",
      "  0.39418203  0.98458266 -0.12635416]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.168749738079071, -0.6982140229802323, -0.037816567182540894]\n",
      "action: [6.55338168e-03 1.86784157e+02 1.75231042e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 172, 182] phase_loss 0.0011137718066366602 dis_reward -0.005287801750565902\n",
      "picked_obj 1\n",
      "93 87\n",
      "action  [ 0.00655338  0.3751077   0.97476995  0.12018678  0.27079433  0.38791335\n",
      "  0.39418203  0.98458266 -0.12635416] real action [6.55338168e-03 1.86784157e+02 1.75231042e+02]\n",
      "reward -0.0064015735572025625 done:  False\n",
      "observation: [ 0.19196429  0.60714286 -0.04910714  0.54464286  0.25446429  0.33035714\n",
      "  0.4375      0.75        0.59821429  0.57589286  0.59375     0.25892857] [ True]\n",
      "[0.9898795  0.01289931 0.00787333 0.33550376 0.9801142  0.06636772\n",
      " 0.02365234 0.21104836 0.02366471]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.14999974807907102, -0.46785700298023225, 0.02374340777844191]\n",
      "place_xyz[2] 0.02374340777844191 False\n",
      "desired_action : [1, 95, 166] phase_loss 0.001832471510246278 dis_reward -0.0008178633399956106\n",
      "action  [0.9898795  0.01289931 0.00787333 0.33550376 0.9801142  0.06636772\n",
      " 0.02365234 0.21104836 0.02366471] real action [  0.98987949 100.9546771  168.33130598]\n",
      "reward 0.9973496651497581 done:  True\n",
      "observation: [0.19196429 0.60714286 0.37946429 0.78571429 0.25446429 0.33035714\n",
      " 0.4375     0.75       0.59821429 0.57589286 0.59375    0.25892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "[ 0.01361272  0.9554421   0.35244256  0.29316875  0.35488045  0.22855705\n",
      "  0.36576587 -0.31950432 -0.6124076 ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.02946409807907102, -0.48392842298023225, -0.042409827768802644]\n",
      "action: [1.36127174e-02 1.06526939e+02 1.23426293e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 111, 134] phase_loss 0.002538586582854095 dis_reward -0.0026362308606723856\n",
      "picked_obj 0\n",
      "53 61\n",
      "action  [ 0.01361272  0.9554421   0.35244256  0.29316875  0.35488045  0.22855705\n",
      "  0.36576587 -0.31950432 -0.6124076 ] real action [1.36127174e-02 1.06526939e+02 1.23426293e+02]\n",
      "reward -0.005174817443526481 done:  False\n",
      "observation: [0.02232143 0.55357143 0.23660714 0.49553571 0.51785714 0.26785714\n",
      " 0.83035714 0.75446429 0.25892857 0.18303571 0.23660714 0.71428571] [ True]\n",
      "[ 0.9913305   0.09824765  0.03116617  0.4883171   0.02246886  0.08878589\n",
      "  0.99456036 -0.16324669 -0.43668687]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [0.10982119807907104, -0.33392850298023224, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 57, 163] phase_loss 0.0015398114820730179 dis_reward -0.0024512985166791072\n",
      "action  [ 0.9913305   0.09824765  0.03116617  0.4883171   0.02246886  0.08878589\n",
      "  0.99456036 -0.16324669 -0.43668687] real action [  0.9913305   50.7145462  153.88638401]\n",
      "reward 0.9960088900012479 done:  True\n",
      "observation: [0.21875    0.73214286 0.23660714 0.49553571 0.51785714 0.26785714\n",
      " 0.83035714 0.75446429 0.25892857 0.18303571 0.23660714 0.71428571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "[ 0.01292524  0.03176966  0.9553361   0.0626058   0.01636228  0.03436741\n",
      "  0.0357793  -0.4041133   0.18746495]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.13660724192092896, -0.48660699298023224, -0.04031062296032906]\n",
      "action: [1.29252374e-02 1.07342414e+02 6.16245093e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 115, 60] phase_loss 0.002399382693360783 dis_reward -0.0012255531084407858\n",
      "picked_obj 1\n",
      "53 30\n",
      "action  [ 0.01292524  0.03176966  0.9553361   0.0626058   0.01636228  0.03436741\n",
      "  0.0357793  -0.4041133   0.18746495] real action [1.29252374e-02 1.07342414e+02 6.16245093e+01]\n",
      "reward -0.003624935801801569 done:  False\n",
      "observation: [0.64285714 0.50892857 0.01785714 0.47767857 0.59375    0.77232143\n",
      " 0.20535714 0.45535714 0.80803571 0.24107143 0.33482143 0.75      ] [ True]\n",
      "[0.9920248  0.03593805 0.00836876 0.44156003 0.03488475 0.09035757\n",
      " 0.9946101  0.3203013  0.21006012]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.15535688807907105, -0.41160703298023227, 0.02426734191924334]\n",
      "place_xyz[2] 0.02426734191924334 False\n",
      "desired_action : [1, 74, 168] phase_loss 0.0013999322501125732 dis_reward -0.0007745039630062137\n",
      "action  [0.9920248  0.03593805 0.00836876 0.44156003 0.03488475 0.09035757\n",
      " 0.9946101  0.3203013  0.21006012] real action [  0.99202478  79.48421812 170.94084167]\n",
      "reward 0.9978255637868813 done:  True\n",
      "observation: [0.64285714 0.50892857 0.37053571 0.75892857 0.59375    0.77232143\n",
      " 0.20535714 0.45535714 0.80803571 0.24107143 0.33482143 0.75      ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.01093411  0.22670138  0.34121335  0.9836867   0.2284207   0.33664498\n",
      "  0.5520963  -0.02799642  0.13329554]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.07232156192092895, -0.43839273298023224, -0.040714818820357324]\n",
      "action: [1.09341145e-02 8.96080501e+01 8.58661375e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 90, 87] phase_loss 0.00199675740271154 dis_reward -2.8785377527975698e-05\n",
      "picked_obj 2\n",
      "44 42\n",
      "action  [ 0.01093411  0.22670138  0.34121335  0.9836867   0.2284207   0.33664498\n",
      "  0.5520963  -0.02799642  0.13329554] real action [1.09341145e-02 8.96080501e+01 8.58661375e+01]\n",
      "reward -0.0020255427802395158 done:  False\n",
      "observation: [0.73214286 0.25446429 0.23660714 0.8125     0.01339286 0.5\n",
      " 0.50446429 0.6875     0.77678571 0.66517857 0.20089286 0.53125   ] [ True]\n",
      "[0.99435353 0.02827463 0.00858587 0.24935412 0.04540157 0.17092821\n",
      " 0.98611873 0.11056447 0.25699675]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.02678552807907103, -0.3232142229802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 42, 117] phase_loss 0.0009314591186264465 dis_reward -0.0010404102525732528\n",
      "action  [0.99435353 0.02827463 0.00858587 0.24935412 0.04540157 0.17092821\n",
      " 0.98611873 0.11056447 0.25699675] real action [  0.99435353  46.54790258 122.59795451]\n",
      "reward 0.9980281306288002 done:  True\n",
      "observation: [0.73214286 0.25446429 0.23660714 0.8125     0.19196429 0.54910714\n",
      " 0.50446429 0.6875     0.77678571 0.66517857 0.20089286 0.53125   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.053500000000000006]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 78, 87] phase_loss 0.0014074473110506833 dis_reward -0.0003982827763334319\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.0018057300873841153 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.053500000000000006]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 77, 88] phase_loss 0.0014074473110506833 dis_reward -0.0003444612602964445\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.0017519085713471277 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.053500000000000006]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 76, 88] phase_loss 0.0014074473110506833 dis_reward -0.00047472853706036075\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.001882175848111044 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.053500000000000006]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 74, 90] phase_loss 0.0014074473110506833 dis_reward -0.0006870855049863861\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.002094532816037069 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.053500000000000006]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 73, 90] phase_loss 0.0014074473110506833 dis_reward -0.000937352781750302\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.0023448000928009854 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.053500000000000006]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 73, 90] phase_loss 0.0014074473110506833 dis_reward -0.000937352781750302\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.0023448000928009854 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.053500000000000006]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 74, 90] phase_loss 0.0014074473110506833 dis_reward -0.0006870855049863861\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.002094532816037069 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.04422100803256035]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 73, 90] phase_loss 0.0014074473110506833 dis_reward -0.000937352781750302\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.0023448000928009854 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.04451658746600151]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 73, 90] phase_loss 0.0014074473110506833 dis_reward -0.000937352781750302\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.0023448000928009854 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.053500000000000006]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 74, 90] phase_loss 0.0014074473110506833 dis_reward -0.0006870855049863861\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.002094532816037069 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "[0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.056250141920928975, -0.41160703298023227, -0.04559156468510628]\n",
      "action: [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "pick_success 0\n",
      "desired_action : [0, 74, 90] phase_loss 0.0014074473110506833 dis_reward -0.0006870855049863861\n",
      "action  [0.00801253 0.30311787 0.9337086  0.22396553 0.2760461  0.42167974\n",
      " 0.14941248 0.19690585 0.07872999] real action [8.01253319e-03 7.97566819e+01 9.11022198e+01]\n",
      "reward -0.002094532816037069 done:  True\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[ 0.01230979  0.16831574  0.24856582  0.9867713   0.23750877  0.21839818\n",
      "  0.27047747  0.18760741 -0.04627824]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.21428577192092896, -0.35267849298023224, -0.04112879356741905]\n",
      "action: [1.23097897e-02 5.76265037e+01 3.23521047e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 59, 37] phase_loss 0.0022748463346244524 dis_reward -0.000469788462510129\n",
      "picked_obj 2\n",
      "28 16\n",
      "action  [ 0.01230979  0.16831574  0.24856582  0.9867713   0.23750877  0.21839818\n",
      "  0.27047747  0.18760741 -0.04627824] real action [1.23097897e-02 5.76265037e+01 3.23521047e+01]\n",
      "reward -0.0027446347971345816 done:  False\n",
      "observation: [0.29017857 0.74553571 0.50446429 0.46428571 0.00446429 0.51339286\n",
      " 0.20535714 0.42857143 0.75892857 0.61607143 0.78125    0.38392857] [ True]\n",
      "[ 9.9073660e-01  1.9611925e-02  9.2054904e-03  3.0935180e-01\n",
      "  9.7757745e-01  1.1809930e-01  2.3766696e-02  2.0764542e-01\n",
      " -4.7945976e-04]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.045535861920928955, -0.32857136298023226, 0.021514406405389312]\n",
      "place_xyz[2] 0.021514406405389312 False\n",
      "desired_action : [1, 47, 94] phase_loss 0.001659545476117724 dis_reward -0.00015219961915984186\n",
      "action  [ 9.9073660e-01  1.9611925e-02  9.2054904e-03  3.0935180e-01\n",
      "  9.7757745e-01  1.1809930e-01  2.3766696e-02  2.0764542e-01\n",
      " -4.7945976e-04] real action [ 0.9907366  48.90703583 95.99328756]\n",
      "reward 0.9981882549047224 done:  True\n",
      "observation: [0.29017857 0.74553571 0.50446429 0.46428571 0.21428571 0.45982143\n",
      " 0.20535714 0.42857143 0.75892857 0.61607143 0.78125    0.38392857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[ 0.01055157  0.1574898   0.24531406  0.9844638   0.29029852  0.33146417\n",
      "  0.29612476  0.04247677 -0.01977724]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.184821158079071, -0.4008927529802322, -0.03908012045919895]\n",
      "action: [1.05515718e-02 7.55946748e+01 1.81723119e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 75, 187] phase_loss 0.0019194961353165005 dis_reward -0.0005639822958962547\n",
      "picked_obj 2\n",
      "37 90\n",
      "action  [ 0.01055157  0.1574898   0.24531406  0.9844638   0.29029852  0.33146417\n",
      "  0.29612476  0.04247677 -0.01977724] real action [1.05515718e-02 7.55946748e+01 1.81723119e+02]\n",
      "reward -0.0024834784312127555 done:  False\n",
      "observation: [0.38839286 0.55357143 0.20089286 0.37053571 0.00892857 0.52232143\n",
      " 0.55803571 0.29464286 0.79464286 0.70089286 0.80803571 0.14732143] [ True]\n",
      "[0.9922905  0.01712933 0.00740451 0.21918133 0.96982074 0.14370391\n",
      " 0.01996171 0.25679445 0.02487063]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.12321439192092895, -0.5428569629802322, 0.022903586715459827]\n",
      "place_xyz[2] 0.022903586715459827 False\n",
      "desired_action : [1, 124, 63] phase_loss 0.0013464226162322327 dis_reward -0.0006465103610381495\n",
      "action  [0.9922905  0.01712933 0.00740451 0.21918133 0.96982074 0.14370391\n",
      " 0.01996171 0.25679445 0.02487063] real action [  0.9922905  128.59512234  66.34818888]\n",
      "reward 0.9980070670227296 done:  True\n",
      "observation: [0.38839286 0.55357143 0.20089286 0.37053571 0.57589286 0.31696429\n",
      " 0.55803571 0.29464286 0.79464286 0.70089286 0.80803571 0.14732143] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "[0.00808373 0.23995957 0.2646859  0.98577    0.24845004 0.20445868\n",
      " 0.46895102 0.00198686 0.13249588]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.021428388079071048, -0.4464284429802322, -0.03871651349961758]\n",
      "action: [8.08373094e-03 9.20278161e+01 1.20854942e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 96, 123] phase_loss 0.001421787935307236 dis_reward -0.0004075903543659762\n",
      "picked_obj 2\n",
      "46 60\n",
      "action  [0.00808373 0.23995957 0.2646859  0.98577    0.24845004 0.20445868\n",
      " 0.46895102 0.00198686 0.13249588] real action [8.08373094e-03 9.20278161e+01 1.20854942e+02]\n",
      "reward -0.0018293782896732123 done:  False\n",
      "observation: [0.73660714 0.6875     0.54910714 0.22767857 0.         0.49107143\n",
      " 0.19196429 0.38392857 0.17410714 0.67857143 0.45982143 0.77678571] [ True]\n",
      "[0.9912735  0.02498999 0.00729981 0.20069763 0.9521346  0.1518637\n",
      " 0.02029434 0.24600446 0.04893732]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.06964299192092896, -0.3232142229802322, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 41, 89] phase_loss 0.0015512963001327634 dis_reward -0.0006999294815805217\n",
      "action  [0.9912735  0.02498999 0.00729981 0.20069763 0.9521346  0.1518637\n",
      " 0.02029434 0.24600446 0.04893732] real action [ 0.99127352 46.44406247 86.68512249]\n",
      "reward 0.9977487742182867 done:  True\n",
      "observation: [0.73660714 0.6875     0.54910714 0.22767857 0.20535714 0.39285714\n",
      " 0.19196429 0.38392857 0.17410714 0.67857143 0.45982143 0.77678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[ 0.0104799   0.21982932  0.33264327  0.98112625  0.22719026  0.28753817\n",
      "  0.5585234  -0.02127296  0.17336941]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.008035538079071036, -0.3419642129802323, -0.038892308086156846]\n",
      "action: [1.04798973e-02 5.37021786e+01 1.15427172e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 57, 117] phase_loss 0.0019050235004904718 dis_reward -0.0002669882968378832\n",
      "picked_obj 2\n",
      "26 57\n",
      "action  [ 0.0104799   0.21982932  0.33264327  0.98112625  0.22719026  0.28753817\n",
      "  0.5585234  -0.02127296  0.17336941] real action [1.04798973e-02 5.37021786e+01 1.15427172e+02]\n",
      "reward -0.002172011797328355 done:  False\n",
      "observation: [0.70089286 0.33035714 0.34821429 0.76785714 0.02678571 0.49553571\n",
      " 0.79017857 0.51339286 0.65625    0.73660714 0.41517857 0.24553571] [ True]\n",
      "[0.9911266  0.03218603 0.01062894 0.3349977  0.03113371 0.08636287\n",
      " 0.9900845  0.19605434 0.21752632]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.14464295192092896, -0.45446415298023224, 0.011500000000000003]\n",
      "place_xyz[2] 0.011500000000000003 False\n",
      "desired_action : [1, 96, 55] phase_loss 0.0015809123938248565 dis_reward -0.00018678831933130143\n",
      "action  [0.9911266  0.03218603 0.01062894 0.3349977  0.03113371 0.08636287\n",
      " 0.9900845  0.19605434 0.21752632] real action [ 0.9911266  95.74476075 58.04536843]\n",
      "reward 0.9982322992868439 done:  True\n",
      "observation: [0.70089286 0.33035714 0.34821429 0.76785714 0.43303571 0.27232143\n",
      " 0.79017857 0.51339286 0.65625    0.73660714 0.41517857 0.24553571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "[0.00929353 0.2543958  0.30513346 0.98863244 0.27819258 0.4994109\n",
      " 0.40046188 0.06321812 0.01496649]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.08035692807907102, -0.6446426229802322, -0.03853953240811825]\n",
      "action: [9.29352641e-03 1.66885054e+02 1.42209531e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 169, 143] phase_loss 0.0016656218083867397 dis_reward -0.00010195679272897904\n",
      "picked_obj 2\n",
      "83 71\n",
      "action  [0.00929353 0.2543958  0.30513346 0.98863244 0.27819258 0.4994109\n",
      " 0.40046188 0.06321812 0.01496649] real action [9.29352641e-03 1.66885054e+02 1.42209531e+02]\n",
      "reward -0.0017675786011157187 done:  False\n",
      "observation: [0.20535714 0.30803571 0.21428571 0.69642857 0.03571429 0.5\n",
      " 0.64285714 0.33482143 0.80803571 0.14732143 0.46428571 0.58482143] [ True]\n",
      "[0.9940251  0.03389317 0.00717723 0.3476705  0.04298985 0.10841829\n",
      " 0.9923055  0.15402853 0.22213197]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.058928368079071036, -0.48392842298023225, 0.02211445660889149]\n",
      "place_xyz[2] 0.02211445660889149 False\n",
      "desired_action : [1, 105, 128] phase_loss 0.000997460951329936 dis_reward -0.0007733499361530052\n",
      "action  [0.9940251  0.03389317 0.00717723 0.3476705  0.04298985 0.10841829\n",
      " 0.9923055  0.15402853 0.22213197] real action [  0.99402511 106.15639949 134.10984755]\n",
      "reward 0.998229189112517 done:  True\n",
      "observation: [0.20535714 0.30803571 0.21428571 0.69642857 0.49107143 0.58928571\n",
      " 0.64285714 0.33482143 0.80803571 0.14732143 0.46428571 0.58482143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "[ 0.00698042  0.29564878  0.88051414  0.19973612  0.16417009  0.31403223\n",
      "  0.07584092 -0.74326944  0.42998147]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.010714451920928958, -0.5642855229802322, -0.04123808054625988]\n",
      "action: [6.98041916e-03 1.36594228e+02 1.08019741e+02]\n",
      "pick_success 1\n",
      "desired_action : [0, 144, 104] phase_loss 0.0011996746968620706 dis_reward -0.001420075527134709\n",
      "picked_obj 1\n",
      "68 54\n",
      "action  [ 0.00698042  0.29564878  0.88051414  0.19973612  0.16417009  0.31403223\n",
      "  0.07584092 -0.74326944  0.42998147] real action [6.98041916e-03 1.36594228e+02 1.08019741e+02]\n",
      "reward -0.0026197502239967796 done:  False\n",
      "observation: [0.1875     0.73214286 0.04017857 0.48214286 0.21875    0.40178571\n",
      " 0.84821429 0.79017857 0.54017857 0.19196429 0.47321429 0.75892857] [ True]\n",
      "[ 0.9914986   0.01234731  0.00859642  0.4283601   0.98521984  0.06538099\n",
      "  0.02786767  0.2237612  -0.0116204 ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.17142830807907106, -0.7169640129802323, 0.027380526974797252]\n",
      "place_xyz[2] 0.027380526974797252 False\n",
      "desired_action : [1, 186, 177] phase_loss 0.0015059375129374008 dis_reward -0.0010180251964477178\n",
      "action  [ 0.9914986   0.01234731  0.00859642  0.4283601   0.98521984  0.06538099\n",
      "  0.02786767  0.2237612  -0.0116204 ] real action [  0.99149859 193.13265681 176.83731437]\n",
      "reward 0.9974760372906148 done:  True\n",
      "observation: [0.1875     0.73214286 0.875      0.76339286 0.21875    0.40178571\n",
      " 0.84821429 0.79017857 0.54017857 0.19196429 0.47321429 0.75892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "[ 0.00723103  0.27432883  0.9493458   0.410246    0.1395298   0.2594257\n",
      "  0.05244845 -0.7250246   0.09110487]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.08035727192092895, -0.35535706298023223, -0.04266032001376152]\n",
      "action: [7.23102689e-03 5.88496561e+01 8.22754681e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 70, 82] phase_loss 0.001250104151199657 dis_reward -0.0024881210331207434\n",
      "picked_obj 1\n",
      "29 41\n",
      "action  [ 0.00723103  0.27432883  0.9493458   0.410246    0.1395298   0.2594257\n",
      "  0.05244845 -0.7250246   0.09110487] real action [7.23102689e-03 5.88496561e+01 8.22754681e+01]\n",
      "reward -0.0037382251843204005 done:  False\n",
      "observation: [0.47321429 0.64732143 0.0625     0.5        0.74553571 0.48660714\n",
      " 0.18303571 0.67857143 0.74107143 0.13839286 0.75446429 0.74553571] [ True]\n",
      "[0.99309385 0.00502276 0.08891669 0.01375833 0.01551941 0.97807336\n",
      " 0.10722125 0.04740036 0.02631092]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.21696434192092895, -0.6446426229802322, 0.028337129369378093]\n",
      "place_xyz[2] 0.028337129369378093 False\n",
      "desired_action : [1, 167, 33] phase_loss 0.0011847324131193486 dis_reward -5.550867809077431e-05\n",
      "action  [0.99309385 0.00502276 0.08891669 0.01375833 0.01551941 0.97807336\n",
      " 0.10722125 0.04740036 0.02631092] real action [  0.99309385 166.66360497  31.36835289]\n",
      "reward 0.9987597589087899 done:  True\n",
      "observation: [0.47321429 0.64732143 0.78571429 0.13839286 0.74553571 0.48660714\n",
      " 0.18303571 0.67857143 0.74107143 0.13839286 0.75446429 0.74553571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "[0.00797641 0.2046901  0.30328166 0.9853455  0.41178876 0.25260904\n",
      " 0.31207454 0.15220451 0.0480783 ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.07500013192092897, -0.6874997429802322, -0.03781216202676296]\n",
      "action: [7.97641277e-03 1.82130863e+02 8.46730962e+01]\n",
      "pick_success 1\n",
      "desired_action : [0, 180, 82] phase_loss 0.0014001723435394177 dis_reward -0.00023372042241070177\n",
      "picked_obj 2\n",
      "91 42\n",
      "action  [0.00797641 0.2046901  0.30328166 0.9853455  0.41178876 0.25260904\n",
      " 0.31207454 0.15220451 0.0480783 ] real action [7.97641277e-03 1.82130863e+02 8.46730962e+01]\n",
      "reward -0.0016338927659501194 done:  False\n",
      "observation: [ 0.50446429  0.63392857  0.8125      0.72321429 -0.01785714  0.46428571\n",
      "  0.29464286  0.1875      0.26785714  0.76785714  0.20982143  0.46428571] [ True]\n",
      "[ 0.99611163  0.0043917   0.19732529  0.03196186  0.13777071  0.9598528\n",
      "  0.05162102  0.25450134 -0.21751744]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.14999974807907102, -0.36874991298023224, 0.019506621152162555]\n",
      "place_xyz[2] 0.019506621152162555 False\n",
      "desired_action : [1, 62, 168] phase_loss 0.0005785095985699798 dis_reward -6.709172741633665e-05\n",
      "action  [ 0.99611163  0.0043917   0.19732529  0.03196186  0.13777071  0.9598528\n",
      "  0.05162102  0.25450134 -0.21751744] real action [  0.99611163  63.5630188  168.95475578]\n",
      "reward 0.9993543986740137 done:  True\n",
      "observation: [0.50446429 0.63392857 0.8125     0.72321429 0.25       0.73660714\n",
      " 0.29464286 0.1875     0.26785714 0.76785714 0.20982143 0.46428571] [False]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "env = ResPickOrPlaceEnvWithoutLangReward(\n",
    "                                        task= PutLetterontheBowl,#PutLetterontheBowlUnseenLetters\n",
    "                                         image_obs=True,\n",
    "                                         residual=True,\n",
    "                                         observation_noise=5,\n",
    "                                         render=True,\n",
    "                                         multi_discrete=False,\n",
    "                                         scale_action=True,\n",
    "                                         ee=\"suction\",\n",
    "                                         scale_obs=True,\n",
    "                                         neglect_steps=False,\n",
    "                                      one_hot_action = True)\n",
    "success = 0# 97%\n",
    "trial = 100\n",
    "steps = []\n",
    "#step2 0.79\n",
    "# step3 0.12\n",
    "# step4 0.03\n",
    "for seed in range(trial):\n",
    "    np.random.seed(seed)\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        action,_ = model.predict(obs, deterministic=True)\n",
    "        print(action)\n",
    "        obs, rewards, done,_, info = env.step(action)\n",
    "        step += 1\n",
    "        if done:\n",
    "            steps.append(step)\n",
    "            if rewards >= 0.95:\n",
    "                success += 1\n",
    "            print(\"done\")\n",
    "            break\n",
    "RL_success = success/trial\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL_success 0.96\n",
      "mean 3.06\n",
      "step2 0.75\n",
      "step3 0.07\n",
      "step4 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"RL_success\",RL_success)\n",
    "step2 = steps.count(2)/len(steps)\n",
    "step3 = steps.count(3)/len(steps)\n",
    "step4 = steps.count(4)/len(steps)\n",
    "print(\"mean\",np.mean(steps))\n",
    "print(\"step2\",step2)\n",
    "print(\"step3\",step3)\n",
    "print(\"step4\",step4)\n",
    "# seen color\n",
    "# RL_success 0.97\n",
    "# mean 2.53\n",
    "# step2 0.87\n",
    "# step3 0.04\n",
    "# step4 0.01\n",
    "# unseen color\n",
    "# RL_success 0.92\n",
    "# mean 2.89\n",
    "# step2 0.83\n",
    "# step3 0.04\n",
    "# step4 0.02\n",
    "# unseen color unseen letters\n",
    "# RL_success 0.81\n",
    "# mean 4.12\n",
    "# step2 0.64\n",
    "# step3 0.09\n",
    "# step4 0.03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Success rate|mean step|\n",
    "| :----: | :----: | :----: |\n",
    "| PutLetterontheBowl|0.97|2.53|\n",
    "| PutLetterontheBowlUnseen|0.92|2.89|\n",
    "\n",
    "|  | Success rate|mean step|\n",
    "| :----: | :----: | :----: |\n",
    "| RL|0.92|2.53|\n",
    "| VLM+LLM code|0.79|4.24|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) UHD Graphics (TGL GT1)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 23.0.4-0ubuntu1~22.04.1\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 23.0.4-0ubuntu1~22.04.1\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) UHD Graphics (TGL GT1)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.07142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.17946436192092896, -0.6553569029802322, -0.04525229491293431]\n",
      "action: [  0. 170.  45.]\n",
      "pick_success 1\n",
      "desired_action : [0, 174, 48] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "picked_obj 2\n",
      "85 22\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571  0.07142857] real action [  0. 170.  45.]\n",
      "reward -0.0005000000000000001 done:  False\n",
      "observation: [0.36160714 0.52232143 0.57142857 0.79017857 0.04464286 0.51785714\n",
      " 0.29017857 0.14732143 0.29910714 0.78125    0.80803571 0.58928571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.21428571 -0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.045535518079071025, -0.6767854629802322, 0.018195733539760117]\n",
      "place_xyz[2] 0.018195733539760117 False\n",
      "desired_action : [1, 178, 132] phase_loss 0.0 dis_reward -0.00018\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.21428571 -0.21428571] real action [  1. 178. 129.]\n",
      "reward 0.99982 done:  True\n",
      "observation: [0.36160714 0.52232143 0.57142857 0.79017857 0.82142857 0.57589286\n",
      " 0.29017857 0.14732143 0.29910714 0.78125    0.80803571 0.58928571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.20089292192092895, -0.5937497929802322, -0.060000000000000005]\n",
      "action: [  0. 147.  37.]\n",
      "pick_success 0\n",
      "desired_action : [0, 142, 37] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571] real action [  0. 147.  37.]\n",
      "reward -0.0005000000000000001 done:  False\n",
      "observation: [0.36160714 0.44196429 0.63839286 0.15178571 0.1875     0.70982143\n",
      " 0.45089286 0.75892857 0.33928571 0.13839286 0.78571429 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.42857143 -0.07142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.21160720192092897, -0.5991069329802322, -0.047320650592446334]\n",
      "action: [  0. 149.  33.]\n",
      "pick_success 1\n",
      "desired_action : [0, 142, 37] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "picked_obj 1\n",
      "74 16\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.42857143 -0.07142857] real action [  0. 149.  33.]\n",
      "reward -0.0012999999999999997 done:  False\n",
      "observation: [ 0.36160714  0.44196429 -0.00892857  0.52678571  0.1875      0.70982143\n",
      "  0.45982143  0.77232143  0.33928571  0.13839286  0.78571429  0.45535714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857  0.71428571]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.19017829807907105, -0.47321414298023223, 0.014762030094861989]\n",
      "place_xyz[2] 0.014762030094861989 False\n",
      "desired_action : [1, 107, 171] phase_loss 0.0 dis_reward -0.0033800000000000006\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857  0.71428571] real action [  1. 102. 183.]\n",
      "reward -0.0033800000000000006 done:  False\n",
      "observation: [0.36160714 0.44196429 0.40178571 0.83928571 0.1875     0.70982143\n",
      " 0.45982143 0.77232143 0.33928571 0.13839286 0.78571429 0.45535714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.5        -0.35714286]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.4598212929802322, -0.011872455179691314]\n",
      "action: [  0.  97. 183.]\n",
      "pick_success 1\n",
      "desired_action : [False, 94, 188] phase_loss 0.0 dis_reward -0.00068\n",
      "picked_obj 1\n",
      "48 91\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.5        -0.35714286] real action [  0.  97. 183.]\n",
      "reward -0.00068 done:  False\n",
      "observation: [0.36160714 0.44196429 0.         0.51339286 0.1875     0.70982143\n",
      " 0.45982143 0.77232143 0.33928571 0.13839286 0.78571429 0.45535714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.28571429 -0.28571429]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.152678318079071, -0.4651784329802322, 0.01760668691247702]\n",
      "place_xyz[2] 0.01760668691247702 False\n",
      "desired_action : [1, 107, 171] phase_loss 0.0 dis_reward -0.0013599999999999999\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.28571429 -0.28571429] real action [  1.  99. 169.]\n",
      "reward 0.99864 done:  True\n",
      "observation: [0.36160714 0.44196429 0.41071429 0.78571429 0.1875     0.70982143\n",
      " 0.45982143 0.77232143 0.33928571 0.13839286 0.78571429 0.45535714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.11517868192092895, -0.4598212929802322, -0.047603150531649596]\n",
      "action: [ 0. 97. 69.]\n",
      "pick_success 1\n",
      "desired_action : [0, 94, 68] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "picked_obj 2\n",
      "48 34\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.07142857] real action [ 0. 97. 69.]\n",
      "reward -0.00020000000000000006 done:  False\n",
      "observation: [ 0.8125      0.44196429  0.54464286  0.51339286 -0.01339286  0.50446429\n",
      "  0.79910714  0.68303571  0.50446429  0.75446429  0.20535714  0.46428571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143  0.78571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.13928546807907105, -0.6633926129802322, 0.022509233206510548]\n",
      "place_xyz[2] 0.022509233206510548 False\n",
      "desired_action : [1, 175, 154] phase_loss 0.0 dis_reward -0.00208\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143  0.78571429] real action [  1. 173. 164.]\n",
      "reward 0.99792 done:  True\n",
      "observation: [0.8125     0.44196429 0.54464286 0.51339286 0.75892857 0.72767857\n",
      " 0.79910714 0.68303571 0.50446429 0.75446429 0.20535714 0.46428571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.42857143]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.168749738079071, -0.3312499329802322, -0.048421771898865706]\n",
      "action: [  0.  49. 175.]\n",
      "pick_success 1\n",
      "desired_action : [0, 53, 171] phase_loss 0.0 dis_reward -0.00064\n",
      "picked_obj 1\n",
      "24 87\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.42857143] real action [  0.  49. 175.]\n",
      "reward -0.00064 done:  False\n",
      "observation: [0.35714286 0.54017857 0.01785714 0.48660714 0.70089286 0.26785714\n",
      " 0.64285714 0.54910714 0.18303571 0.26339286 0.50446429 0.77678571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.14285714 0.07142857]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.13928581192092895, -0.31517851298023225, 0.014221556596457963]\n",
      "place_xyz[2] 0.014221556596457963 False\n",
      "desired_action : [1, 44, 56] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.14285714 0.07142857] real action [ 1. 43. 60.]\n",
      "reward 0.99966 done:  True\n",
      "observation: [0.35714286 0.54017857 0.20089286 0.25       0.70089286 0.26785714\n",
      " 0.64285714 0.54910714 0.18303571 0.26339286 0.50446429 0.77678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.48392842298023225, -0.060000000000000005]\n",
      "action: [  0. 106. 182.]\n",
      "pick_success 0\n",
      "desired_action : [0, 105, 182] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.28571429] real action [  0. 106. 182.]\n",
      "reward -2e-05 done:  False\n",
      "observation: [0.46428571 0.8125     0.6875     0.625      0.54017857 0.33928571\n",
      " 0.17410714 0.69642857 0.1875     0.16964286 0.20535714 0.40625   ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.42857143]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.20357114807907106, -0.47321414298023223, -0.04959577478468419]\n",
      "action: [  0. 102. 188.]\n",
      "pick_success 1\n",
      "desired_action : [0, 106, 182] phase_loss 0.0 dis_reward -0.00104\n",
      "picked_obj 0\n",
      "51 94\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.42857143] real action [  0. 102. 188.]\n",
      "reward -0.00104 done:  False\n",
      "observation: [0.01339286 0.44642857 0.6875     0.625      0.54017857 0.33928571\n",
      " 0.17410714 0.69642857 0.1875     0.16964286 0.20535714 0.40625   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.         0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.12857118807907103, -0.30446423298023223, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 40, 157] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.         0.28571429] real action [  1.  39. 160.]\n",
      "reward 0.9998 done:  True\n",
      "observation: [0.16964286 0.68303571 0.6875     0.625      0.54017857 0.33928571\n",
      " 0.17410714 0.69642857 0.1875     0.16964286 0.20535714 0.40625   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.09375012192092896, -0.6205354929802323, -0.045882880389690406]\n",
      "action: [  0. 157.  77.]\n",
      "pick_success 1\n",
      "desired_action : [0, 159, 82] phase_loss 0.0 dis_reward -0.0005799999999999999\n",
      "picked_obj 2\n",
      "78 38\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857] real action [  0. 157.  77.]\n",
      "reward -0.0005799999999999999 done:  False\n",
      "observation: [0.26339286 0.32142857 0.5        0.6875     0.02232143 0.51785714\n",
      " 0.70535714 0.75       0.49107143 0.125      0.16964286 0.55357143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.35714286 -0.78571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.25446432192092894, -0.4812498529802322, 0.01554556574672461]\n",
      "place_xyz[2] 0.01554556574672461 False\n",
      "desired_action : [1, 110, 28] phase_loss 0.0 dis_reward -0.0029200000000000003\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.35714286 -0.78571429] real action [  1. 105.  17.]\n",
      "reward 0.99708 done:  True\n",
      "observation: [0.26339286 0.32142857 0.5        0.6875     0.48214286 0.08035714\n",
      " 0.70535714 0.75       0.49107143 0.125      0.16964286 0.55357143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.42857143]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.0053573119209289755, -0.4758927129802322, -0.04440889105200768]\n",
      "action: [  0. 103. 110.]\n",
      "pick_success 1\n",
      "desired_action : [0, 100, 115] phase_loss 0.0 dis_reward -0.0006799999999999972\n",
      "picked_obj 2\n",
      "51 55\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.42857143] real action [  0. 103. 110.]\n",
      "reward -0.0006799999999999972 done:  False\n",
      "observation: [ 0.59821429  0.75        0.42857143  0.23660714 -0.03571429  0.52678571\n",
      "  0.19196429  0.54017857  0.66964286  0.38392857  0.17857143  0.25      ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.   0.   0.   0.   0.   0.   1.  -0.5  0. ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.15000009192092895, -0.2883928129802322, 0.013181453682482247]\n",
      "place_xyz[2] 0.013181453682482247 False\n",
      "desired_action : [1, 41, 62] phase_loss 0.0 dis_reward -0.0020000000000000005\n",
      "action  [ 1.   0.   0.   0.   0.   0.   1.  -0.5  0. ] real action [ 1. 33. 56.]\n",
      "reward 0.998 done:  True\n",
      "observation: [0.59821429 0.75       0.42857143 0.23660714 0.11160714 0.25\n",
      " 0.19196429 0.54017857 0.66964286 0.38392857 0.16517857 0.24553571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.21428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.005356968079071045, -0.6848211729802323, -0.044527806043624885]\n",
      "action: [  0. 181. 114.]\n",
      "pick_success 1\n",
      "desired_action : [0, 176, 112] phase_loss 0.0 dis_reward -0.0005799999999999999\n",
      "picked_obj 2\n",
      "90 57\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.21428571] real action [  0. 181. 114.]\n",
      "reward -0.0005799999999999999 done:  False\n",
      "observation: [ 0.31696429  0.20982143  0.46428571  0.8125     -0.02232143  0.47767857\n",
      "  0.28571429  0.58928571  0.81696429  0.74107143  0.51339286  0.37946429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.21428571 0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.15535688807907105, -0.6982140229802323, 0.016982928030192856]\n",
      "place_xyz[2] 0.016982928030192856 False\n",
      "desired_action : [1, 183, 167] phase_loss 0.0 dis_reward -0.0003599999999999999\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.21428571 0.28571429] real action [  1. 186. 170.]\n",
      "reward 0.99964 done:  True\n",
      "observation: [0.31696429 0.20982143 0.46428571 0.8125     0.77678571 0.75892857\n",
      " 0.28571429 0.58928571 0.81696429 0.74107143 0.51339286 0.37946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.   0.   0.   1.   0.   0.   0.   0.  -0.5]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.11785725192092897, -0.6982140229802323, -0.045481912493705756]\n",
      "action: [  0. 186.  68.]\n",
      "pick_success 1\n",
      "desired_action : [0, 185, 72] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "picked_obj 2\n",
      "93 34\n",
      "action  [ 0.   0.   0.   1.   0.   0.   0.   0.  -0.5] real action [  0. 186.  68.]\n",
      "reward -0.00033999999999999997 done:  False\n",
      "observation: [ 0.17857143  0.74553571  0.49107143  0.74107143 -0.00446429  0.51339286\n",
      "  0.58482143  0.40625     0.20089286  0.30357143  0.59375     0.14732143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.71428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.029464441920928952, -0.5428569629802322, 0.01980274181813002]\n",
      "place_xyz[2] 0.01980274181813002 False\n",
      "desired_action : [1, 127, 92] phase_loss 0.0 dis_reward -0.0016400000000000002\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.71428571] real action [  1. 128. 101.]\n",
      "reward 0.99836 done:  True\n",
      "observation: [0.17857143 0.74553571 0.49107143 0.74107143 0.54464286 0.47321429\n",
      " 0.58482143 0.40625    0.20089286 0.30357143 0.59375    0.14732143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.0026787419209289842, -0.6660711829802322, -0.043030285909771926]\n",
      "action: [  0. 174. 111.]\n",
      "pick_success 1\n",
      "desired_action : [0, 167, 111] phase_loss 0.0 dis_reward -0.0009800000000000002\n",
      "picked_obj 1\n",
      "87 55\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.21428571] real action [  0. 174. 111.]\n",
      "reward -0.0009800000000000002 done:  False\n",
      "observation: [ 0.49553571  0.16517857 -0.01785714  0.47767857  0.24107143  0.28571429\n",
      "  0.80357143  0.76785714  0.45535714  0.59821429  0.17857143  0.5       ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.07142857 -0.64285714]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.03482123807907106, -0.4758927129802322, 0.01727555144578219]\n",
      "place_xyz[2] 0.01727555144578219 False\n",
      "desired_action : [1, 101, 132] phase_loss 0.0 dis_reward -0.00106\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.07142857 -0.64285714] real action [  1. 103. 125.]\n",
      "reward 0.99894 done:  True\n",
      "observation: [0.49553571 0.16517857 0.41517857 0.5625     0.24107143 0.28571429\n",
      " 0.80357143 0.76785714 0.45535714 0.59821429 0.17857143 0.5       ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.09910691807907102, -0.6848211729802323, -0.060000000000000005]\n",
      "action: [  0. 181. 149.]\n",
      "pick_success 1\n",
      "desired_action : [0, 184, 153] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "picked_obj 0\n",
      "90 74\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.07142857] real action [  0. 181. 149.]\n",
      "reward -0.0005000000000000001 done:  False\n",
      "observation: [0.02232143 0.51339286 0.32142857 0.57589286 0.32142857 0.28571429\n",
      " 0.75892857 0.22767857 0.53125    0.79910714 0.55357143 0.41517857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.42857143 -0.5       ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.18214293192092895, -0.6714283229802323, 0.01645739667117596]\n",
      "place_xyz[2] 0.01645739667117596 False\n",
      "desired_action : [1, 173, 53] phase_loss 0.0 dis_reward -0.0018000000000000004\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.42857143 -0.5       ] real action [  1. 176.  44.]\n",
      "reward 0.9982 done:  True\n",
      "observation: [0.79910714 0.20089286 0.32142857 0.57589286 0.32142857 0.28571429\n",
      " 0.75892857 0.22767857 0.53125    0.79910714 0.55357143 0.41517857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.13392867192092897, -0.6821426029802322, -0.060000000000000005]\n",
      "action: [  0. 180.  62.]\n",
      "pick_success 1\n",
      "desired_action : [0, 184, 64] phase_loss 0.0 dis_reward -0.0004\n",
      "picked_obj 0\n",
      "90 31\n",
      "action  [0. 1. 0. 0. 0. 0. 0. 0. 0.] real action [  0. 180.  62.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.02678571 0.52678571 0.33928571 0.47321429 0.5        0.16071429\n",
      " 0.26785714 0.74107143 0.75       0.59821429 0.22321429 0.24107143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.21428571 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.05089265807907101, -0.6419640529802322, 0.016076590046286587]\n",
      "place_xyz[2] 0.016076590046286587 False\n",
      "desired_action : [1, 170, 137] phase_loss 0.0 dis_reward -0.00122\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.21428571 -0.21428571] real action [  1. 165. 131.]\n",
      "reward 0.99878 done:  True\n",
      "observation: [0.75892857 0.61160714 0.33928571 0.47321429 0.5        0.16071429\n",
      " 0.26785714 0.74107143 0.75       0.59821429 0.22321429 0.24107143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.57142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.184821158079071, -0.6821426029802322, -0.04275573201477528]\n",
      "action: [  0. 180. 181.]\n",
      "pick_success 1\n",
      "desired_action : [0, 182, 172] phase_loss 0.0 dis_reward -0.0017000000000000001\n",
      "picked_obj 1\n",
      "90 90\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.57142857] real action [  0. 180. 181.]\n",
      "reward -0.0017000000000000001 done:  False\n",
      "observation: [0.32589286 0.25892857 0.02678571 0.46428571 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571 -0.35714286]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.02678587192092896, -0.48660699298023224, 0.016077512055635457]\n",
      "place_xyz[2] 0.016077512055635457 False\n",
      "desired_action : [1, 114, 110] phase_loss 0.0 dis_reward -0.0022600000000000003\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571 -0.35714286] real action [  1. 107. 102.]\n",
      "reward -0.0022600000000000003 done:  False\n",
      "observation: [0.32589286 0.25892857 0.47767857 0.41517857 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.5        0.07142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.048214431920928946, -0.5053569829802322, -0.010581507980823517]\n",
      "action: [  0. 114.  94.]\n",
      "pick_success 0\n",
      "desired_action : [False, 108, 93] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.5        0.07142857] real action [  0. 114.  94.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [0.32589286 0.25892857 0.47767857 0.41517857 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.5       ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.03214301192092894, -0.5026784129802322, -0.009773403108119964]\n",
      "action: [  0. 113. 100.]\n",
      "pick_success 1\n",
      "desired_action : [0, 108, 93] phase_loss 0.0 dis_reward -0.00148\n",
      "picked_obj 1\n",
      "56 50\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.5       ] real action [  0. 113. 100.]\n",
      "reward -0.00148 done:  False\n",
      "observation: [ 0.32589286  0.25892857 -0.01785714  0.45982143  0.24553571  0.80357143\n",
      "  0.49107143  0.47767857  0.76339286  0.20982143  0.52232143  0.74107143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.28571429 -0.35714286]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.02678587192092896, -0.5053569829802322, 0.012854430936276917]\n",
      "place_xyz[2] 0.012854430936276917 False\n",
      "desired_action : [1, 114, 110] phase_loss 0.0 dis_reward -0.00128\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.28571429 -0.35714286] real action [  1. 114. 102.]\n",
      "reward -0.00128 done:  False\n",
      "observation: [0.32589286 0.25892857 0.48214286 0.41071429 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.71428571]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.02678587192092896, -0.48660699298023224, 0.0035491961240768366]\n",
      "pick_success 0\n",
      "desired_action : [False, 107, 92] phase_loss 0.0 dis_reward -0.0020000000000000005\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.71428571] real action [  0. 107. 102.]\n",
      "reward -0.0020000000000000005 done:  False\n",
      "observation: [0.32589286 0.25892857 0.48214286 0.41071429 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.35714286]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.04017872192092897, -0.5053569829802322, 0.000600688457489007]\n",
      "action: [  0. 114.  97.]\n",
      "pick_success 1\n",
      "desired_action : [0, 107, 91] phase_loss 0.0 dis_reward -0.0017000000000000001\n",
      "picked_obj 1\n",
      "57 48\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.35714286] real action [  0. 114.  97.]\n",
      "reward -0.0017000000000000001 done:  False\n",
      "observation: [0.32589286 0.25892857 0.         0.45535714 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.92857143 -0.85714286]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.045535861920928955, -0.5294641129802322, 0.010243566818535332]\n",
      "place_xyz[2] 0.010243566818535332 False\n",
      "desired_action : [1, 114, 110] phase_loss 0.0 dis_reward -0.0061200000000000004\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.92857143 -0.85714286] real action [  1. 123.  95.]\n",
      "reward -0.0061200000000000004 done:  False\n",
      "observation: [0.32589286 0.25892857 0.50892857 0.39285714 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.57142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.042857291920928964, -0.5107141229802322, -0.01177708774805069]\n",
      "action: [  0. 116.  96.]\n",
      "pick_success 0\n",
      "desired_action : [False, 115, 89] phase_loss 0.0 dis_reward -0.001\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.14285714 0.57142857] real action [  0. 116.  96.]\n",
      "reward -0.001 done:  False\n",
      "observation: [0.32589286 0.25892857 0.50892857 0.39285714 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.5       ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.045535861920928955, -0.5187498329802323, -0.0017474141716957159]\n",
      "action: [  0. 119.  95.]\n",
      "pick_success 1\n",
      "desired_action : [0, 115, 89] phase_loss 0.0 dis_reward -0.00104\n",
      "picked_obj 1\n",
      "59 47\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.5       ] real action [  0. 119.  95.]\n",
      "reward -0.00104 done:  False\n",
      "observation: [0.32589286 0.25892857 0.00446429 0.47321429 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.   0.   0.   0.   1.   0.   0.   0.5 -1. ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.050893001920928965, -0.5133926929802322, 0.009620251245796685]\n",
      "place_xyz[2] 0.009620251245796685 False\n",
      "desired_action : [1, 114, 110] phase_loss 0.0 dis_reward -0.00596\n",
      "action  [ 1.   0.   0.   0.   1.   0.   0.   0.5 -1. ] real action [  1. 117.  93.]\n",
      "reward -0.00596 done:  True\n",
      "observation: [0.32589286 0.25892857 0.47767857 0.37946429 0.24553571 0.80357143\n",
      " 0.49107143 0.47767857 0.76339286 0.20982143 0.52232143 0.74107143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.        ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.17678579192092897, -0.5830355129802323, -0.04386980615556241]\n",
      "action: [  0. 143.  46.]\n",
      "pick_success 1\n",
      "desired_action : [0, 142, 43] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "picked_obj 2\n",
      "71 23\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.        ] real action [  0. 143.  46.]\n",
      "reward -0.00020000000000000006 done:  False\n",
      "observation: [0.66071429 0.69642857 0.20089286 0.71875    0.01339286 0.47321429\n",
      " 0.25892857 0.15625    0.43303571 0.375      0.74553571 0.38392857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.35714286 -0.35714286]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.21964291192092894, -0.36874991298023224, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 59, 37] phase_loss 0.0 dis_reward -0.001300000000000001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.35714286 -0.35714286] real action [ 1. 63. 30.]\n",
      "reward 0.9987 done:  True\n",
      "observation: [0.66071429 0.69642857 0.20089286 0.71875    0.28125    0.10714286\n",
      " 0.25892857 0.15625    0.43303571 0.375      0.74553571 0.38392857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.005356968079071045, -0.37946419298023226, -0.060000000000000005]\n",
      "action: [  0.  67. 115.]\n",
      "pick_success 0\n",
      "desired_action : [0, 71, 114] phase_loss 0.0 dis_reward -0.0003399999999999994\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ] real action [  0.  67. 115.]\n",
      "reward -0.0003399999999999994 done:  False\n",
      "observation: [0.32142857 0.51339286 0.82589286 0.72321429 0.61160714 0.49553571\n",
      " 0.70089286 0.22321429 0.16964286 0.73660714 0.28571429 0.1875    ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.0026787419209289842, -0.38482133298023224, -0.060000000000000005]\n",
      "action: [  0.  69. 112.]\n",
      "pick_success 0\n",
      "desired_action : [0, 71, 114] phase_loss 0.0 dis_reward -0.00016000000000000115\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.21428571] real action [  0.  69. 112.]\n",
      "reward -0.00016000000000000115 done:  False\n",
      "observation: [0.32142857 0.51339286 0.82589286 0.72321429 0.61160714 0.49553571\n",
      " 0.70089286 0.22321429 0.16964286 0.73660714 0.28571429 0.1875    ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-1.7192092893747457e-07, -0.4089284629802322, -0.04934276424348355]\n",
      "action: [  0.  78. 113.]\n",
      "pick_success 1\n",
      "desired_action : [0, 72, 114] phase_loss 0.0 dis_reward -0.0007400000000000006\n",
      "picked_obj 0\n",
      "39 56\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.14285714] real action [  0.  78. 113.]\n",
      "reward -0.0007400000000000006 done:  False\n",
      "observation: [-0.02232143  0.53571429  0.82589286  0.72321429  0.61160714  0.49553571\n",
      "  0.70089286  0.22321429  0.16964286  0.73660714  0.28571429  0.1875    ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.14285714 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.17142865192092896, -0.6151783529802322, 0.016942797340452675]\n",
      "place_xyz[2] 0.016942797340452675 False\n",
      "desired_action : [1, 156, 48] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.14285714 -0.14285714] real action [  1. 155.  48.]\n",
      "reward 0.99998 done:  True\n",
      "observation: [0.65178571 0.23660714 0.82589286 0.72321429 0.61160714 0.49553571\n",
      " 0.70089286 0.22321429 0.16964286 0.73660714 0.28571429 0.1875    ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.08303549807907101, -0.3446427829802322, -0.0469148025661707]\n",
      "action: [  0.  54. 143.]\n",
      "pick_success 1\n",
      "desired_action : [0, 57, 145] phase_loss 0.0 dis_reward -0.00025999999999999916\n",
      "picked_obj 2\n",
      "27 71\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.        ] real action [  0.  54. 143.]\n",
      "reward -0.00025999999999999916 done:  False\n",
      "observation: [0.71428571 0.72321429 0.60714286 0.20982143 0.00892857 0.50892857\n",
      " 0.3125     0.34375    0.82589286 0.32142857 0.42857143 0.76785714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.5        -0.78571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.13124975807907102, -0.43839273298023224, 0.015316292755305772]\n",
      "place_xyz[2] 0.015316292755305772 False\n",
      "desired_action : [1, 95, 176] phase_loss 0.0 dis_reward -0.005219999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.5        -0.78571429] real action [  1.  89. 161.]\n",
      "reward 0.99478 done:  True\n",
      "observation: [0.71428571 0.72321429 0.60714286 0.20982143 0.38392857 0.72321429\n",
      " 0.3125     0.34375    0.82589286 0.32142857 0.42857143 0.76785714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.28571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.17946436192092896, -0.3258927929802322, -0.047532260119915015]\n",
      "action: [ 0. 47. 45.]\n",
      "pick_success 1\n",
      "desired_action : [0, 46, 48] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "picked_obj 2\n",
      "23 22\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.28571429] real action [ 0. 47. 45.]\n",
      "reward -0.00020000000000000006 done:  False\n",
      "observation: [ 0.5         0.3125      0.79910714  0.55357143 -0.00892857  0.51339286\n",
      "  0.50892857  0.56696429  0.29017857  0.77232143  0.76339286  0.73660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.07142857 0.        ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.14196403807907104, -0.6607140429802323, 0.020252581797540192]\n",
      "place_xyz[2] 0.020252581797540192 False\n",
      "desired_action : [1, 171, 168] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.07142857 0.        ] real action [  1. 172. 165.]\n",
      "reward 0.9998 done:  True\n",
      "observation: [0.5        0.3125     0.79910714 0.55357143 0.76785714 0.74553571\n",
      " 0.52232143 0.59375    0.29017857 0.77232143 0.76339286 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.08571441192092896, -0.48392842298023225, -0.060000000000000005]\n",
      "action: [  0. 106.  80.]\n",
      "pick_success 0\n",
      "desired_action : [0, 107, 81] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.        ] real action [  0. 106.  80.]\n",
      "reward -4e-05 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.08571441192092896, -0.49999984298023226, -0.060000000000000005]\n",
      "action: [  0. 112.  80.]\n",
      "pick_success 0\n",
      "desired_action : [0, 108, 81] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.        ] real action [  0. 112.  80.]\n",
      "reward -0.00033999999999999997 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.09910726192092897, -0.4973212729802322, -0.060000000000000005]\n",
      "action: [  0. 111.  75.]\n",
      "pick_success 0\n",
      "desired_action : [0, 108, 81] phase_loss 0.0 dis_reward -0.0009000000000000002\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.35714286] real action [  0. 111.  75.]\n",
      "reward -0.0009000000000000002 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.08571441192092896, -0.4946427029802322, -0.060000000000000005]\n",
      "action: [  0. 110.  80.]\n",
      "pick_success 0\n",
      "desired_action : [0, 109, 81] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ] real action [  0. 110.  80.]\n",
      "reward -4e-05 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.09642869192092896, -0.48928556298023224, -0.060000000000000005]\n",
      "action: [  0. 108.  76.]\n",
      "pick_success 0\n",
      "desired_action : [0, 109, 80] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429] real action [  0. 108.  76.]\n",
      "reward -0.00033999999999999997 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.09642869192092896, -0.4919641329802322, -0.060000000000000005]\n",
      "action: [  0. 109.  76.]\n",
      "pick_success 0\n",
      "desired_action : [0, 110, 80] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.28571429] real action [  0. 109.  76.]\n",
      "reward -0.00033999999999999997 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.08303584192092897, -0.5107141229802322, -0.0488423702120781]\n",
      "action: [  0. 116.  81.]\n",
      "pick_success 0\n",
      "desired_action : [0, 110, 80] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.07142857] real action [  0. 116.  81.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.08571441192092896, -0.4946427029802322, -0.060000000000000005]\n",
      "action: [  0. 110.  80.]\n",
      "pick_success 0\n",
      "desired_action : [0, 110, 80] phase_loss 0.0 dis_reward -0.0\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ] real action [  0. 110.  80.]\n",
      "reward 0.0 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.09642869192092896, -0.48928556298023224, -0.060000000000000005]\n",
      "action: [  0. 108.  76.]\n",
      "pick_success 0\n",
      "desired_action : [0, 111, 79] phase_loss 0.0 dis_reward -0.0003599999999999999\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429] real action [  0. 108.  76.]\n",
      "reward -0.0003599999999999999 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.09107155192092897, -0.5026784129802322, -0.060000000000000005]\n",
      "action: [  0. 113.  78.]\n",
      "pick_success 0\n",
      "desired_action : [0, 111, 79] phase_loss 0.0 dis_reward -0.0001\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.14285714] real action [  0. 113.  78.]\n",
      "reward -0.0001 done:  False\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "get_expert_demonstration\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.08571441192092896, -0.4973212729802322, -0.060000000000000005]\n",
      "action: [  0. 111.  80.]\n",
      "pick_success 0\n",
      "desired_action : [0, 112, 79] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [0. 1. 0. 0. 0. 0. 0. 0. 0.] real action [  0. 111.  80.]\n",
      "reward -4e-05 done:  True\n",
      "observation: [0.49553571 0.35714286 0.77232143 0.29017857 0.40625    0.70089286\n",
      " 0.80803571 0.76339286 0.77678571 0.51785714 0.25446429 0.41964286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.5        0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15535723192092896, -0.6151783529802322, -0.060000000000000005]\n",
      "action: [  0. 155.  54.]\n",
      "pick_success 0\n",
      "desired_action : [0, 153, 51] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.5        0.07142857] real action [  0. 155.  54.]\n",
      "reward -0.00026 done:  False\n",
      "observation: [0.66517857 0.21428571 0.19196429 0.54910714 0.35267857 0.24553571\n",
      " 0.49553571 0.60714286 0.75446429 0.77678571 0.82142857 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.42857143 0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.16875008192092897, -0.6151783529802322, -0.060000000000000005]\n",
      "action: [  0. 155.  49.]\n",
      "pick_success 0\n",
      "desired_action : [0, 153, 51] phase_loss 0.0 dis_reward -0.00016\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.42857143 0.07142857] real action [  0. 155.  49.]\n",
      "reward -0.00016 done:  False\n",
      "observation: [0.70089286 0.22767857 0.19196429 0.54910714 0.35267857 0.24553571\n",
      " 0.49553571 0.60714286 0.75446429 0.77678571 0.82142857 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.16875008192092897, -0.6232140629802323, -0.060000000000000005]\n",
      "action: [  0. 158.  49.]\n",
      "pick_success 0\n",
      "desired_action : [0, 154, 51] phase_loss 0.0 dis_reward -0.0004\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.14285714] real action [  0. 158.  49.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.70089286 0.22767857 0.19196429 0.54910714 0.35267857 0.24553571\n",
      " 0.49553571 0.60714286 0.75446429 0.77678571 0.82142857 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.16607151192092895, -0.6071426429802322, -0.060000000000000005]\n",
      "action: [  0. 152.  50.]\n",
      "pick_success 0\n",
      "desired_action : [0, 154, 51] phase_loss 0.0 dis_reward -0.0001\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.07142857] real action [  0. 152.  50.]\n",
      "reward -0.0001 done:  False\n",
      "observation: [0.70089286 0.22767857 0.19196429 0.54910714 0.35267857 0.24553571\n",
      " 0.49553571 0.60714286 0.75446429 0.77678571 0.82142857 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.17678579192092897, -0.6151783529802322, -0.060000000000000005]\n",
      "action: [  0. 155.  46.]\n",
      "pick_success 1\n",
      "desired_action : [0, 154, 52] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "picked_obj 0\n",
      "77 23\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.35714286] real action [  0. 155.  46.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [0.00892857 0.5        0.19196429 0.54910714 0.35267857 0.24553571\n",
      " 0.49553571 0.60714286 0.75446429 0.77678571 0.82142857 0.40178571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.57142857 0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.17946401807907103, -0.6741068929802323, 0.02041640236973763]\n",
      "place_xyz[2] 0.02041640236973763 False\n",
      "desired_action : [1, 168, 172] phase_loss 0.0 dis_reward -0.0026\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.57142857 0.35714286] real action [  1. 177. 179.]\n",
      "reward 0.9974 done:  True\n",
      "observation: [0.79464286 0.82589286 0.19196429 0.54910714 0.35267857 0.24553571\n",
      " 0.49553571 0.60714286 0.75446429 0.77678571 0.82142857 0.40178571] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.08839298192092895, -0.5964283629802323, -0.04190252505242825]\n",
      "action: [  0. 148.  79.]\n",
      "pick_success 1\n",
      "desired_action : [0, 153, 87] phase_loss 0.0 dis_reward -0.0017799999999999997\n",
      "picked_obj 0\n",
      "74 39\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.28571429] real action [  0. 148.  79.]\n",
      "reward -0.0017799999999999997 done:  False\n",
      "observation: [0.02232143 0.52678571 0.48214286 0.59821429 0.18303571 0.28571429\n",
      " 0.79464286 0.625      0.19196429 0.73660714 0.44196429 0.26339286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.21428571 -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.15803580192092895, -0.45714272298023223, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 98, 58] phase_loss 0.0 dis_reward -0.0005799999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.21428571 -0.42857143] real action [ 1. 96. 53.]\n",
      "reward 0.99942 done:  True\n",
      "observation: [0.45535714 0.28571429 0.48214286 0.59821429 0.18303571 0.28571429\n",
      " 0.79464286 0.625      0.19196429 0.73660714 0.44196429 0.26339286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.03214266807907101, -0.34732135298023226, -0.060000000000000005]\n",
      "action: [  0.  55. 124.]\n",
      "pick_success 0\n",
      "desired_action : [0, 53, 125] phase_loss 0.0 dis_reward -0.0001\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.14285714] real action [  0.  55. 124.]\n",
      "reward -0.0001 done:  False\n",
      "observation: [0.22321429 0.5625     0.375      0.19642857 0.49553571 0.41071429\n",
      " 0.70982143 0.5625     0.78125    0.30803571 0.48660714 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02946409807907102, -0.3312499329802322, -0.060000000000000005]\n",
      "action: [  0.  49. 123.]\n",
      "pick_success 0\n",
      "desired_action : [0, 54, 125] phase_loss 0.0 dis_reward -0.0005799999999999999\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.21428571] real action [  0.  49. 123.]\n",
      "reward -0.0005799999999999999 done:  False\n",
      "observation: [0.23660714 0.55357143 0.375      0.19642857 0.49553571 0.41071429\n",
      " 0.70982143 0.5625     0.78125    0.30803571 0.48660714 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02410695807907104, -0.3419642129802323, -0.060000000000000005]\n",
      "action: [  0.  53. 121.]\n",
      "pick_success 0\n",
      "desired_action : [0, 55, 124] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.21428571] real action [  0.  53. 121.]\n",
      "reward -0.00026 done:  False\n",
      "observation: [0.23660714 0.55357143 0.375      0.19642857 0.49553571 0.41071429\n",
      " 0.70982143 0.5625     0.78125    0.30803571 0.48660714 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02410695807907104, -0.3446427829802322, -0.060000000000000005]\n",
      "action: [  0.  54. 121.]\n",
      "pick_success 0\n",
      "desired_action : [0, 56, 124] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.21428571] real action [  0.  54. 121.]\n",
      "reward -0.00026 done:  False\n",
      "observation: [0.23660714 0.55357143 0.375      0.19642857 0.49553571 0.41071429\n",
      " 0.70982143 0.5625     0.78125    0.30803571 0.48660714 0.73660714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.04017837807907104, -0.32857136298023226, -0.0443281863629818]\n",
      "action: [  0.  48. 127.]\n",
      "pick_success 1\n",
      "desired_action : [0, 57, 124] phase_loss 0.0 dis_reward -0.0018000000000000004\n",
      "picked_obj 0\n",
      "24 63\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.21428571] real action [  0.  48. 127.]\n",
      "reward -0.0018000000000000004 done:  False\n",
      "observation: [0.03571429 0.48214286 0.375      0.19642857 0.49553571 0.41071429\n",
      " 0.70982143 0.5625     0.78125    0.30803571 0.48660714 0.73660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.71428571 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.12857153192092896, -0.6419640529802322, 0.012094602100551133]\n",
      "place_xyz[2] 0.012094602100551133 False\n",
      "desired_action : [1, 177, 68] phase_loss 0.0 dis_reward -0.003200000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.71428571 -0.35714286] real action [  1. 165.  64.]\n",
      "reward 0.9968 done:  True\n",
      "observation: [0.75       0.27232143 0.375      0.19642857 0.49553571 0.41071429\n",
      " 0.70982143 0.5625     0.78125    0.30803571 0.48660714 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.57142857 -0.21428571]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.029464441920928952, -0.6553569029802322, -0.04541013360023499]\n",
      "action: [  0. 170. 101.]\n",
      "pick_success 1\n",
      "desired_action : [0, 164, 102] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "picked_obj 1\n",
      "85 50\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.57142857 -0.21428571] real action [  0. 170. 101.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [ 0.43303571  0.44196429 -0.01339286  0.47767857  0.60714286  0.73660714\n",
      "  0.76339286  0.125       0.30357143  0.69642857  0.21875     0.17857143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.21428571 0.        ]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [-0.19285721192092897, -0.3392856429802322, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 53, 37] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.21428571 0.        ] real action [ 1. 52. 40.]\n",
      "reward 0.9998 done:  True\n",
      "observation: [0.43303571 0.44196429 0.20982143 0.19642857 0.60714286 0.73660714\n",
      " 0.76339286 0.125      0.30357143 0.69642857 0.21875    0.17857143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.12857118807907103, -0.40357132298023224, -0.060000000000000005]\n",
      "action: [  0.  76. 160.]\n",
      "pick_success 1\n",
      "desired_action : [0, 75, 159] phase_loss 0.0 dis_reward -4e-05\n",
      "picked_obj 2\n",
      "38 80\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.07142857 0.14285714] real action [  0.  76. 160.]\n",
      "reward -4e-05 done:  False\n",
      "observation: [ 0.49553571  0.29464286  0.25446429  0.44642857 -0.00446429  0.48214286\n",
      "  0.82142857  0.26785714  0.64732143  0.58035714  0.20982143  0.15625   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.35714286 0.42857143]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.12321439192092895, -0.7062497329802322, 0.017841748073697095]\n",
      "place_xyz[2] 0.017841748073697095 False\n",
      "desired_action : [1, 186, 56] phase_loss 0.0 dis_reward -0.00218\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.35714286 0.42857143] real action [  1. 189.  66.]\n",
      "reward 0.99782 done:  True\n",
      "observation: [0.49553571 0.29464286 0.25446429 0.44642857 0.84375    0.29464286\n",
      " 0.82142857 0.26785714 0.64732143 0.58035714 0.20982143 0.15625   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.06696407807907101, -0.6714283229802323, -0.03970347687602044]\n",
      "action: [  0. 176. 137.]\n",
      "pick_success 1\n",
      "desired_action : [0, 180, 141] phase_loss 0.0 dis_reward -0.00064\n",
      "picked_obj 2\n",
      "88 68\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143 -0.14285714] real action [  0. 176. 137.]\n",
      "reward -0.00064 done:  False\n",
      "observation: [0.35267857 0.22321429 0.61160714 0.79017857 0.04017857 0.50892857\n",
      " 0.61607143 0.17410714 0.28125    0.49553571 0.19196429 0.72321429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.14285714 -0.85714286]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.03482158192092899, -0.3633927729802322, 0.014506681933999066]\n",
      "place_xyz[2] 0.014506681933999066 False\n",
      "desired_action : [1, 62, 110] phase_loss 0.0 dis_reward -0.00244\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.14285714 -0.85714286] real action [ 1. 61. 99.]\n",
      "reward 0.99756 done:  True\n",
      "observation: [0.35267857 0.22321429 0.61160714 0.79017857 0.28125    0.4375\n",
      " 0.61607143 0.17410714 0.28125    0.49553571 0.19196429 0.72321429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.19285686807907104, -0.4142856029802322, -0.060000000000000005]\n",
      "action: [  0.  80. 184.]\n",
      "pick_success 0\n",
      "desired_action : [0, 82, 181] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.        ] real action [  0.  80. 184.]\n",
      "reward -0.00026 done:  False\n",
      "observation: [0.375      0.80357143 0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.187499728079071, -0.42232131298023223, -0.060000000000000005]\n",
      "action: [  0.  83. 182.]\n",
      "pick_success 0\n",
      "desired_action : [0, 82, 180] phase_loss 0.0 dis_reward -0.0001\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.14285714] real action [  0.  83. 182.]\n",
      "reward -0.0001 done:  False\n",
      "observation: [0.375      0.80357143 0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.18214258807907102, -0.41964274298023224, -0.060000000000000005]\n",
      "action: [  0.  82. 180.]\n",
      "pick_success 0\n",
      "desired_action : [0, 83, 180] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.        ] real action [  0.  82. 180.]\n",
      "reward -2e-05 done:  False\n",
      "observation: [0.375      0.80357143 0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.17410687807907105, -0.43571416298023224, -0.060000000000000005]\n",
      "action: [  0.  88. 177.]\n",
      "pick_success 0\n",
      "desired_action : [0, 83, 180] phase_loss 0.0 dis_reward -0.00068\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.28571429 -0.21428571] real action [  0.  88. 177.]\n",
      "reward -0.00068 done:  False\n",
      "observation: [0.375      0.80357143 0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.19017829807907105, -0.42232131298023223, -0.060000000000000005]\n",
      "action: [  0.  83. 183.]\n",
      "pick_success 0\n",
      "desired_action : [0, 83, 181] phase_loss 0.0 dis_reward -8e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571] real action [  0.  83. 183.]\n",
      "reward -8e-05 done:  False\n",
      "observation: [0.375      0.80357143 0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.19285686807907104, -0.4142856029802322, -0.04731342539191247]\n",
      "action: [  0.  80. 184.]\n",
      "pick_success 1\n",
      "desired_action : [0, 84, 181] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "picked_obj 0\n",
      "40 92\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.28571429] real action [  0.  80. 184.]\n",
      "reward -0.0005000000000000001 done:  False\n",
      "observation: [0.01785714 0.46875    0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.17142865192092896, -0.5428569629802322, 0.015878542438149457]\n",
      "place_xyz[2] 0.015878542438149457 False\n",
      "desired_action : [1, 129, 48] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [  1. 128.  48.]\n",
      "reward 0.99998 done:  True\n",
      "observation: [0.58928571 0.19642857 0.6875     0.84821429 0.33482143 0.41964286\n",
      " 0.5625     0.21875    0.66517857 0.48214286 0.18303571 0.55357143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.13928546807907105, -0.45446415298023224, -0.060000000000000005]\n",
      "action: [  0.  95. 164.]\n",
      "pick_success 1\n",
      "desired_action : [0, 100, 167] phase_loss 0.0 dis_reward -0.00068\n",
      "picked_obj 0\n",
      "47 82\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.35714286] real action [  0.  95. 164.]\n",
      "reward -0.00068 done:  False\n",
      "observation: [0.01339286 0.50892857 0.70982143 0.33035714 0.44196429 0.47321429\n",
      " 0.18303571 0.36607143 0.33928571 0.13839286 0.77232143 0.59375   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -1.          0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.06964299192092896, -0.2723213929802322, 0.01645031396299601]\n",
      "place_xyz[2] 0.01645031396299601 False\n",
      "desired_action : [1, 38, 85] phase_loss 0.0 dis_reward -0.00244\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -1.          0.28571429] real action [ 1. 27. 86.]\n",
      "reward 0.99756 done:  True\n",
      "observation: [0.125      0.41517857 0.70982143 0.33035714 0.44196429 0.47321429\n",
      " 0.18303571 0.36607143 0.33928571 0.13839286 0.77232143 0.59375   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.        ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.13125010192092895, -0.33660707298023224, -0.04589112631976605]\n",
      "action: [ 0. 51. 63.]\n",
      "pick_success 1\n",
      "desired_action : [0, 53, 63] phase_loss 0.0 dis_reward -8e-05\n",
      "picked_obj 2\n",
      "25 31\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286  0.        ] real action [ 0. 51. 63.]\n",
      "reward -8e-05 done:  False\n",
      "observation: [0.49107143 0.21428571 0.41071429 0.52678571 0.         0.48660714\n",
      " 0.74553571 0.32589286 0.69196429 0.74107143 0.16964286 0.64285714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.71428571  0.5       ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.16339259807907103, -0.5883926529802322, 0.014499790146946911]\n",
      "place_xyz[2] 0.014499790146946911 False\n",
      "desired_action : [1, 155, 167] phase_loss 0.0 dis_reward -0.00272\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.71428571  0.5       ] real action [  1. 145. 173.]\n",
      "reward 0.9972799999999999 done:  True\n",
      "observation: [0.49107143 0.21428571 0.41071429 0.52678571 0.65625    0.79910714\n",
      " 0.74553571 0.32589286 0.69196429 0.74107143 0.16964286 0.64285714] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.5        0.14285714]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.10178548807907101, -0.5589283829802323, -0.04509228810667992]\n",
      "action: [  0. 134. 150.]\n",
      "pick_success 1\n",
      "desired_action : [0, 124, 148] phase_loss 0.0 dis_reward -0.00208\n",
      "picked_obj 1\n",
      "67 75\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.5        0.14285714] real action [  0. 134. 150.]\n",
      "reward -0.00208 done:  False\n",
      "observation: [ 0.1875      0.41964286 -0.02678571  0.48214286  0.21875     0.82142857\n",
      "  0.79910714  0.70535714  0.48214286  0.20982143  0.77678571  0.25      ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.71428571 -0.07142857]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.17678579192092897, -0.4624998629802322, 0.015240347124636178]\n",
      "place_xyz[2] 0.015240347124636178 False\n",
      "desired_action : [1, 107, 48] phase_loss 0.0 dis_reward -0.0017000000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.71428571 -0.07142857] real action [ 1. 98. 46.]\n",
      "reward -0.0017000000000000001 done:  False\n",
      "observation: [0.1875     0.41964286 0.39285714 0.16964286 0.21875    0.82142857\n",
      " 0.79910714 0.70535714 0.48214286 0.20982143 0.77678571 0.25      ] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.35714286]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.21160720192092897, -0.4410713029802322, -0.007023110687732696]\n",
      "action: [ 0. 90. 33.]\n",
      "pick_success 1\n",
      "desired_action : [False, 87, 45] phase_loss 0.0 dis_reward -0.0030600000000000002\n",
      "picked_obj 1\n",
      "45 16\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.14285714 -0.35714286] real action [ 0. 90. 33.]\n",
      "reward -0.0030600000000000002 done:  False\n",
      "observation: [ 0.1875      0.41964286 -0.00446429  0.53125     0.21875     0.82142857\n",
      "  0.79910714  0.70535714  0.48214286  0.20982143  0.77678571  0.25      ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.42857143 -0.92857143]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.20892863192092898, -0.5053569829802322, 0.030566626340150838]\n",
      "place_xyz[2] 0.030566626340150838 False\n",
      "desired_action : [1, 107, 48] phase_loss 0.0 dis_reward -0.004900000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.42857143 -0.92857143] real action [  1. 114.  34.]\n",
      "reward 0.9951 done:  True\n",
      "observation: [0.1875     0.41964286 0.48214286 0.19196429 0.21875    0.82142857\n",
      " 0.79910714 0.70535714 0.48214286 0.20982143 0.77678571 0.25      ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.   0.   1.   0.   0.   0.   0.  -0.5  0. ]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15267866192092897, -0.5241069729802322, -0.060000000000000005]\n",
      "action: [  0. 121.  55.]\n",
      "pick_success 1\n",
      "desired_action : [0, 127, 56] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "picked_obj 1\n",
      "60 27\n",
      "action  [ 0.   0.   1.   0.   0.   0.   0.  -0.5  0. ] real action [  0. 121.  55.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [0.46875    0.66071429 0.04464286 0.48660714 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.21428571 0.14285714]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.08303549807907101, -0.6392854829802322, 0.021828434541821484]\n",
      "place_xyz[2] 0.021828434541821484 False\n",
      "desired_action : [1, 164, 144] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.21428571 0.14285714] real action [  1. 164. 143.]\n",
      "reward 0.99998 done:  True\n",
      "observation: [0.46875    0.66071429 0.76339286 0.65178571 0.26339286 0.29017857\n",
      " 0.16071429 0.75892857 0.8125     0.28125    0.71875    0.62946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.14732117807907102, -0.5830355129802323, -0.060000000000000005]\n",
      "action: [  0. 143. 167.]\n",
      "pick_success 0\n",
      "desired_action : [0, 144, 166] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.07142857] real action [  0. 143. 167.]\n",
      "reward -4e-05 done:  False\n",
      "observation: [0.63839286 0.75       0.32142857 0.20535714 0.47767857 0.46428571\n",
      " 0.26339286 0.60267857 0.84375    0.29017857 0.60714286 0.14732143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.136606898079071, -0.5857140829802322, -0.060000000000000005]\n",
      "action: [  0. 144. 163.]\n",
      "pick_success 0\n",
      "desired_action : [0, 144, 166] phase_loss 0.0 dis_reward -0.00018\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.35714286] real action [  0. 144. 163.]\n",
      "reward -0.00018 done:  False\n",
      "observation: [0.63839286 0.75       0.32142857 0.20535714 0.47767857 0.46428571\n",
      " 0.26339286 0.60267857 0.84375    0.29017857 0.60714286 0.14732143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.14732117807907102, -0.5883926529802322, -0.060000000000000005]\n",
      "action: [  0. 145. 167.]\n",
      "pick_success 0\n",
      "desired_action : [0, 144, 166] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [  0. 145. 167.]\n",
      "reward -4e-05 done:  False\n",
      "observation: [0.63839286 0.75       0.32142857 0.20535714 0.47767857 0.46428571\n",
      " 0.26339286 0.60267857 0.84375    0.29017857 0.60714286 0.14732143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.15803545807907105, -0.5776783729802322, -0.0453609448671341]\n",
      "action: [  0. 141. 171.]\n",
      "pick_success 1\n",
      "desired_action : [0, 144, 166] phase_loss 0.0 dis_reward -0.00068\n",
      "picked_obj 0\n",
      "70 85\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.21428571] real action [  0. 141. 171.]\n",
      "reward -0.00068 done:  False\n",
      "observation: [0.         0.47321429 0.32142857 0.20535714 0.47767857 0.46428571\n",
      " 0.26339286 0.60267857 0.84375    0.29017857 0.60714286 0.14732143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.28571429 0.85714286]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.09374977807907103, -0.36874991298023224, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 60, 137] phase_loss 0.0 dis_reward -0.00218\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.28571429 0.85714286] real action [  1.  63. 147.]\n",
      "reward 0.99782 done:  True\n",
      "observation: [0.29464286 0.62946429 0.32142857 0.20535714 0.47767857 0.46428571\n",
      " 0.26339286 0.60267857 0.84375    0.29017857 0.60714286 0.14732143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143  0.35714286]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.20892828807907105, -0.5937497929802322, -0.0450798735767603]\n",
      "action: [  0. 147. 190.]\n",
      "pick_success 1\n",
      "desired_action : [0, 152, 185] phase_loss 0.0 dis_reward -0.001\n",
      "picked_obj 1\n",
      "73 95\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143  0.35714286] real action [  0. 147. 190.]\n",
      "reward -0.001 done:  False\n",
      "observation: [0.5625     0.60267857 0.04017857 0.46875    0.46875    0.25892857\n",
      " 0.32589286 0.46428571 0.16071429 0.26339286 0.29017857 0.75446429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857  0.42857143]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.0053573119209289755, -0.3928570429802322, 0.017145265936851506]\n",
      "place_xyz[2] 0.017145265936851506 False\n",
      "desired_action : [1, 72, 105] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857  0.42857143] real action [  1.  72. 110.]\n",
      "reward 0.9995 done:  True\n",
      "observation: [0.5625     0.60267857 0.35267857 0.46875    0.46875    0.25892857\n",
      " 0.32589286 0.46428571 0.16071429 0.26339286 0.29017857 0.75446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.11250011192092896, -0.6473211929802323, -0.04563873231410981]\n",
      "action: [  0. 167.  70.]\n",
      "pick_success 1\n",
      "desired_action : [0, 166, 68] phase_loss 0.0 dis_reward -0.0001\n",
      "picked_obj 2\n",
      "83 35\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.21428571] real action [  0. 167.  70.]\n",
      "reward -0.0001 done:  False\n",
      "observation: [ 0.1875      0.34375     0.18303571  0.66964286 -0.01785714  0.49107143\n",
      "  0.78125     0.71875     0.46875     0.17410714  0.53571429  0.58035714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.35714286 0.5       ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.14999974807907102, -0.6821426029802322, 0.018519993051886563]\n",
      "place_xyz[2] 0.018519993051886563 False\n",
      "desired_action : [1, 176, 164] phase_loss 0.0 dis_reward -0.00064\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.35714286 0.5       ] real action [  1. 180. 168.]\n",
      "reward 0.99936 done:  True\n",
      "observation: [0.1875     0.34375    0.18303571 0.66964286 0.77678571 0.71875\n",
      " 0.78125    0.71875    0.46875    0.17410714 0.53571429 0.58035714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.42857143]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.15803580192092895, -0.31785708298023224, -0.043367849364876754]\n",
      "action: [ 0. 44. 53.]\n",
      "pick_success 1\n",
      "desired_action : [0, 48, 52] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "picked_obj 2\n",
      "22 26\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.42857143] real action [ 0. 44. 53.]\n",
      "reward -0.00033999999999999997 done:  False\n",
      "observation: [0.58482143 0.72321429 0.21428571 0.54017857 0.01339286 0.48660714\n",
      " 0.61160714 0.1875     0.81696429 0.52232143 0.5        0.46428571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.14285714 -0.42857143]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.03750015192092898, -0.4946427029802322, 0.018233808800578122]\n",
      "place_xyz[2] 0.018233808800578122 False\n",
      "desired_action : [1, 108, 102] phase_loss 0.0 dis_reward -0.0004\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.14285714 -0.42857143] real action [  1. 110.  98.]\n",
      "reward 0.9996 done:  True\n",
      "observation: [0.58482143 0.72321429 0.21428571 0.54017857 0.5        0.44642857\n",
      " 0.61160714 0.1875     0.81696429 0.52232143 0.5        0.46428571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.71428571  0.07142857]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14999974807907102, -0.6098212129802323, -0.05223084770143033]\n",
      "action: [  0. 153. 168.]\n",
      "pick_success 1\n",
      "desired_action : [0, 159, 167] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "picked_obj 1\n",
      "76 84\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.71428571  0.07142857] real action [  0. 153. 168.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [0.52232143 0.32142857 0.03571429 0.48660714 0.20089286 0.19642857\n",
      " 0.34821429 0.53125    0.29910714 0.76785714 0.77678571 0.35267857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.42857143  0.5       ]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [-0.06964299192092896, -0.6499997629802322, 0.018119666837155823]\n",
      "place_xyz[2] 0.018119666837155823 False\n",
      "desired_action : [1, 175, 81] phase_loss 0.0 dis_reward -0.00148\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.42857143  0.5       ] real action [  1. 168.  86.]\n",
      "reward 0.99852 done:  True\n",
      "observation: [0.52232143 0.32142857 0.77678571 0.375      0.20089286 0.19642857\n",
      " 0.34821429 0.53125    0.29910714 0.76785714 0.77678571 0.35267857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.28571429]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.042857291920928964, -0.5883926529802322, -0.060000000000000005]\n",
      "action: [  0. 145.  96.]\n",
      "pick_success 1\n",
      "desired_action : [0, 149, 101] phase_loss 0.0 dis_reward -0.0008200000000000001\n",
      "picked_obj 1\n",
      "72 48\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.28571429] real action [  0. 145.  96.]\n",
      "reward -0.0008200000000000001 done:  False\n",
      "observation: [0.3125     0.1875     0.02678571 0.50446429 0.42410714 0.75892857\n",
      " 0.78125    0.76339286 0.80357143 0.19196429 0.31696429 0.43303571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.57142857 -0.5       ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.20357149192092897, -0.7035711629802323, 0.01622222281992436]\n",
      "place_xyz[2] 0.01622222281992436 False\n",
      "desired_action : [1, 182, 40] phase_loss 0.0 dis_reward -0.00104\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.57142857 -0.5       ] real action [  1. 188.  36.]\n",
      "reward 0.99896 done:  True\n",
      "observation: [0.3125     0.1875     0.86607143 0.17857143 0.42410714 0.75892857\n",
      " 0.78125    0.76339286 0.80357143 0.19196429 0.31696429 0.43303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.07232121807907105, -0.4410713029802322, -0.04465790435671807]\n",
      "action: [  0.  90. 139.]\n",
      "pick_success 1\n",
      "desired_action : [0, 85, 139] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "picked_obj 2\n",
      "45 69\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.21428571 -0.21428571] real action [  0.  90. 139.]\n",
      "reward -0.0005000000000000001 done:  False\n",
      "observation: [0.60714286 0.47321429 0.75       0.69642857 0.         0.5\n",
      " 0.17857143 0.32589286 0.69196429 0.15625    0.19642857 0.78125   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.35714286  0.42857143]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.184821158079071, -0.30446423298023223, 0.014023881517350678]\n",
      "place_xyz[2] 0.014023881517350678 False\n",
      "desired_action : [1, 47, 172] phase_loss 0.0 dis_reward -0.0029000000000000002\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.35714286  0.42857143] real action [  1.  39. 181.]\n",
      "reward 0.9971 done:  True\n",
      "observation: [0.60714286 0.47321429 0.75       0.69642857 0.13839286 0.80357143\n",
      " 0.17857143 0.32589286 0.69196429 0.15625    0.19642857 0.78125   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.28571429 -0.07142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.06696442192092897, -0.36607134298023225, -0.04668110579252244]\n",
      "action: [ 0. 62. 87.]\n",
      "pick_success 1\n",
      "desired_action : [0, 55, 89] phase_loss 0.0 dis_reward -0.0010600000000000021\n",
      "picked_obj 2\n",
      "31 43\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.28571429 -0.07142857] real action [ 0. 62. 87.]\n",
      "reward -0.0010600000000000021 done:  False\n",
      "observation: [ 0.48660714  0.5625      0.65178571  0.19642857 -0.02678571  0.49107143\n",
      "  0.30357143  0.69196429  0.71875     0.76785714  0.79910714  0.49553571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.35714286 0.64285714]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.021428388079071048, -0.6928568829802322, 0.021124036163091664]\n",
      "place_xyz[2] 0.021124036163091664 False\n",
      "desired_action : [1, 185, 112] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.35714286 0.64285714] real action [  1. 184. 120.]\n",
      "reward 0.9987 done:  True\n",
      "observation: [0.48660714 0.5625     0.65178571 0.19642857 0.79464286 0.54464286\n",
      " 0.30357143 0.69196429 0.71875    0.76785714 0.81696429 0.50446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5         0.14285714]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.12321439192092895, -0.4437498729802322, -0.0454808358848095]\n",
      "action: [ 0. 91. 66.]\n",
      "pick_success 1\n",
      "desired_action : [0, 100, 66] phase_loss 0.0 dis_reward -0.00162\n",
      "picked_obj 1\n",
      "45 33\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5         0.14285714] real action [ 0. 91. 66.]\n",
      "reward -0.00162 done:  False\n",
      "observation: [0.52678571 0.78125    0.05357143 0.49107143 0.37053571 0.58928571\n",
      " 0.75892857 0.14285714 0.83035714 0.54017857 0.22321429 0.73660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143  0.5       ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.19553578192092896, -0.6392854829802322, 0.016924562044441704]\n",
      "place_xyz[2] 0.016924562044441704 False\n",
      "desired_action : [1, 167, 36] phase_loss 0.0 dis_reward -0.0003599999999999999\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143  0.5       ] real action [  1. 164.  39.]\n",
      "reward 0.99964 done:  True\n",
      "observation: [0.52678571 0.78125    0.76339286 0.17857143 0.37053571 0.58928571\n",
      " 0.75892857 0.14285714 0.83035714 0.54017857 0.22321429 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.11785725192092897, -0.5321426829802323, -0.04529529407620431]\n",
      "action: [  0. 124.  68.]\n",
      "pick_success 1\n",
      "desired_action : [0, 129, 67] phase_loss 0.0 dis_reward -0.00052\n",
      "picked_obj 2\n",
      "62 34\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.        ] real action [  0. 124.  68.]\n",
      "reward -0.00052 done:  False\n",
      "observation: [0.24107143 0.41517857 0.37053571 0.79910714 0.01339286 0.5\n",
      " 0.53125    0.54464286 0.81696429 0.14285714 0.8125     0.65178571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.35714286  0.35714286]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.03749980807907105, -0.5053569829802322, 0.017291696853935723]\n",
      "place_xyz[2] 0.017291696853935723 False\n",
      "desired_action : [1, 118, 123] phase_loss 0.0 dis_reward -0.0006399999999999978\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.35714286  0.35714286] real action [  1. 114. 127.]\n",
      "reward 0.99936 done:  True\n",
      "observation: [0.24107143 0.41517857 0.37053571 0.79910714 0.52232143 0.58035714\n",
      " 0.53125    0.54464286 0.81696429 0.14285714 0.8125     0.65178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.   0.   1.   0.   0.   0.   0.   0.  -0.5]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.11785690807907101, -0.6499997629802322, -0.060000000000000005]\n",
      "action: [  0. 168. 156.]\n",
      "pick_success 0\n",
      "desired_action : [0, 168, 160] phase_loss 0.0 dis_reward -0.00032\n",
      "action  [ 0.   0.   1.   0.   0.   0.   0.   0.  -0.5] real action [  0. 168. 156.]\n",
      "reward -0.00032 done:  False\n",
      "observation: [0.29017857 0.54017857 0.75       0.72767857 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.5       ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.11785690807907101, -0.6392854829802322, -0.060000000000000005]\n",
      "action: [  0. 164. 156.]\n",
      "pick_success 1\n",
      "desired_action : [0, 168, 160] phase_loss 0.0 dis_reward -0.00064\n",
      "picked_obj 1\n",
      "82 78\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.5       ] real action [  0. 164. 156.]\n",
      "reward -0.00064 done:  False\n",
      "observation: [0.29017857 0.54017857 0.03571429 0.51785714 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.14285714  0.42857143]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.12857153192092896, -0.6901783129802322, 0.020566826798021798]\n",
      "place_xyz[2] 0.020566826798021798 False\n",
      "desired_action : [1, 181, 61] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.14285714  0.42857143] real action [  1. 183.  64.]\n",
      "reward 0.99974 done:  True\n",
      "observation: [0.29017857 0.54017857 0.82589286 0.30803571 0.25       0.21428571\n",
      " 0.82589286 0.25892857 0.29017857 0.77232143 0.56696429 0.17410714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.03482158192092899, -0.6928568829802322, -0.05260763473808766]\n",
      "action: [  0. 184.  99.]\n",
      "pick_success 1\n",
      "desired_action : [0, 178, 98] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "picked_obj 0\n",
      "92 49\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.28571429] real action [  0. 184.  99.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [-0.00892857  0.48214286  0.625       0.67857143  0.42410714  0.52232143\n",
      "  0.22767857  0.14732143  0.53125     0.25446429  0.28571429  0.75892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.07142857 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.14196438192092897, -0.5214284029802323, 0.012554316427558665]\n",
      "place_xyz[2] 0.012554316427558665 False\n",
      "desired_action : [1, 120, 54] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.07142857 0.14285714] real action [  1. 120.  59.]\n",
      "reward 0.9995 done:  True\n",
      "observation: [0.50446429 0.24107143 0.625      0.67857143 0.42410714 0.52232143\n",
      " 0.22767857 0.14732143 0.53125    0.25446429 0.28571429 0.75892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143  0.42857143]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.08839263807907105, -0.6767854629802322, -0.060000000000000005]\n",
      "action: [  0. 178. 145.]\n",
      "pick_success 1\n",
      "desired_action : [0, 180, 138] phase_loss 0.0 dis_reward -0.00106\n",
      "picked_obj 1\n",
      "89 72\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143  0.42857143] real action [  0. 178. 145.]\n",
      "reward -0.00106 done:  False\n",
      "observation: [0.81696429 0.33482143 0.03571429 0.47321429 0.44196429 0.24553571\n",
      " 0.56696429 0.73214286 0.34821429 0.52232143 0.19642857 0.27678571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.21428571 0.64285714]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.03749980807907105, -0.41696417298023225, 0.01664907775819302]\n",
      "place_xyz[2] 0.01664907775819302 False\n",
      "desired_action : [1, 78, 119] phase_loss 0.0 dis_reward -0.0011600000000000002\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.21428571 0.64285714] real action [  1.  81. 126.]\n",
      "reward 0.99884 done:  True\n",
      "observation: [0.81696429 0.33482143 0.39285714 0.54464286 0.44196429 0.24553571\n",
      " 0.56696429 0.73214286 0.34821429 0.52232143 0.19642857 0.27678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.048214431920928946, -0.3071428029802322, -0.060000000000000005]\n",
      "action: [ 0. 40. 94.]\n",
      "pick_success 0\n",
      "desired_action : [0, 45, 93] phase_loss 0.0 dis_reward -0.00052\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.        ] real action [ 0. 40. 94.]\n",
      "reward -0.00052 done:  False\n",
      "observation: [0.19642857 0.41964286 0.43303571 0.67410714 0.73214286 0.28571429\n",
      " 0.69196429 0.67857143 0.47321429 0.31696429 0.30803571 0.13839286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.050893001920928965, -0.33392850298023224, -0.060000000000000005]\n",
      "action: [ 0. 50. 93.]\n",
      "pick_success 0\n",
      "desired_action : [0, 47, 92] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.07142857] real action [ 0. 50. 93.]\n",
      "reward -0.00020000000000000006 done:  False\n",
      "observation: [0.19642857 0.41964286 0.43303571 0.67410714 0.73214286 0.28571429\n",
      " 0.69196429 0.67857143 0.47321429 0.31696429 0.30803571 0.13839286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.03482158192092899, -0.3124999429802322, -0.060000000000000005]\n",
      "action: [ 0. 42. 99.]\n",
      "pick_success 1\n",
      "desired_action : [0, 48, 92] phase_loss 0.0 dis_reward -0.0017000000000000001\n",
      "picked_obj 0\n",
      "21 49\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.35714286] real action [ 0. 42. 99.]\n",
      "reward -0.0017000000000000001 done:  False\n",
      "observation: [0.03571429 0.45982143 0.43303571 0.67410714 0.73214286 0.28571429\n",
      " 0.69196429 0.67857143 0.47321429 0.31696429 0.30803571 0.13839286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.35714286 -0.57142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.23839290192092896, -0.37142848298023223, 0.01419948518276215]\n",
      "place_xyz[2] 0.01419948518276215 False\n",
      "desired_action : [1, 65, 29] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.35714286 -0.57142857] real action [ 1. 64. 23.]\n",
      "reward 0.99926 done:  True\n",
      "observation: [0.29017857 0.08482143 0.43303571 0.67410714 0.73214286 0.28571429\n",
      " 0.69196429 0.67857143 0.47321429 0.31696429 0.30803571 0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.        ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.07499978807907104, -0.4973212729802322, -0.060000000000000005]\n",
      "action: [  0. 111. 140.]\n",
      "pick_success 0\n",
      "desired_action : [0, 106, 137] phase_loss 0.0 dis_reward -0.00068\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.35714286 0.        ] real action [  0. 111. 140.]\n",
      "reward -0.00068 done:  False\n",
      "observation: [0.41964286 0.24107143 0.47321429 0.625      0.8125     0.33928571\n",
      " 0.67857143 0.70089286 0.18303571 0.68303571 0.20089286 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.07142857]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.07767835807907103, -0.49999984298023226, -0.05087849467992783]\n",
      "action: [  0. 112. 141.]\n",
      "pick_success 1\n",
      "desired_action : [0, 105, 137] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "picked_obj 1\n",
      "56 70\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.07142857] real action [  0. 112. 141.]\n",
      "reward -0.0012999999999999997 done:  False\n",
      "observation: [ 0.41964286  0.24107143 -0.03125     0.48660714  0.8125      0.33928571\n",
      "  0.67857143  0.70089286  0.18303571  0.68303571  0.20089286  0.40178571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.21428571 -0.42857143]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.09374977807907103, -0.31785708298023224, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 42, 155] phase_loss 0.0 dis_reward -0.0013599999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.21428571 -0.42857143] real action [  1.  44. 147.]\n",
      "reward 0.99864 done:  True\n",
      "observation: [0.41964286 0.24107143 0.17857143 0.63392857 0.8125     0.33928571\n",
      " 0.67857143 0.70089286 0.18303571 0.68303571 0.20089286 0.40178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.04017872192092897, -0.6526783329802321, -0.04813916020095349]\n",
      "action: [  0. 169.  97.]\n",
      "pick_success 1\n",
      "desired_action : [0, 170, 101] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "picked_obj 2\n",
      "84 48\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714] real action [  0. 169.  97.]\n",
      "reward -0.00033999999999999997 done:  False\n",
      "observation: [0.75446429 0.72767857 0.4375     0.41517857 0.01339286 0.52678571\n",
      " 0.20982143 0.25892857 0.24553571 0.74553571 0.62946429 0.15178571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.64285714  0.57142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.12321439192092895, -0.30178566298023224, 0.014919333271682267]\n",
      "place_xyz[2] 0.014919333271682267 False\n",
      "desired_action : [1, 44, 61] phase_loss 0.0 dis_reward -0.00122\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.64285714  0.57142857] real action [ 1. 38. 66.]\n",
      "reward 0.99878 done:  True\n",
      "observation: [0.75446429 0.72767857 0.4375     0.41517857 0.16964286 0.29910714\n",
      " 0.20982143 0.25892857 0.24553571 0.74553571 0.62946429 0.15178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.57142857 -0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.02142873192092898, -0.4946427029802322, -0.04533356025815011]\n",
      "action: [  0. 110. 104.]\n",
      "pick_success 1\n",
      "desired_action : [0, 116, 104] phase_loss 0.0 dis_reward -0.00072\n",
      "picked_obj 2\n",
      "55 52\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.57142857 -0.07142857] real action [  0. 110. 104.]\n",
      "reward -0.00072 done:  False\n",
      "observation: [0.46875    0.80803571 0.78125    0.35714286 0.03571429 0.50892857\n",
      " 0.76785714 0.66071429 0.24553571 0.19196429 0.18303571 0.45982143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.09910691807907102, -0.6526783329802321, 0.018379204086959366]\n",
      "place_xyz[2] 0.018379204086959366 False\n",
      "desired_action : [1, 176, 150] phase_loss 0.0 dis_reward -0.001\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.07142857] real action [  1. 169. 149.]\n",
      "reward 0.999 done:  True\n",
      "observation: [0.46875    0.80803571 0.78125    0.35714286 0.79017857 0.65625\n",
      " 0.76785714 0.66071429 0.24553571 0.19196429 0.18303571 0.45982143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.42857143 0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.11785690807907101, -0.45714272298023223, -0.060000000000000005]\n",
      "action: [  0.  96. 156.]\n",
      "pick_success 0\n",
      "desired_action : [0, 92, 154] phase_loss 0.0 dis_reward -0.0004\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.42857143 0.28571429] real action [  0.  96. 156.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.40178571 0.67857143 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67410714 0.70982143 0.82142857 0.18303571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.11517833807907102, -0.4437498729802322, -0.060000000000000005]\n",
      "action: [  0.  91. 155.]\n",
      "pick_success 0\n",
      "desired_action : [0, 92, 154] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.21428571] real action [  0.  91. 155.]\n",
      "reward -4e-05 done:  False\n",
      "observation: [0.40178571 0.67857143 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67410714 0.70982143 0.82142857 0.18303571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.11249976807907103, -0.45178558298023225, -0.060000000000000005]\n",
      "action: [  0.  94. 154.]\n",
      "pick_success 0\n",
      "desired_action : [0, 92, 154] phase_loss 0.0 dis_reward -8e-05\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.14285714] real action [  0.  94. 154.]\n",
      "reward -8e-05 done:  False\n",
      "observation: [0.40178571 0.67857143 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67410714 0.70982143 0.82142857 0.18303571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.09642834807907102, -0.45446415298023224, -0.04898741252720357]\n",
      "action: [  0.  95. 148.]\n",
      "pick_success 0\n",
      "desired_action : [0, 93, 154] phase_loss 0.0 dis_reward -0.0008000000000000003\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.28571429] real action [  0.  95. 148.]\n",
      "reward -0.0008000000000000003 done:  False\n",
      "observation: [0.40178571 0.67857143 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67410714 0.70982143 0.82142857 0.18303571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.10714262807907105, -0.45178558298023225, -0.060000000000000005]\n",
      "action: [  0.  94. 152.]\n",
      "pick_success 0\n",
      "desired_action : [0, 93, 154] phase_loss 0.0 dis_reward -0.0001\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.        ] real action [  0.  94. 152.]\n",
      "reward -0.0001 done:  False\n",
      "observation: [0.40178571 0.67857143 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67410714 0.70982143 0.82142857 0.18303571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.28571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.09642834807907102, -0.43035702298023226, -0.04387701459228993]\n",
      "action: [  0.  86. 148.]\n",
      "pick_success 1\n",
      "desired_action : [0, 93, 154] phase_loss 0.0 dis_reward -0.0017000000000000001\n",
      "picked_obj 0\n",
      "43 74\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429 -0.28571429] real action [  0.  86. 148.]\n",
      "reward -0.0017000000000000001 done:  False\n",
      "observation: [0.03571429 0.51339286 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67410714 0.70982143 0.82142857 0.18303571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.14285714 0.71428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.152678318079071, -0.6098212129802323, 0.01573579583317042]\n",
      "place_xyz[2] 0.01573579583317042 False\n",
      "desired_action : [1, 153, 163] phase_loss 0.0 dis_reward -0.00072\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.14285714 0.71428571] real action [  1. 153. 169.]\n",
      "reward 0.99928 done:  True\n",
      "observation: [0.68303571 0.79464286 0.34375    0.34375    0.54017857 0.19642857\n",
      " 0.77232143 0.45535714 0.67410714 0.70982143 0.82142857 0.18303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.16339294192092896, -0.30178566298023224, -0.060000000000000005]\n",
      "action: [ 0. 38. 51.]\n",
      "pick_success 0\n",
      "desired_action : [0, 41, 54] phase_loss 0.0 dis_reward -0.0003599999999999999\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.14285714] real action [ 0. 38. 51.]\n",
      "reward -0.0003599999999999999 done:  False\n",
      "observation: [0.17857143 0.23214286 0.60714286 0.65625    0.28125    0.64732143\n",
      " 0.8125     0.29910714 0.47321429 0.35267857 0.60267857 0.13392857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.21428571]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15267866192092897, -0.30178566298023224, -0.060000000000000005]\n",
      "action: [ 0. 38. 55.]\n",
      "pick_success 0\n",
      "desired_action : [0, 42, 53] phase_loss 0.0 dis_reward -0.0004\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.21428571] real action [ 0. 38. 55.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.17857143 0.23214286 0.60714286 0.65625    0.28125    0.64732143\n",
      " 0.8125     0.29910714 0.47321429 0.35267857 0.60267857 0.13392857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.16607151192092895, -0.30178566298023224, -0.060000000000000005]\n",
      "action: [ 0. 38. 50.]\n",
      "pick_success 0\n",
      "desired_action : [0, 42, 52] phase_loss 0.0 dis_reward -0.0004\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.14285714] real action [ 0. 38. 50.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.17857143 0.23214286 0.60714286 0.65625    0.28125    0.64732143\n",
      " 0.8125     0.29910714 0.47321429 0.35267857 0.60267857 0.13392857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [-0.15535723192092896, -0.29910709298023225, -0.05590984009206296]\n",
      "action: [ 0. 37. 54.]\n",
      "pick_success 1\n",
      "desired_action : [0, 43, 51] phase_loss 0.0 dis_reward -0.0009000000000000002\n",
      "picked_obj 0\n",
      "18 27\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571  0.14285714] real action [ 0. 37. 54.]\n",
      "reward -0.0009000000000000002 done:  False\n",
      "observation: [0.02232143 0.50446429 0.60714286 0.65625    0.28125    0.64732143\n",
      " 0.8125     0.29910714 0.47321429 0.35267857 0.60267857 0.13392857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.92857143 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.09375012192092896, -0.44910701298023226, 0.012545239292085175]\n",
      "place_xyz[2] 0.012545239292085175 False\n",
      "desired_action : [1, 108, 82] phase_loss 0.0 dis_reward -0.005000000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.92857143 -0.14285714] real action [ 1. 93. 77.]\n",
      "reward 0.995 done:  True\n",
      "observation: [0.42410714 0.33035714 0.60714286 0.65625    0.28125    0.64732143\n",
      " 0.8125     0.29910714 0.47321429 0.35267857 0.60267857 0.13392857] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.04285694807907103, -0.29910709298023225, -0.0465745010226965]\n",
      "action: [  0.  37. 128.]\n",
      "pick_success 1\n",
      "desired_action : [0, 43, 132] phase_loss 0.0 dis_reward -0.00104\n",
      "picked_obj 1\n",
      "18 64\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857] real action [  0.  37. 128.]\n",
      "reward -0.00104 done:  False\n",
      "observation: [0.45982143 0.24107143 0.         0.51339286 0.58482143 0.66517857\n",
      " 0.80803571 0.17410714 0.21428571 0.18303571 0.82589286 0.75      ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.35714286  0.57142857]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.17142830807907106, -0.6821426029802322, 0.016801357381045823]\n",
      "place_xyz[2] 0.016801357381045823 False\n",
      "desired_action : [1, 186, 170] phase_loss 0.0 dis_reward -0.0014399999999999997\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.35714286  0.57142857] real action [  1. 180. 176.]\n",
      "reward 0.99856 done:  True\n",
      "observation: [0.45982143 0.24107143 0.82142857 0.79464286 0.58482143 0.66517857\n",
      " 0.80803571 0.17410714 0.21428571 0.18303571 0.82589286 0.75      ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.42857143]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.14999974807907102, -0.35535706298023223, -0.060000000000000005]\n",
      "action: [  0.  58. 168.]\n",
      "pick_success 1\n",
      "desired_action : [0, 54, 176] phase_loss 0.0 dis_reward -0.0016\n",
      "picked_obj 1\n",
      "29 84\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.42857143] real action [  0.  58. 168.]\n",
      "reward -0.0016 done:  False\n",
      "observation: [0.66964286 0.36160714 0.         0.54017857 0.44642857 0.62053571\n",
      " 0.80357143 0.75       0.24553571 0.27232143 0.44642857 0.17857143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.42857143 0.5       ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.168749738079071, -0.6982140229802323, 0.017620453722774987]\n",
      "place_xyz[2] 0.017620453722774987 False\n",
      "desired_action : [1, 178, 172] phase_loss 0.0 dis_reward -0.0014599999999999995\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.42857143 0.5       ] real action [  1. 186. 175.]\n",
      "reward 0.99854 done:  True\n",
      "observation: [0.66964286 0.36160714 0.79464286 0.8125     0.44642857 0.62053571\n",
      " 0.80357143 0.75       0.20535714 0.29464286 0.44642857 0.17857143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.28571429 -0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.15535688807907105, -0.48928556298023224, -0.045194079801440246]\n",
      "action: [  0. 108. 170.]\n",
      "pick_success 1\n",
      "desired_action : [0, 103, 173] phase_loss 0.0 dis_reward -0.00068\n",
      "picked_obj 2\n",
      "54 85\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.28571429 -0.07142857] real action [  0. 108. 170.]\n",
      "reward -0.00068 done:  False\n",
      "observation: [ 0.67857143  0.5         0.16071429  0.43303571 -0.02678571  0.50446429\n",
      "  0.41964286  0.3125      0.20982143  0.66517857  0.79017857  0.13839286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857  0.        ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.11250011192092896, -0.44910701298023226, 0.014372280910611157]\n",
      "place_xyz[2] 0.014372280910611157 False\n",
      "desired_action : [1, 95, 72] phase_loss 0.0 dis_reward -0.00016\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.07142857  0.        ] real action [ 1. 93. 70.]\n",
      "reward 0.99984 done:  True\n",
      "observation: [0.67857143 0.5        0.16071429 0.43303571 0.37946429 0.33035714\n",
      " 0.41964286 0.3125     0.20982143 0.66517857 0.79017857 0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.02946409807907102, -0.34732135298023226, -0.047771583944559104]\n",
      "action: [  0.  55. 123.]\n",
      "pick_success 1\n",
      "desired_action : [0, 60, 127] phase_loss 0.0 dis_reward -0.0008199999999999986\n",
      "picked_obj 0\n",
      "27 61\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286] real action [  0.  55. 123.]\n",
      "reward -0.0008199999999999986 done:  False\n",
      "observation: [0.02232143 0.50446429 0.45089286 0.25892857 0.6875     0.46875\n",
      " 0.82142857 0.74107143 0.44196429 0.73660714 0.19642857 0.15178571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [0.136606898079071, -0.4624998629802322, 0.013111495524644856]\n",
      "place_xyz[2] 0.013111495524644856 False\n",
      "desired_action : [1, 100, 165] phase_loss 0.0 dis_reward -0.00016\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.07142857 -0.14285714] real action [  1.  98. 163.]\n",
      "reward 0.99984 done:  True\n",
      "observation: [0.44642857 0.74553571 0.45089286 0.25892857 0.6875     0.46875\n",
      " 0.82142857 0.74107143 0.44196429 0.73660714 0.19642857 0.15178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.42857143]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.16339294192092896, -0.31517851298023225, -0.04911071218550206]\n",
      "action: [ 0. 43. 51.]\n",
      "pick_success 0\n",
      "desired_action : [0, 43, 45] phase_loss 0.0 dis_reward -0.00072\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.42857143] real action [ 0. 43. 51.]\n",
      "reward -0.00072 done:  False\n",
      "observation: [0.80803571 0.71875    0.43303571 0.29464286 0.18303571 0.20089286\n",
      " 0.46875    0.76339286 0.32589286 0.54017857 0.75446429 0.37053571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.19017864192092895, -0.31517851298023225, -0.04963435202836991]\n",
      "action: [ 0. 43. 41.]\n",
      "pick_success 1\n",
      "desired_action : [0, 43, 46] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "picked_obj 2\n",
      "21 20\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.28571429] real action [ 0. 43. 41.]\n",
      "reward -0.0005000000000000001 done:  False\n",
      "observation: [ 0.80803571  0.71875     0.43303571  0.29464286 -0.00446429  0.52678571\n",
      "  0.46875     0.76339286  0.32589286  0.54017857  0.75446429  0.37053571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.71428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [0.184821158079071, -0.47321414298023223, 0.016498171836137776]\n",
      "place_xyz[2] 0.016498171836137776 False\n",
      "desired_action : [1, 109, 174] phase_loss 0.0 dis_reward -0.00196\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.71428571] real action [  1. 102. 181.]\n",
      "reward 0.99804 done:  True\n",
      "observation: [0.80803571 0.71875    0.43303571 0.29464286 0.44642857 0.8125\n",
      " 0.46875    0.76339286 0.32589286 0.54017857 0.75446429 0.37053571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.136606898079071, -0.47321414298023223, -0.060000000000000005]\n",
      "action: [  0. 102. 163.]\n",
      "pick_success 0\n",
      "desired_action : [0, 103, 164] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.21428571] real action [  0. 102. 163.]\n",
      "reward -4e-05 done:  False\n",
      "observation: [0.45982143 0.71428571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.13928546807907105, -0.47053557298023224, -0.060000000000000005]\n",
      "action: [  0. 101. 164.]\n",
      "pick_success 0\n",
      "desired_action : [0, 103, 164] phase_loss 0.0 dis_reward -8e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.28571429] real action [  0. 101. 164.]\n",
      "reward -8e-05 done:  False\n",
      "observation: [0.45982143 0.71428571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.12857118807907103, -0.47321414298023223, -0.060000000000000005]\n",
      "action: [  0. 102. 160.]\n",
      "pick_success 0\n",
      "desired_action : [0, 104, 164] phase_loss 0.0 dis_reward -0.0004\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ] real action [  0. 102. 160.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.45982143 0.71428571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.12321404807907105, -0.47321414298023223, -0.060000000000000005]\n",
      "action: [  0. 102. 158.]\n",
      "pick_success 0\n",
      "desired_action : [0, 105, 163] phase_loss 0.0 dis_reward -0.00068\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714] real action [  0. 102. 158.]\n",
      "reward -0.00068 done:  False\n",
      "observation: [0.45982143 0.71428571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.12857118807907103, -0.47053557298023224, -0.060000000000000005]\n",
      "action: [  0. 101. 160.]\n",
      "pick_success 0\n",
      "desired_action : [0, 105, 164] phase_loss 0.0 dis_reward -0.00064\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.        ] real action [  0. 101. 160.]\n",
      "reward -0.00064 done:  False\n",
      "observation: [0.45982143 0.71428571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.133928328079071, -0.47053557298023224, -0.060000000000000005]\n",
      "action: [  0. 101. 162.]\n",
      "pick_success 0\n",
      "desired_action : [0, 106, 164] phase_loss 0.0 dis_reward -0.0005799999999999999\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714] real action [  0. 101. 162.]\n",
      "reward -0.0005799999999999999 done:  False\n",
      "observation: [0.45982143 0.71428571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.136606898079071, -0.4758927129802322, -0.060000000000000005]\n",
      "action: [  0. 103. 163.]\n",
      "pick_success 0\n",
      "desired_action : [0, 106, 163] phase_loss 0.0 dis_reward -0.00018\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.21428571] real action [  0. 103. 163.]\n",
      "reward -0.00018 done:  False\n",
      "observation: [0.45982143 0.71428571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.13124975807907102, -0.4812498529802322, -0.060000000000000005]\n",
      "action: [  0. 105. 161.]\n",
      "pick_success 0\n",
      "desired_action : [0, 106, 163] phase_loss 0.0 dis_reward -0.0001\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.14285714 0.07142857] real action [  0. 105. 161.]\n",
      "reward -0.0001 done:  False\n",
      "observation: [0.45982143 0.71428571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.07142857]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.13124975807907102, -0.47321414298023223, -0.060000000000000005]\n",
      "action: [  0. 102. 161.]\n",
      "pick_success 1\n",
      "desired_action : [0, 107, 163] phase_loss 0.0 dis_reward -0.0005799999999999999\n",
      "picked_obj 0\n",
      "51 80\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857  0.07142857] real action [  0. 102. 161.]\n",
      "reward -0.0005799999999999999 done:  False\n",
      "observation: [0.02232143 0.52678571 0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.   0.   0.   0.   0.   0.   1.  -0.5  0.5]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.19553578192092896, -0.28571424298023224, 0.013506204001605515]\n",
      "place_xyz[2] 0.013506204001605515 False\n",
      "desired_action : [1, 40, 36] phase_loss 0.0 dis_reward -0.0014599999999999995\n",
      "action  [ 1.   0.   0.   0.   0.   0.   1.  -0.5  0.5] real action [ 1. 32. 39.]\n",
      "reward 0.99854 done:  True\n",
      "observation: [0.14732143 0.1875     0.59375    0.48660714 0.58928571 0.18303571\n",
      " 0.70982143 0.70535714 0.25892857 0.41964286 0.17410714 0.14285714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.42857143]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.21696434192092895, -0.29910709298023225, -0.04592253983020783]\n",
      "action: [ 0. 37. 31.]\n",
      "pick_success 1\n",
      "desired_action : [0, 42, 39] phase_loss 0.0 dis_reward -0.0017799999999999997\n",
      "picked_obj 1\n",
      "18 15\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.42857143] real action [ 0. 37. 31.]\n",
      "reward -0.0017799999999999997 done:  False\n",
      "observation: [0.58482143 0.45089286 0.02678571 0.52678571 0.33035714 0.69642857\n",
      " 0.82142857 0.57589286 0.5625     0.16071429 0.84821429 0.27678571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.92857143 -0.14285714]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.20892863192092898, -0.5026784129802322, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 126, 34] phase_loss 0.0 dis_reward -0.0033800000000000006\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.92857143 -0.14285714] real action [  1. 113.  34.]\n",
      "reward 0.99662 done:  True\n",
      "observation: [0.58482143 0.45089286 0.52678571 0.1875     0.33035714 0.69642857\n",
      " 0.82142857 0.57589286 0.5625     0.16071429 0.84821429 0.27678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.5       ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.17678579192092897, -0.30982137298023227, -0.060000000000000005]\n",
      "action: [ 0. 41. 46.]\n",
      "pick_success 0\n",
      "desired_action : [0, 42, 51] phase_loss 0.0 dis_reward -0.00052\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.5       ] real action [ 0. 41. 46.]\n",
      "reward -0.00052 done:  False\n",
      "observation: [0.19642857 0.23660714 0.67410714 0.49107143 0.80803571 0.73214286\n",
      " 0.23660714 0.66071429 0.49553571 0.75       0.41964286 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.35714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.17142865192092896, -0.31785708298023224, -0.060000000000000005]\n",
      "action: [ 0. 44. 48.]\n",
      "pick_success 0\n",
      "desired_action : [0, 43, 49] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.35714286] real action [ 0. 44. 48.]\n",
      "reward -4e-05 done:  False\n",
      "observation: [0.1875     0.20982143 0.67410714 0.49107143 0.80803571 0.73214286\n",
      " 0.23660714 0.66071429 0.49553571 0.76785714 0.41964286 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.16875008192092897, -0.32053565298023223, -0.060000000000000005]\n",
      "action: [ 0. 45. 49.]\n",
      "pick_success 0\n",
      "desired_action : [0, 45, 48] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.21428571 0.14285714] real action [ 0. 45. 49.]\n",
      "reward -2e-05 done:  False\n",
      "observation: [0.1875     0.20982143 0.67410714 0.49107143 0.80803571 0.73214286\n",
      " 0.23660714 0.66071429 0.49553571 0.76785714 0.41964286 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.21428571]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.18214293192092895, -0.3258927929802322, -0.060000000000000005]\n",
      "action: [ 0. 47. 44.]\n",
      "pick_success 0\n",
      "desired_action : [0, 46, 47] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.35714286 -0.21428571] real action [ 0. 47. 44.]\n",
      "reward -0.00020000000000000006 done:  False\n",
      "observation: [0.1875     0.20982143 0.67410714 0.49107143 0.80803571 0.73214286\n",
      " 0.23660714 0.66071429 0.49553571 0.76785714 0.41964286 0.40178571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.42857143]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [-0.19017864192092895, -0.3124999429802322, -0.04615416906774045]\n",
      "action: [ 0. 42. 41.]\n",
      "pick_success 1\n",
      "desired_action : [0, 46, 46] phase_loss 0.0 dis_reward -0.0008200000000000001\n",
      "picked_obj 0\n",
      "21 20\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.         -0.42857143] real action [ 0. 42. 41.]\n",
      "reward -0.0008200000000000001 done:  False\n",
      "observation: [0.01785714 0.53571429 0.67410714 0.49107143 0.80803571 0.73214286\n",
      " 0.23660714 0.66071429 0.49553571 0.76785714 0.41964286 0.40178571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429  0.        ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.05892871192092897, -0.4410713029802322, 0.01542252499610186]\n",
      "place_xyz[2] 0.01542252499610186 False\n",
      "desired_action : [1, 91, 87] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429  0.        ] real action [ 1. 90. 90.]\n",
      "reward 0.9998 done:  True\n",
      "observation: [0.40178571 0.41517857 0.67410714 0.49107143 0.80803571 0.73214286\n",
      " 0.23660714 0.66071429 0.49553571 0.76785714 0.41964286 0.40178571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.5       ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.20357114807907106, -0.5508926729802321, -0.04301920503377915]\n",
      "action: [  0. 131. 188.]\n",
      "pick_success 1\n",
      "desired_action : [0, 137, 184] phase_loss 0.0 dis_reward -0.00104\n",
      "picked_obj 0\n",
      "65 94\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.5       ] real action [  0. 131. 188.]\n",
      "reward -0.00104 done:  False\n",
      "observation: [0.04464286 0.48660714 0.29017857 0.39732143 0.76785714 0.38839286\n",
      " 0.45982143 0.54910714 0.18303571 0.79464286 0.50446429 0.16964286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.78571429  0.85714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [-0.16607151192092895, -0.47321414298023223, 0.013207987062633042]\n",
      "place_xyz[2] 0.013207987062633042 False\n",
      "desired_action : [1, 112, 40] phase_loss 0.0 dis_reward -0.004\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.78571429  0.85714286] real action [  1. 102.  50.]\n",
      "reward 0.996 done:  True\n",
      "observation: [0.48660714 0.20535714 0.29017857 0.39732143 0.76785714 0.38839286\n",
      " 0.45982143 0.54910714 0.18303571 0.79464286 0.50446429 0.16964286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.        ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.12857118807907103, -0.3392856429802322, -0.048595627471804625]\n",
      "action: [  0.  52. 160.]\n",
      "pick_success 1\n",
      "desired_action : [0, 50, 158] phase_loss 0.0 dis_reward -0.00016\n",
      "picked_obj 2\n",
      "26 80\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.28571429 0.        ] real action [  0.  52. 160.]\n",
      "reward -0.00016 done:  False\n",
      "observation: [ 0.68303571  0.23660714  0.45535714  0.53571429 -0.02232143  0.49553571\n",
      "  0.24553571  0.16517857  0.75        0.42410714  0.71428571  0.73214286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.35714286 0.35714286]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.152678318079071, -0.6419640529802322, 0.013234493434429173]\n",
      "place_xyz[2] 0.013234493434429173 False\n",
      "desired_action : [1, 163, 166] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.35714286 0.35714286] real action [  1. 165. 169.]\n",
      "reward 0.99974 done:  True\n",
      "observation: [0.68303571 0.23660714 0.45535714 0.53571429 0.70535714 0.73214286\n",
      " 0.24553571 0.16517857 0.75       0.42410714 0.71428571 0.73214286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.35714286]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.018749818079071057, -0.6848211729802323, -0.047501865476369864]\n",
      "action: [  0. 181. 119.]\n",
      "pick_success 1\n",
      "desired_action : [0, 175, 111] phase_loss 0.0 dis_reward -0.0020000000000000005\n",
      "picked_obj 1\n",
      "90 59\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.35714286] real action [  0. 181. 119.]\n",
      "reward -0.0020000000000000005 done:  False\n",
      "observation: [ 0.53571429  0.41964286 -0.02678571  0.45089286  0.16964286  0.69642857\n",
      "  0.58035714  0.64732143  0.19196429  0.16071429  0.71875     0.17857143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.         -0.35714286]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.21696434192092895, -0.31517851298023225, 0.01289967924356461]\n",
      "place_xyz[2] 0.01289967924356461 False\n",
      "desired_action : [1, 45, 33] phase_loss 0.0 dis_reward -0.00016\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.         -0.35714286] real action [ 1. 43. 31.]\n",
      "reward 0.99984 done:  True\n",
      "observation: [0.53571429 0.41964286 0.16071429 0.11160714 0.16964286 0.69642857\n",
      " 0.58035714 0.64732143 0.19196429 0.16071429 0.71875    0.17857143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.11785725192092897, -0.47321414298023223, -0.05180971667170525]\n",
      "action: [  0. 102.  68.]\n",
      "pick_success 1\n",
      "desired_action : [0, 102, 76] phase_loss 0.0 dis_reward -0.00128\n",
      "picked_obj 1\n",
      "51 34\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.35714286] real action [  0. 102.  68.]\n",
      "reward -0.00128 done:  False\n",
      "observation: [0.72321429 0.77678571 0.00446429 0.51785714 0.54910714 0.59375\n",
      " 0.72767857 0.28571429 0.19196429 0.20982143 0.20089286 0.54017857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.57142857 -0.07142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.13125010192092895, -0.6580354729802322, 0.018464866206049924]\n",
      "place_xyz[2] 0.018464866206049924 False\n",
      "desired_action : [1, 167, 63] phase_loss 0.0 dis_reward -0.00032\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.57142857 -0.07142857] real action [  1. 171.  63.]\n",
      "reward 0.99968 done:  True\n",
      "observation: [0.72321429 0.77678571 0.75446429 0.33482143 0.54910714 0.59375\n",
      " 0.72767857 0.28571429 0.19196429 0.20982143 0.20089286 0.54017857] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.35714286]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.03749980807907105, -0.4410713029802322, -0.044166633561253554]\n",
      "action: [  0.  90. 126.]\n",
      "pick_success 1\n",
      "desired_action : [0, 96, 124] phase_loss 0.0 dis_reward -0.0008000000000000003\n",
      "picked_obj 1\n",
      "45 63\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.21428571  0.35714286] real action [  0.  90. 126.]\n",
      "reward -0.0008000000000000003 done:  False\n",
      "observation: [0.80357143 0.51785714 0.03125    0.50446429 0.45535714 0.24107143\n",
      " 0.66071429 0.75       0.82589286 0.12946429 0.24553571 0.76785714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.5        -0.57142857]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.24375004192092897, -0.6767854629802322, 0.019810150489211087]\n",
      "place_xyz[2] 0.019810150489211087 False\n",
      "desired_action : [1, 186, 31] phase_loss 0.0 dis_reward -0.003279999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.5        -0.57142857] real action [  1. 178.  21.]\n",
      "reward 0.99672 done:  True\n",
      "observation: [0.80357143 0.51785714 0.78571429 0.08482143 0.45535714 0.24107143\n",
      " 0.66071429 0.75       0.82589286 0.12946429 0.24553571 0.76785714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.14285714]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.06160728192092896, -0.5589283829802323, -0.047020148187875754]\n",
      "action: [  0. 134.  89.]\n",
      "pick_success 1\n",
      "desired_action : [0, 136, 83] phase_loss 0.0 dis_reward -0.0008000000000000003\n",
      "picked_obj 2\n",
      "67 44\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.14285714] real action [  0. 134.  89.]\n",
      "reward -0.0008000000000000003 done:  False\n",
      "observation: [0.72321429 0.69642857 0.41517857 0.79464286 0.01785714 0.47321429\n",
      " 0.26339286 0.4375     0.33482143 0.13392857 0.83928571 0.13839286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.64285714 -0.28571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.22767862192092897, -0.7276782929802322, 0.019741773717105393]\n",
      "place_xyz[2] 0.019741773717105393 False\n",
      "desired_action : [1, 185, 31] phase_loss 0.0 dis_reward -0.003200000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.64285714 -0.28571429] real action [  1. 197.  27.]\n",
      "reward 0.9968 done:  True\n",
      "observation: [0.72321429 0.69642857 0.41517857 0.79464286 0.87053571 0.10714286\n",
      " 0.26339286 0.4375     0.33482143 0.13392857 0.83928571 0.13839286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.19017864192092895, -0.49999984298023226, -0.060000000000000005]\n",
      "action: [  0. 112.  41.]\n",
      "pick_success 0\n",
      "desired_action : [0, 114, 42] phase_loss 0.0 dis_reward -9.999999999999885e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.28571429  0.07142857] real action [  0. 112.  41.]\n",
      "reward -9.999999999999885e-05 done:  False\n",
      "observation: [0.51785714 0.17857143 0.55357143 0.73660714 0.20089286 0.33482143\n",
      " 0.82589286 0.53571429 0.81696429 0.25892857 0.24553571 0.72767857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.19553578192092896, -0.5160712629802322, -0.060000000000000005]\n",
      "action: [  0. 118.  39.]\n",
      "pick_success 0\n",
      "desired_action : [0, 114, 42] phase_loss 0.0 dis_reward -0.0005000000000000023\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [  0. 118.  39.]\n",
      "reward -0.0005000000000000023 done:  False\n",
      "observation: [0.51785714 0.17857143 0.55357143 0.73660714 0.20089286 0.33482143\n",
      " 0.82589286 0.53571429 0.81696429 0.25892857 0.24553571 0.72767857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.19821435192092896, -0.5133926929802322, -0.060000000000000005]\n",
      "action: [  0. 117.  38.]\n",
      "pick_success 0\n",
      "desired_action : [0, 114, 42] phase_loss 0.0 dis_reward -0.0005000000000000017\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.07142857 -0.14285714] real action [  0. 117.  38.]\n",
      "reward -0.0005000000000000017 done:  False\n",
      "observation: [0.51785714 0.17857143 0.55357143 0.73660714 0.20089286 0.33482143\n",
      " 0.82589286 0.53571429 0.81696429 0.25892857 0.24553571 0.72767857] [False]\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.19285721192092897, -0.5133926929802322, -0.060000000000000005]\n",
      "action: [  0. 117.  40.]\n",
      "pick_success 0\n",
      "desired_action : [0, 114, 42] phase_loss 0.0 dis_reward -0.0002600000000000017\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.07142857 0.        ] real action [  0. 117.  40.]\n",
      "reward -0.0002600000000000017 done:  False\n",
      "observation: [0.51785714 0.17857143 0.55357143 0.73660714 0.20089286 0.33482143\n",
      " 0.82589286 0.53571429 0.81696429 0.25892857 0.24553571 0.72767857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857  0.        ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.19285721192092897, -0.48928556298023224, -0.04288336232304574]\n",
      "action: [  0. 108.  40.]\n",
      "pick_success 1\n",
      "desired_action : [0, 114, 42] phase_loss 0.0 dis_reward -0.0007999999999999965\n",
      "picked_obj 0\n",
      "54 20\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857  0.        ] real action [  0. 108.  40.]\n",
      "reward -0.0007999999999999965 done:  False\n",
      "observation: [0.04017857 0.50892857 0.55357143 0.73660714 0.20089286 0.33482143\n",
      " 0.82589286 0.53571429 0.81696429 0.25892857 0.24553571 0.72767857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.64285714  0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.02946409807907102, -0.6714283229802323, 0.019748346060514455]\n",
      "place_xyz[2] 0.019748346060514455 False\n",
      "desired_action : [1, 184, 124] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.64285714  0.21428571] real action [  1. 176. 123.]\n",
      "reward 0.9987 done:  True\n",
      "observation: [0.82589286 0.57142857 0.55357143 0.73660714 0.20089286 0.33482143\n",
      " 0.82589286 0.53571429 0.81696429 0.25892857 0.24553571 0.72767857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.28571429]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.02410695807907104, -0.5589283829802323, -0.04925057448446751]\n",
      "action: [  0. 134. 121.]\n",
      "pick_success 1\n",
      "desired_action : [0, 127, 120] phase_loss 0.0 dis_reward -0.001\n",
      "picked_obj 0\n",
      "67 60\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.35714286 0.28571429] real action [  0. 134. 121.]\n",
      "reward -0.001 done:  False\n",
      "observation: [-0.00892857  0.48214286  0.49553571  0.19196429  0.83035714  0.53571429\n",
      "  0.22321429  0.76339286  0.21875     0.15625     0.5625      0.75892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.57142857  0.5       ]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [0.17410687807907105, -0.5160712629802322, 0.016387954466044907]\n",
      "place_xyz[2] 0.016387954466044907 False\n",
      "desired_action : [1, 127, 172] phase_loss 0.0 dis_reward -0.0021200000000000004\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.57142857  0.5       ] real action [  1. 118. 177.]\n",
      "reward 0.99788 done:  True\n",
      "observation: [0.47767857 0.8125     0.49553571 0.19196429 0.83035714 0.53571429\n",
      " 0.22321429 0.76339286 0.21875    0.15625    0.5625     0.75892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.28571429]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.02410695807907104, -0.6419640529802322, -0.060000000000000005]\n",
      "action: [  0. 165. 121.]\n",
      "pick_success 0\n",
      "desired_action : [0, 162, 124] phase_loss 0.0 dis_reward -0.0003599999999999999\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.28571429] real action [  0. 165. 121.]\n",
      "reward -0.0003599999999999999 done:  False\n",
      "observation: [0.44642857 0.41517857 0.72321429 0.55803571 0.70089286 0.20089286\n",
      " 0.375      0.71875    0.19642857 0.18303571 0.67410714 0.75446429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.5        0.07142857]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.03749980807907105, -0.6526783329802321, -0.05117251880466939]\n",
      "action: [  0. 169. 126.]\n",
      "pick_success 1\n",
      "desired_action : [0, 162, 124] phase_loss 0.0 dis_reward -0.00106\n",
      "picked_obj 1\n",
      "84 63\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.5        0.07142857] real action [  0. 169. 126.]\n",
      "reward -0.00106 done:  False\n",
      "observation: [ 0.44642857  0.41517857 -0.01785714  0.49553571  0.70089286  0.20089286\n",
      "  0.375       0.71875     0.23214286  0.18303571  0.67410714  0.75446429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.07142857  0.57142857]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.17410687807907105, -0.6017855029802321, 0.015845456272363667]\n",
      "place_xyz[2] 0.015845456272363667 False\n",
      "desired_action : [1, 149, 172] phase_loss 0.0 dis_reward -0.00052\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.07142857  0.57142857] real action [  1. 150. 177.]\n",
      "reward 0.99948 done:  True\n",
      "observation: [0.44642857 0.41517857 0.625      0.79910714 0.70089286 0.20089286\n",
      " 0.375      0.71875    0.23214286 0.18303571 0.67410714 0.75446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.11250011192092896, -0.4919641329802322, -0.04676436975598336]\n",
      "action: [  0. 109.  70.]\n",
      "pick_success 1\n",
      "desired_action : [0, 111, 72] phase_loss 0.0 dis_reward -0.00016\n",
      "picked_obj 2\n",
      "54 35\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429 -0.14285714] real action [  0. 109.  70.]\n",
      "reward -0.00016 done:  False\n",
      "observation: [0.81696429 0.30357143 0.29910714 0.63392857 0.03125    0.50892857\n",
      " 0.74107143 0.62053571 0.19642857 0.19196429 0.49553571 0.77232143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.71428571 0.        ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.18482150192092894, -0.3446427829802322, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 48, 43] phase_loss 0.0 dis_reward -0.00072\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.71428571 0.        ] real action [ 1. 54. 43.]\n",
      "reward 0.99928 done:  True\n",
      "observation: [0.81696429 0.30357143 0.29910714 0.63392857 0.24107143 0.20535714\n",
      " 0.74107143 0.62053571 0.19642857 0.19196429 0.49553571 0.77232143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.28571429 -0.42857143]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.09642834807907102, -0.4758927129802322, -0.04274154238402844]\n",
      "action: [  0. 103. 148.]\n",
      "pick_success 1\n",
      "desired_action : [0, 103, 151] phase_loss 0.0 dis_reward -0.00018\n",
      "picked_obj 2\n",
      "51 74\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.28571429 -0.42857143] real action [  0. 103. 148.]\n",
      "reward -0.00018 done:  False\n",
      "observation: [ 0.75446429  0.26785714  0.375       0.39732143 -0.00892857  0.50892857\n",
      "  0.70535714  0.75892857  0.44196429  0.11607143  0.19196429  0.78571429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.5        0.71428571]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.20357149192092897, -0.48392842298023225, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 103, 28] phase_loss 0.0 dis_reward -0.0014599999999999995\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.5        0.71428571] real action [  1. 106.  36.]\n",
      "reward 0.99854 done:  True\n",
      "observation: [0.75446429 0.26785714 0.375      0.39732143 0.45982143 0.15625\n",
      " 0.70535714 0.75892857 0.44196429 0.11607143 0.19196429 0.78571429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.07142857]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.010714108079071027, -0.34732135298023226, -0.060000000000000005]\n",
      "action: [  0.  55. 116.]\n",
      "pick_success 0\n",
      "desired_action : [0, 58, 119] phase_loss 0.0 dis_reward -0.0003599999999999999\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.07142857] real action [  0.  55. 116.]\n",
      "reward -0.0003599999999999999 done:  False\n",
      "observation: [0.25       0.52232143 0.62053571 0.625      0.58928571 0.21875\n",
      " 0.83035714 0.29017857 0.17857143 0.15625    0.41964286 0.76785714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping pick:  [0.008035538079071036, -0.34732135298023226, -0.060000000000000005]\n",
      "action: [  0.  55. 115.]\n",
      "pick_success 1\n",
      "desired_action : [0, 60, 118] phase_loss 0.0 dis_reward -0.00068\n",
      "picked_obj 0\n",
      "27 57\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.14285714] real action [  0.  55. 115.]\n",
      "reward -0.00068 done:  False\n",
      "observation: [0.01339286 0.51785714 0.62053571 0.625      0.58928571 0.21875\n",
      " 0.83035714 0.29017857 0.17857143 0.15625    0.41964286 0.76785714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429 -0.78571429]\n",
      "lang goal put the Letter O on a green bowl\n",
      "steping: place [-0.23571433192092894, -0.29642852298023226, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 44, 34] phase_loss 0.0 dis_reward -0.0032800000000000004\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429 -0.78571429] real action [ 1. 36. 24.]\n",
      "reward 0.99672 done:  True\n",
      "observation: [0.17857143 0.10714286 0.62053571 0.625      0.58928571 0.21875\n",
      " 0.83035714 0.29017857 0.17857143 0.15625    0.41964286 0.76785714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.07232121807907105, -0.3419642129802323, -0.046775858551263816]\n",
      "action: [  0.  53. 139.]\n",
      "pick_success 1\n",
      "desired_action : [0, 47, 142] phase_loss 0.0 dis_reward -0.0009000000000000002\n",
      "picked_obj 2\n",
      "26 69\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.14285714 -0.21428571] real action [  0.  53. 139.]\n",
      "reward -0.0009000000000000002 done:  False\n",
      "observation: [ 0.80803571  0.32589286  0.62946429  0.58035714 -0.02678571  0.51339286\n",
      "  0.47321429  0.76785714  0.49107143  0.12946429  0.16071429  0.16071429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429 -0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.21160720192092897, -0.28571424298023224, 0.016371940374374394]\n",
      "place_xyz[2] 0.016371940374374394 False\n",
      "desired_action : [1, 38, 32] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429 -0.21428571] real action [ 1. 32. 33.]\n",
      "reward 0.99926 done:  True\n",
      "observation: [0.80803571 0.32589286 0.62946429 0.58035714 0.12053571 0.16071429\n",
      " 0.47321429 0.76785714 0.49107143 0.12946429 0.16071429 0.16071429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5         0.57142857]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.03482123807907106, -0.5776783729802322, -0.060000000000000005]\n",
      "action: [  0. 141. 125.]\n",
      "pick_success 0\n",
      "desired_action : [0, 149, 121] phase_loss 0.0 dis_reward -0.0016\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5         0.57142857] real action [  0. 141. 125.]\n",
      "reward -0.0016 done:  False\n",
      "observation: [0.30357143 0.37053571 0.66071429 0.52232143 0.77678571 0.24553571\n",
      " 0.37053571 0.55803571 0.63392857 0.79464286 0.52232143 0.19196429] [False]\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.64285714]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.03749980807907105, -0.5991069329802322, -0.060000000000000005]\n",
      "action: [  0. 149. 126.]\n",
      "pick_success 1\n",
      "desired_action : [0, 149, 121] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "picked_obj 1\n",
      "74 63\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.07142857 0.64285714] real action [  0. 149. 126.]\n",
      "reward -0.0005000000000000001 done:  False\n",
      "observation: [0.30357143 0.37053571 0.00892857 0.48214286 0.77678571 0.24553571\n",
      " 0.37053571 0.55803571 0.63392857 0.79464286 0.52232143 0.19196429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429  0.64285714]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.20089257807907102, -0.5696426629802323, 0.01674471620470286]\n",
      "place_xyz[2] 0.01674471620470286 False\n",
      "desired_action : [1, 142, 175] phase_loss 0.0 dis_reward -0.003200000000000001\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429  0.64285714] real action [  1. 138. 187.]\n",
      "reward 0.9968 done:  True\n",
      "observation: [0.30357143 0.37053571 0.625      0.81696429 0.77678571 0.24553571\n",
      " 0.37053571 0.55803571 0.63392857 0.79464286 0.52232143 0.19196429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.57142857]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.09642869192092896, -0.6553569029802322, -0.04732368297874928]\n",
      "action: [  0. 170.  76.]\n",
      "pick_success 1\n",
      "desired_action : [0, 165, 85] phase_loss 0.0 dis_reward -0.0021200000000000004\n",
      "picked_obj 1\n",
      "85 38\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.57142857] real action [  0. 170.  76.]\n",
      "reward -0.0021200000000000004 done:  False\n",
      "observation: [ 0.23660714  0.77232143 -0.01339286  0.52678571  0.53571429  0.73214286\n",
      "  0.36607143  0.13839286  0.48214286  0.44642857  0.8125      0.68303571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429 -0.07142857]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.10714262807907105, -0.6767854629802322, 0.015391796007752423]\n",
      "place_xyz[2] 0.015391796007752423 False\n",
      "desired_action : [1, 179, 154] phase_loss 0.0 dis_reward -0.0001\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.28571429 -0.07142857] real action [  1. 178. 152.]\n",
      "reward 0.9999 done:  True\n",
      "observation: [0.23660714 0.77232143 0.75446429 0.6875     0.53571429 0.73214286\n",
      " 0.36607143 0.13839286 0.48214286 0.44642857 0.8125     0.68303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.57142857]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.152678318079071, -0.6258926329802322, -0.046741297170519835]\n",
      "action: [  0. 159. 169.]\n",
      "pick_success 1\n",
      "desired_action : [0, 157, 162] phase_loss 0.0 dis_reward -0.00106\n",
      "picked_obj 1\n",
      "79 84\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.57142857] real action [  0. 159. 169.]\n",
      "reward -0.00106 done:  False\n",
      "observation: [ 0.56696429  0.29464286 -0.01785714  0.47321429  0.29910714  0.76339286\n",
      "  0.22767857  0.20535714  0.37946429  0.48660714  0.81696429  0.45535714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.92857143 0.14285714]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.0026787419209289842, -0.4624998629802322, 0.010684951785951857]\n",
      "place_xyz[2] 0.010684951785951857 False\n",
      "desired_action : [1, 85, 108] phase_loss 0.0 dis_reward -0.0035600000000000007\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.92857143 0.14285714] real action [  1.  98. 111.]\n",
      "reward 0.99644 done:  True\n",
      "observation: [0.56696429 0.29464286 0.42857143 0.46875    0.29910714 0.76339286\n",
      " 0.22767857 0.20535714 0.37946429 0.48660714 0.81696429 0.45535714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.14285714]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.021428388079071048, -0.5642855229802322, -0.060000000000000005]\n",
      "action: [  0. 136. 120.]\n",
      "pick_success 0\n",
      "desired_action : [0, 132, 117] phase_loss 0.0 dis_reward -0.0005000000000000001\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.28571429 0.14285714] real action [  0. 136. 120.]\n",
      "reward -0.0005000000000000001 done:  False\n",
      "observation: [0.37946429 0.22767857 0.58928571 0.52678571 0.19642857 0.45535714\n",
      " 0.78571429 0.18303571 0.79910714 0.65178571 0.24107143 0.68303571] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.5        -0.14285714]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.010714108079071027, -0.5723212329802323, -0.04632740251719952]\n",
      "action: [  0. 139. 116.]\n",
      "pick_success 1\n",
      "desired_action : [0, 132, 117] phase_loss 0.0 dis_reward -0.001\n",
      "picked_obj 1\n",
      "69 58\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.5        -0.14285714] real action [  0. 139. 116.]\n",
      "reward -0.001 done:  False\n",
      "observation: [ 0.37946429  0.22767857 -0.02678571  0.49107143  0.19642857  0.45535714\n",
      "  0.78571429  0.18303571  0.79910714  0.65178571  0.24107143  0.68303571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.14285714 0.        ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.19017864192092895, -0.6767854629802322, 0.01821210060268641]\n",
      "place_xyz[2] 0.01821210060268641 False\n",
      "desired_action : [1, 179, 38] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.14285714 0.        ] real action [  1. 178.  41.]\n",
      "reward 0.9998 done:  True\n",
      "observation: [0.37946429 0.22767857 0.75       0.20089286 0.19642857 0.45535714\n",
      " 0.78571429 0.18303571 0.79910714 0.65178571 0.24107143 0.68303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [0.17410687807907105, -0.6473211929802323, -0.04299442440271378]\n",
      "action: [  0. 167. 177.]\n",
      "pick_success 1\n",
      "desired_action : [0, 171, 175] phase_loss 0.0 dis_reward -0.0004\n",
      "picked_obj 2\n",
      "83 88\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.14285714] real action [  0. 167. 177.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.46428571 0.59375    0.46428571 0.3125     0.02232143 0.49107143\n",
      " 0.1875     0.77232143 0.69642857 0.1875     0.21428571 0.5       ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.14285714 -0.28571429]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.19821435192092896, -0.6124997829802322, 0.01830806035548449]\n",
      "place_xyz[2] 0.01830806035548449 False\n",
      "desired_action : [1, 155, 46] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.14285714 -0.28571429] real action [  1. 154.  38.]\n",
      "reward 0.9987 done:  True\n",
      "observation: [0.46428571 0.59375    0.46428571 0.3125     0.70089286 0.15178571\n",
      " 0.1875     0.77232143 0.69642857 0.1875     0.21428571 0.5       ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.12589296192092897, -0.38482133298023224, -0.060000000000000005]\n",
      "action: [ 0. 69. 65.]\n",
      "pick_success 0\n",
      "desired_action : [0, 70, 68] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.14285714 -0.07142857] real action [ 0. 69. 65.]\n",
      "reward -0.00020000000000000006 done:  False\n",
      "observation: [0.29910714 0.29464286 0.63392857 0.73214286 0.73214286 0.23214286\n",
      " 0.27678571 0.65178571 0.48214286 0.44196429 0.80357143 0.55357143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.12589296192092897, -0.3767856229802322, -0.060000000000000005]\n",
      "action: [ 0. 66. 65.]\n",
      "pick_success 0\n",
      "desired_action : [0, 69, 67] phase_loss 0.0 dis_reward -0.00026\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.07142857 -0.07142857] real action [ 0. 66. 65.]\n",
      "reward -0.00026 done:  False\n",
      "observation: [0.29910714 0.29464286 0.63392857 0.73214286 0.73214286 0.23214286\n",
      " 0.27678571 0.65178571 0.48214286 0.44196429 0.80357143 0.55357143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.12589296192092897, -0.37142848298023223, -0.060000000000000005]\n",
      "action: [ 0. 64. 65.]\n",
      "pick_success 1\n",
      "desired_action : [0, 69, 67] phase_loss 0.0 dis_reward -0.0005799999999999999\n",
      "picked_obj 0\n",
      "32 32\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.07142857] real action [ 0. 64. 65.]\n",
      "reward -0.0005799999999999999 done:  False\n",
      "observation: [0.01785714 0.46875    0.63392857 0.73214286 0.73214286 0.23214286\n",
      " 0.27678571 0.65178571 0.48214286 0.44196429 0.80357143 0.55357143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.71428571 0.42857143]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.10714262807907105, -0.3928570429802322, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 65, 146] phase_loss 0.0 dis_reward -0.0017000000000000001\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.71428571 0.42857143] real action [  1.  72. 152.]\n",
      "reward 0.9983 done:  True\n",
      "observation: [0.34821429 0.70535714 0.63392857 0.73214286 0.73214286 0.23214286\n",
      " 0.27678571 0.65178571 0.48214286 0.44196429 0.80357143 0.55357143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.42857143]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.13928546807907105, -0.32857136298023226, -0.060000000000000005]\n",
      "action: [  0.  48. 164.]\n",
      "pick_success 0\n",
      "desired_action : [0, 48, 170] phase_loss 0.0 dis_reward -0.00072\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.42857143] real action [  0.  48. 164.]\n",
      "reward -0.00072 done:  False\n",
      "observation: [0.80357143 0.53571429 0.20089286 0.75892857 0.45089286 0.62946429\n",
      " 0.40625    0.26339286 0.75892857 0.77232143 0.83035714 0.25892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.35714286]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14196403807907104, -0.3312499329802322, -0.060000000000000005]\n",
      "action: [  0.  49. 165.]\n",
      "pick_success 0\n",
      "desired_action : [0, 50, 170] phase_loss 0.0 dis_reward -0.00052\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.28571429 -0.35714286] real action [  0.  49. 165.]\n",
      "reward -0.00052 done:  False\n",
      "observation: [0.80357143 0.53571429 0.23660714 0.76339286 0.45089286 0.62946429\n",
      " 0.40625    0.26339286 0.71428571 0.80803571 0.83035714 0.25892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.13928546807907105, -0.33660707298023224, -0.060000000000000005]\n",
      "action: [  0.  51. 164.]\n",
      "pick_success 0\n",
      "desired_action : [0, 52, 170] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714 -0.5       ] real action [  0.  51. 164.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [0.80357143 0.53571429 0.23660714 0.76339286 0.45089286 0.62946429\n",
      " 0.40625    0.26339286 0.71428571 0.79017857 0.83035714 0.25892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5        -0.42857143]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.14196403807907104, -0.3232142229802322, -0.04831968218088151]\n",
      "action: [  0.  46. 165.]\n",
      "pick_success 1\n",
      "desired_action : [0, 53, 170] phase_loss 0.0 dis_reward -0.00148\n",
      "picked_obj 1\n",
      "23 82\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5        -0.42857143] real action [  0.  46. 165.]\n",
      "reward -0.00148 done:  False\n",
      "observation: [0.80357143 0.53571429 0.04017857 0.51339286 0.45089286 0.62946429\n",
      " 0.40625    0.26339286 0.71428571 0.79017857 0.83035714 0.25892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -1.          0.64285714]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [-0.12053582192092896, -0.6607140429802323, 0.019610512182116513]\n",
      "place_xyz[2] 0.019610512182116513 False\n",
      "desired_action : [1, 185, 55] phase_loss 0.0 dis_reward -0.006259999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -1.          0.64285714] real action [  1. 172.  67.]\n",
      "reward -0.006259999999999999 done:  False\n",
      "observation: [0.80357143 0.53571429 0.79464286 0.33482143 0.45089286 0.62946429\n",
      " 0.40625    0.26339286 0.71428571 0.79017857 0.83035714 0.25892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.10446440192092896, -0.6633926129802322, -0.03002545580267906]\n",
      "action: [  0. 173.  73.]\n",
      "pick_success 1\n",
      "desired_action : [False, 176, 72] phase_loss 0.0 dis_reward -0.00020000000000000006\n",
      "picked_obj 1\n",
      "86 36\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714] real action [  0. 173.  73.]\n",
      "reward -0.00020000000000000006 done:  False\n",
      "observation: [0.80357143 0.53571429 0.04464286 0.5        0.45089286 0.62946429\n",
      " 0.40625    0.26339286 0.71428571 0.79017857 0.83035714 0.25892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.14285714 -0.5       ]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [-0.16339294192092896, -0.7035711629802323, 0.01942224066704512]\n",
      "place_xyz[2] 0.01942224066704512 False\n",
      "desired_action : [1, 185, 55] phase_loss 0.0 dis_reward -0.000499999999999999\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.          0.14285714 -0.5       ] real action [  1. 188.  51.]\n",
      "reward 0.9995 done:  True\n",
      "observation: [0.80357143 0.53571429 0.82589286 0.23660714 0.45089286 0.62946429\n",
      " 0.40625    0.26339286 0.71428571 0.79017857 0.83035714 0.25892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.06964299192092896, -0.6071426429802322, -0.060000000000000005]\n",
      "action: [  0. 152.  86.]\n",
      "pick_success 1\n",
      "desired_action : [0, 158, 87] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "picked_obj 1\n",
      "76 43\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857] real action [  0. 152.  86.]\n",
      "reward -0.0007399999999999999 done:  False\n",
      "observation: [0.29464286 0.37946429 0.04464286 0.5        0.26339286 0.74107143\n",
      " 0.70535714 0.67857143 0.54464286 0.15625    0.48660714 0.53571429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.71428571  0.42857143]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.12321404807907105, -0.5964283629802323, 0.016259866878390317]\n",
      "place_xyz[2] 0.016259866878390317 False\n",
      "desired_action : [1, 162, 156] phase_loss 0.0 dis_reward -0.004\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.71428571  0.42857143] real action [  1. 148. 158.]\n",
      "reward 0.996 done:  True\n",
      "observation: [0.29464286 0.37946429 0.70089286 0.70535714 0.26339286 0.74107143\n",
      " 0.70982143 0.6875     0.54464286 0.15625    0.48660714 0.53571429] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.57142857 0.        ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.16339259807907103, -0.6205354929802323, -0.05377710767090321]\n",
      "action: [  0. 157. 173.]\n",
      "pick_success 0\n",
      "desired_action : [0, 151, 173] phase_loss 0.0 dis_reward -0.00072\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.57142857 0.        ] real action [  0. 157. 173.]\n",
      "reward -0.00072 done:  False\n",
      "observation: [0.45535714 0.52232143 0.66517857 0.77232143 0.36160714 0.1875\n",
      " 0.15625    0.55803571 0.72767857 0.48660714 0.68303571 0.14285714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.57142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.14196403807907104, -0.6071426429802322, -0.05421356640756131]\n",
      "action: [  0. 152. 165.]\n",
      "pick_success 1\n",
      "desired_action : [0, 151, 173] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "picked_obj 1\n",
      "76 82\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.          0.21428571 -0.57142857] real action [  0. 152. 165.]\n",
      "reward -0.0012999999999999997 done:  False\n",
      "observation: [0.45535714 0.52232143 0.02232143 0.54910714 0.36160714 0.1875\n",
      " 0.15625    0.55803571 0.72767857 0.48660714 0.68303571 0.14285714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.42857143 -0.07142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.03214266807907101, -0.30982137298023227, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 40, 125] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.42857143 -0.07142857] real action [  1.  41. 124.]\n",
      "reward 0.99996 done:  True\n",
      "observation: [0.45535714 0.52232143 0.18303571 0.60714286 0.36160714 0.1875\n",
      " 0.15625    0.55803571 0.72767857 0.48660714 0.68303571 0.14285714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.  0.  0.  1.  0.  0.  0.  0.  0.5]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.20357114807907106, -0.5187498329802323, -0.04598542273044587]\n",
      "action: [  0. 119. 188.]\n",
      "pick_success 1\n",
      "desired_action : [0, 120, 181] phase_loss 0.0 dis_reward -0.001\n",
      "picked_obj 2\n",
      "59 94\n",
      "action  [0.  0.  0.  1.  0.  0.  0.  0.  0.5] real action [  0. 119. 188.]\n",
      "reward -0.001 done:  False\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.         0.47321429\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143  0.5       ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.042857291920928964, -0.6312497729802322, 0.017117009609937672]\n",
      "place_xyz[2] 0.017117009609937672 False\n",
      "desired_action : [1, 164, 86] phase_loss 0.0 dis_reward -0.00218\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143  0.5       ] real action [  1. 161.  96.]\n",
      "reward 0.99782 done:  True\n",
      "observation: [0.38392857 0.20535714 0.30357143 0.70982143 0.73214286 0.40625\n",
      " 0.74553571 0.39732143 0.83928571 0.70982143 0.63839286 0.12946429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.        ]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.19285721192092897, -0.6151783529802322, -0.04442432679235936]\n",
      "action: [  0. 155.  40.]\n",
      "pick_success 1\n",
      "desired_action : [0, 153, 40] phase_loss 0.0 dis_reward -8e-05\n",
      "picked_obj 2\n",
      "77 20\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.14285714 0.        ] real action [  0. 155.  40.]\n",
      "reward -8e-05 done:  False\n",
      "observation: [0.51785714 0.5        0.29017857 0.67857143 0.         0.49107143\n",
      " 0.83035714 0.48214286 0.36160714 0.125      0.50892857 0.75446429] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         1.\n",
      " 0.         0.28571429 0.14285714]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [-0.21964291192092894, -0.4276784529802322, 0.016185253970324998]\n",
      "place_xyz[2] 0.016185253970324998 False\n",
      "desired_action : [1, 84, 29] phase_loss 0.0 dis_reward -4e-05\n",
      "action  [1.         0.         0.         0.         0.         1.\n",
      " 0.         0.28571429 0.14285714] real action [ 1. 85. 30.]\n",
      "reward 0.99996 done:  True\n",
      "observation: [0.51785714 0.5        0.29017857 0.67857143 0.35267857 0.12946429\n",
      " 0.83035714 0.48214286 0.36160714 0.125      0.50892857 0.75446429] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.28571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.01607124807907101, -0.41696417298023225, -0.060000000000000005]\n",
      "action: [  0.  81. 119.]\n",
      "pick_success 0\n",
      "desired_action : [0, 82, 115] phase_loss 0.0 dis_reward -0.0003399999999999977\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.28571429] real action [  0.  81. 119.]\n",
      "reward -0.0003399999999999977 done:  False\n",
      "observation: [0.38392857 0.51339286 0.38839286 0.78571429 0.625      0.29017857\n",
      " 0.79017857 0.78125    0.63392857 0.57589286 0.27678571 0.17410714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.0026783980790710538, -0.4142856029802322, -0.060000000000000005]\n",
      "action: [  0.  80. 114.]\n",
      "pick_success 0\n",
      "desired_action : [0, 82, 115] phase_loss 0.0 dis_reward -0.00010000000000000057\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857] real action [  0.  80. 114.]\n",
      "reward -0.00010000000000000057 done:  False\n",
      "observation: [0.38392857 0.51339286 0.38839286 0.78571429 0.625      0.29017857\n",
      " 0.79017857 0.78125    0.63392857 0.57589286 0.27678571 0.17410714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-1.7192092893747457e-07, -0.42232131298023223, -0.060000000000000005]\n",
      "action: [  0.  83. 113.]\n",
      "pick_success 0\n",
      "desired_action : [0, 82, 115] phase_loss 0.0 dis_reward -0.00010000000000000112\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.21428571 -0.14285714] real action [  0.  83. 113.]\n",
      "reward -0.00010000000000000112 done:  False\n",
      "observation: [0.38392857 0.51339286 0.38839286 0.78571429 0.625      0.29017857\n",
      " 0.79017857 0.78125    0.63392857 0.57589286 0.27678571 0.17410714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [0.010714108079071027, -0.4249998829802322, -0.060000000000000005]\n",
      "action: [  0.  84. 117.]\n",
      "pick_success 0\n",
      "desired_action : [0, 83, 115] phase_loss 0.0 dis_reward -9.999999999999885e-05\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.14285714  0.14285714] real action [  0.  84. 117.]\n",
      "reward -9.999999999999885e-05 done:  False\n",
      "observation: [0.38392857 0.51339286 0.38839286 0.78571429 0.625      0.29017857\n",
      " 0.79017857 0.78125    0.63392857 0.57589286 0.27678571 0.17410714] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.21428571]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.0026787419209289842, -0.4089284629802322, -0.060000000000000005]\n",
      "action: [  0.  78. 112.]\n",
      "pick_success 1\n",
      "desired_action : [0, 83, 115] phase_loss 0.0 dis_reward -0.0006800000000000018\n",
      "picked_obj 0\n",
      "39 55\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.21428571] real action [  0.  78. 112.]\n",
      "reward -0.0006800000000000018 done:  False\n",
      "observation: [0.02232143 0.50892857 0.38839286 0.78571429 0.625      0.29017857\n",
      " 0.79017857 0.78125    0.63392857 0.57589286 0.27678571 0.17410714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143 -0.64285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [0.14464260807907103, -0.6580354729802322, 0.01960349187254906]\n",
      "place_xyz[2] 0.01960349187254906 False\n",
      "desired_action : [1, 175, 177] phase_loss 0.0 dis_reward -0.0027400000000000002\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.42857143 -0.64285714] real action [  1. 171. 166.]\n",
      "reward 0.99726 done:  True\n",
      "observation: [0.76785714 0.74107143 0.38839286 0.78571429 0.625      0.29017857\n",
      " 0.79017857 0.78125    0.63392857 0.57589286 0.27678571 0.17410714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.14285714]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.07500013192092897, -0.5749998029802322, -0.04663796320557595]\n",
      "action: [  0. 140.  84.]\n",
      "pick_success 1\n",
      "desired_action : [0, 136, 90] phase_loss 0.0 dis_reward -0.00104\n",
      "picked_obj 0\n",
      "70 42\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.          0.42857143 -0.14285714] real action [  0. 140.  84.]\n",
      "reward -0.00104 done:  False\n",
      "observation: [-0.01785714  0.52232143  0.24107143  0.78571429  0.79464286  0.71428571\n",
      "  0.3125      0.1875      0.47321429  0.64285714  0.16964286  0.39732143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571 -0.5       ]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.20625006192092896, -0.37946419298023226, 0.013332950063049798]\n",
      "place_xyz[2] 0.013332950063049798 False\n",
      "desired_action : [1, 69, 41] phase_loss 0.0 dis_reward -0.0008000000000000003\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571 -0.5       ] real action [ 1. 67. 35.]\n",
      "reward 0.9992 done:  True\n",
      "observation: [0.27232143 0.17857143 0.24107143 0.78571429 0.79464286 0.71428571\n",
      " 0.3125     0.1875     0.47321429 0.64285714 0.16964286 0.39732143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.20892828807907105, -0.36071420298023227, -0.047350270375609405]\n",
      "action: [  0.  60. 190.]\n",
      "pick_success 1\n",
      "desired_action : [0, 62, 186] phase_loss 0.0 dis_reward -0.0004\n",
      "picked_obj 2\n",
      "30 95\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.28571429  0.21428571] real action [  0.  60. 190.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.40178571 0.36160714 0.30803571 0.60267857 0.00446429 0.48660714\n",
      " 0.74553571 0.25892857 0.82589286 0.57589286 0.57142857 0.65625   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.28571429 0.07142857]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.14196438192092897, -0.6580354729802322, 0.02053351525217295]\n",
      "place_xyz[2] 0.02053351525217295 False\n",
      "desired_action : [1, 167, 58] phase_loss 0.0 dis_reward -0.0003400000000000003\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.28571429 0.07142857] real action [  1. 171.  59.]\n",
      "reward 0.99966 done:  True\n",
      "observation: [0.40178571 0.36160714 0.30803571 0.60267857 0.76339286 0.25446429\n",
      " 0.74553571 0.25892857 0.82589286 0.57589286 0.57142857 0.65625   ] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.07142857]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping pick:  [-0.19017864192092895, -0.4758927129802322, -0.04855976410210133]\n",
      "action: [  0. 103.  41.]\n",
      "pick_success 1\n",
      "desired_action : [0, 110, 40] phase_loss 0.0 dis_reward -0.001\n",
      "picked_obj 0\n",
      "51 20\n",
      "action  [ 0.          1.          0.          0.          0.          0.\n",
      "  0.         -0.35714286  0.07142857] real action [  0. 103.  41.]\n",
      "reward -0.001 done:  False\n",
      "observation: [0.04464286 0.47767857 0.4375     0.76339286 0.1875     0.625\n",
      " 0.44196429 0.38392857 0.73660714 0.42857143 0.70535714 0.71875   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.78571429]\n",
      "lang goal put the Letter O on a yellow bowl\n",
      "steping: place [-0.04017872192092897, -0.45714272298023223, 0.016630821973085408]\n",
      "place_xyz[2] 0.016630821973085408 False\n",
      "desired_action : [1, 103, 88] phase_loss 0.0 dis_reward -0.0026\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.21428571  0.78571429] real action [ 1. 96. 97.]\n",
      "reward 0.9974 done:  True\n",
      "observation: [0.45535714 0.44196429 0.42410714 0.77232143 0.1875     0.625\n",
      " 0.44196429 0.38392857 0.73660714 0.42857143 0.70535714 0.71875   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [0.17678544807907104, -0.6366069129802322, -0.060000000000000005]\n",
      "action: [  0. 163. 178.]\n",
      "pick_success 1\n",
      "desired_action : [0, 167, 185] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "picked_obj 1\n",
      "81 89\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.14285714] real action [  0. 163. 178.]\n",
      "reward -0.0012999999999999997 done:  False\n",
      "observation: [0.58928571 0.19642857 0.04017857 0.53571429 0.73214286 0.4375\n",
      " 0.46428571 0.5625     0.26785714 0.70535714 0.15625    0.18303571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.28571429 -0.71428571]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.09642834807907102, -0.37142848298023223, 0.0063440722832456276]\n",
      "place_xyz[2] 0.0063440722832456276 False\n",
      "desired_action : [1, 58, 160] phase_loss 0.0 dis_reward -0.0036000000000000008\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.          0.28571429 -0.71428571] real action [  1.  64. 148.]\n",
      "reward 0.9964 done:  True\n",
      "observation: [0.58928571 0.19642857 0.32142857 0.67857143 0.73214286 0.4375\n",
      " 0.46428571 0.5625     0.26785714 0.70535714 0.15625    0.18303571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.21428571]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [0.187499728079071, -0.6205354929802323, -0.04543620690703393]\n",
      "action: [  0. 157. 182.]\n",
      "pick_success 1\n",
      "desired_action : [0, 153, 176] phase_loss 0.0 dis_reward -0.00104\n",
      "picked_obj 1\n",
      "78 91\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.42857143 0.21428571] real action [  0. 157. 182.]\n",
      "reward -0.00104 done:  False\n",
      "observation: [0.49553571 0.58482143 0.00446429 0.44642857 0.23660714 0.43303571\n",
      " 0.6875     0.25892857 0.44642857 0.10714286 0.375      0.79464286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.35714286 0.14285714]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.18214258807907102, -0.43839273298023224, 0.01489367719739676]\n",
      "place_xyz[2] 0.01489367719739676 False\n",
      "desired_action : [1, 87, 174] phase_loss 0.0 dis_reward -0.0008000000000000003\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.35714286 0.14285714] real action [  1.  89. 180.]\n",
      "reward 0.9992 done:  True\n",
      "observation: [0.49553571 0.58482143 0.38839286 0.78571429 0.23660714 0.43303571\n",
      " 0.6875     0.25892857 0.44642857 0.10714286 0.375      0.79464286] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.19553578192092896, -0.6499997629802322, -0.060000000000000005]\n",
      "action: [  0. 168.  39.]\n",
      "pick_success 1\n",
      "desired_action : [0, 174, 42] phase_loss 0.0 dis_reward -0.0009000000000000002\n",
      "picked_obj 1\n",
      "84 19\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143 -0.07142857] real action [  0. 168.  39.]\n",
      "reward -0.0009000000000000002 done:  False\n",
      "observation: [0.83035714 0.79017857 0.04017857 0.5        0.54910714 0.37946429\n",
      " 0.28571429 0.11160714 0.40625    0.58928571 0.17857143 0.73660714] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.64285714  0.21428571]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [-0.22500005192092895, -0.34732135298023226, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 63, 28] phase_loss 0.0 dis_reward -0.00128\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.64285714  0.21428571] real action [ 1. 55. 28.]\n",
      "reward 0.99872 done:  True\n",
      "observation: [0.83035714 0.79017857 0.25892857 0.14732143 0.54910714 0.37946429\n",
      " 0.28571429 0.11160714 0.40625    0.58928571 0.17857143 0.73660714] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5        -0.21428571]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.16607116807907102, -0.6446426229802322, -0.044441751837730414]\n",
      "action: [  0. 166. 174.]\n",
      "pick_success 1\n",
      "desired_action : [0, 172, 182] phase_loss 0.0 dis_reward -0.0020000000000000005\n",
      "picked_obj 1\n",
      "83 87\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.5        -0.21428571] real action [  0. 166. 174.]\n",
      "reward -0.0020000000000000005 done:  False\n",
      "observation: [0.19196429 0.60714286 0.02678571 0.53125    0.25446429 0.33035714\n",
      " 0.4375     0.75       0.59821429 0.57589286 0.59375    0.25892857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.07142857 0.42857143]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.16607116807907102, -0.4651784329802322, 0.016358099989593033]\n",
      "place_xyz[2] 0.016358099989593033 False\n",
      "desired_action : [1, 95, 166] phase_loss 0.0 dis_reward -0.0016\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.07142857 0.42857143] real action [  1.  99. 174.]\n",
      "reward -0.0016 done:  False\n",
      "observation: [0.19196429 0.60714286 0.46875    0.80803571 0.25446429 0.33035714\n",
      " 0.4375     0.75       0.59821429 0.57589286 0.59375    0.25892857] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [0.184821158079071, -0.4785712829802322, -0.060000000000000005]\n",
      "action: [  0. 104. 181.]\n",
      "pick_success 0\n",
      "desired_action : [False, 104, 182] phase_loss 0.0 dis_reward -2e-05\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.07142857  0.        ] real action [  0. 104. 181.]\n",
      "reward 0.99998 done:  True\n",
      "observation: [0.19196429 0.60714286 0.46875    0.80803571 0.25446429 0.33035714\n",
      " 0.4375     0.75       0.59821429 0.57589286 0.59375    0.25892857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.42857143 0.14285714]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping pick:  [0.05089265807907101, -0.5133926929802322, -0.060000000000000005]\n",
      "action: [  0. 117. 131.]\n",
      "pick_success 1\n",
      "desired_action : [0, 111, 134] phase_loss 0.0 dis_reward -0.0009000000000000002\n",
      "picked_obj 0\n",
      "58 65\n",
      "action  [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.42857143 0.14285714] real action [  0. 117. 131.]\n",
      "reward -0.0009000000000000002 done:  False\n",
      "observation: [-0.00892857  0.51339286  0.22767857  0.52232143  0.52232143  0.27678571\n",
      "  0.82589286  0.73214286  0.26339286  0.16964286  0.25        0.71875   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 0\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.78571429 0.85714286]\n",
      "lang goal put the Letter O on a blue bowl\n",
      "steping: place [0.16339259807907103, -0.37946419298023226, 0.018905686326324944]\n",
      "place_xyz[2] 0.018905686326324944 False\n",
      "desired_action : [1, 57, 163] phase_loss 0.0 dis_reward -0.004\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.78571429 0.85714286] real action [  1.  67. 173.]\n",
      "reward 0.996 done:  True\n",
      "observation: [0.26785714 0.79910714 0.22767857 0.52232143 0.52232143 0.27678571\n",
      " 0.82589286 0.73214286 0.26339286 0.16964286 0.25       0.71875   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.28571429]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping pick:  [-0.15267866192092897, -0.48928556298023224, -0.057321753054857254]\n",
      "action: [  0. 108.  55.]\n",
      "pick_success 1\n",
      "desired_action : [0, 115, 60] phase_loss 0.0 dis_reward -0.00148\n",
      "picked_obj 1\n",
      "54 27\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.35714286 -0.28571429] real action [  0. 108.  55.]\n",
      "reward -0.00148 done:  False\n",
      "observation: [0.64285714 0.50892857 0.02678571 0.50446429 0.59375    0.77232143\n",
      " 0.20535714 0.45535714 0.80803571 0.24107143 0.33482143 0.75      ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.21428571 0.35714286]\n",
      "lang goal put the Letter L on a blue bowl\n",
      "steping: place [0.16339259807907103, -0.4089284629802322, 0.016345779523253445]\n",
      "place_xyz[2] 0.016345779523253445 False\n",
      "desired_action : [1, 74, 168] phase_loss 0.0 dis_reward -0.0008200000000000001\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.21428571 0.35714286] real action [  1.  78. 173.]\n",
      "reward 0.99918 done:  True\n",
      "observation: [0.64285714 0.50892857 0.37053571 0.77678571 0.59375    0.77232143\n",
      " 0.20535714 0.45535714 0.80803571 0.24107143 0.33482143 0.75      ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [-0.06696442192092897, -0.43571416298023224, -0.044642412737011916]\n",
      "action: [ 0. 88. 87.]\n",
      "pick_success 1\n",
      "desired_action : [0, 90, 87] phase_loss 0.0 dis_reward -8e-05\n",
      "picked_obj 2\n",
      "44 43\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.14285714  0.21428571] real action [ 0. 88. 87.]\n",
      "reward -8e-05 done:  False\n",
      "observation: [0.73214286 0.25446429 0.23660714 0.8125     0.00892857 0.49107143\n",
      " 0.50446429 0.6875     0.77678571 0.66517857 0.20089286 0.53125   ] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.64285714 -0.14285714]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.013392678079071019, -0.29642852298023226, 0.01549385499209166]\n",
      "place_xyz[2] 0.01549385499209166 False\n",
      "desired_action : [1, 42, 117] phase_loss 0.0 dis_reward -0.00072\n",
      "action  [ 1.          0.          0.          0.          0.          0.\n",
      "  1.         -0.64285714 -0.14285714] real action [  1.  36. 117.]\n",
      "reward 0.99928 done:  True\n",
      "observation: [0.73214286 0.25446429 0.23660714 0.8125     0.16071429 0.50892857\n",
      " 0.50446429 0.6875     0.77678571 0.66517857 0.20089286 0.53125   ] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.28571429]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.048214431920928946, -0.4142856029802322, -0.047458462119102485]\n",
      "action: [ 0. 80. 94.]\n",
      "pick_success 0\n",
      "desired_action : [0, 78, 87] phase_loss 0.0 dis_reward -0.00106\n",
      "action  [0.         0.         1.         0.         0.         0.\n",
      " 0.         0.21428571 0.28571429] real action [ 0. 80. 94.]\n",
      "reward -0.00106 done:  False\n",
      "observation: [0.61607143 0.29017857 0.34375    0.40178571 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143  0.        ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.05892871192092897, -0.3901784729802322, -0.044696520715951926]\n",
      "action: [ 0. 71. 90.]\n",
      "pick_success 1\n",
      "desired_action : [0, 78, 87] phase_loss 0.0 dis_reward -0.0011600000000000002\n",
      "picked_obj 1\n",
      "35 45\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.42857143  0.        ] real action [ 0. 71. 90.]\n",
      "reward -0.0011600000000000002 done:  False\n",
      "observation: [0.61607143 0.29017857 0.04910714 0.48660714 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.42857143  0.        ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [0.048214088079071016, -0.31517851298023225, 0.016820456944406037]\n",
      "place_xyz[2] 0.016820456944406037 False\n",
      "desired_action : [1, 50, 134] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.42857143  0.        ] real action [  1.  43. 130.]\n",
      "reward 0.9987 done:  True\n",
      "observation: [0.61607143 0.29017857 0.20535714 0.57589286 0.49553571 0.59821429\n",
      " 0.77678571 0.79017857 0.21875    0.58035714 0.74553571 0.48214286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.28571429]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [-0.20089292192092895, -0.34732135298023226, -0.04596134431660176]\n",
      "action: [ 0. 55. 37.]\n",
      "pick_success 1\n",
      "desired_action : [0, 59, 37] phase_loss 0.0 dis_reward -0.00032\n",
      "picked_obj 2\n",
      "27 18\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.28571429] real action [ 0. 55. 37.]\n",
      "reward -0.00032 done:  False\n",
      "observation: [0.29017857 0.74553571 0.50446429 0.46428571 0.03125    0.50446429\n",
      " 0.20535714 0.40625    0.75892857 0.61607143 0.78125    0.38392857] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.         -0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.06428585192092895, -0.3232142229802322, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 47, 94] phase_loss 0.0 dis_reward -0.0007399999999999999\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.         -0.21428571] real action [ 1. 46. 88.]\n",
      "reward 0.99926 done:  True\n",
      "observation: [0.29017857 0.74553571 0.50446429 0.46428571 0.21875    0.39732143\n",
      " 0.20535714 0.40625    0.75892857 0.61607143 0.78125    0.38392857] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.42857143 0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.19553543807907103, -0.41696417298023225, -0.05167779855430127]\n",
      "action: [  0.  81. 185.]\n",
      "pick_success 0\n",
      "desired_action : [0, 75, 187] phase_loss 0.0 dis_reward -0.0008000000000000003\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.42857143 0.21428571] real action [  0.  81. 185.]\n",
      "reward -0.0008000000000000003 done:  False\n",
      "observation: [0.38839286 0.55357143 0.20089286 0.37053571 0.33035714 0.83035714\n",
      " 0.55803571 0.29464286 0.79464286 0.70089286 0.80803571 0.14732143] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.206249718079071, -0.3821427629802322, -0.04655725292861462]\n",
      "action: [  0.  68. 189.]\n",
      "pick_success 1\n",
      "desired_action : [0, 74, 187] phase_loss 0.0 dis_reward -0.0008000000000000003\n",
      "picked_obj 2\n",
      "34 94\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.42857143  0.21428571] real action [  0.  68. 189.]\n",
      "reward -0.0008000000000000003 done:  False\n",
      "observation: [0.38839286 0.55357143 0.20089286 0.37053571 0.03125    0.46875\n",
      " 0.55803571 0.29464286 0.79464286 0.70089286 0.80803571 0.14732143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.78571429 -0.21428571]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.13125010192092895, -0.5053569829802322, 0.016387905105948453]\n",
      "place_xyz[2] 0.016387905105948453 False\n",
      "desired_action : [1, 124, 63] phase_loss 0.0 dis_reward -0.0020000000000000005\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.         -0.78571429 -0.21428571] real action [  1. 114.  63.]\n",
      "reward 0.998 done:  True\n",
      "observation: [0.38839286 0.55357143 0.20089286 0.37053571 0.54017857 0.27678571\n",
      " 0.55803571 0.29464286 0.79464286 0.70089286 0.80803571 0.14732143] [False]\n",
      "done\n",
      "init scene\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.42857143 0.        ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping pick:  [0.018749818079071057, -0.4624998629802322, -0.043082410171628005]\n",
      "action: [  0.  98. 119.]\n",
      "pick_success 1\n",
      "desired_action : [0, 96, 123] phase_loss 0.0 dis_reward -0.0004\n",
      "picked_obj 2\n",
      "49 59\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.42857143 0.        ] real action [  0.  98. 119.]\n",
      "reward -0.0004 done:  False\n",
      "observation: [0.73660714 0.6875     0.54910714 0.22767857 0.00446429 0.51785714\n",
      " 0.19196429 0.38392857 0.17410714 0.67857143 0.45982143 0.77678571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         1.         0.\n",
      " 0.         0.42857143 0.        ]\n",
      "lang goal put the Letter V on a yellow bowl\n",
      "steping: place [-0.06964299192092896, -0.3312499329802322, 0.0050000000000000044]\n",
      "place_xyz[2] 0.0050000000000000044 False\n",
      "desired_action : [1, 41, 89] phase_loss 0.0 dis_reward -0.0014599999999999995\n",
      "action  [1.         0.         0.         0.         1.         0.\n",
      " 0.         0.42857143 0.        ] real action [ 1. 49. 86.]\n",
      "reward 0.99854 done:  True\n",
      "observation: [0.73660714 0.6875     0.54910714 0.22767857 0.20089286 0.37946429\n",
      " 0.19196429 0.38392857 0.17410714 0.67857143 0.45982143 0.77678571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.28571429]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.013392678079071019, -0.3419642129802323, -0.04763545624911786]\n",
      "action: [  0.  53. 117.]\n",
      "pick_success 1\n",
      "desired_action : [0, 57, 117] phase_loss 0.0 dis_reward -0.00032\n",
      "picked_obj 2\n",
      "26 58\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.07142857  0.28571429] real action [  0.  53. 117.]\n",
      "reward -0.00032 done:  False\n",
      "observation: [0.70089286 0.31696429 0.34821429 0.76785714 0.00446429 0.49107143\n",
      " 0.79017857 0.51339286 0.64285714 0.73214286 0.41517857 0.24553571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.57142857 0.07142857]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [-0.15000009192092895, -0.47053557298023224, 0.01763744477182627]\n",
      "place_xyz[2] 0.01763744477182627 False\n",
      "desired_action : [1, 96, 55] phase_loss 0.0 dis_reward -0.00052\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.57142857 0.07142857] real action [  1. 101.  56.]\n",
      "reward 0.99948 done:  True\n",
      "observation: [0.70089286 0.31696429 0.34821429 0.76785714 0.44196429 0.25892857\n",
      " 0.79017857 0.51339286 0.64285714 0.73214286 0.41517857 0.24553571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "get_expert_demonstration\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.21428571]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping pick:  [0.08839263807907105, -0.6526783329802321, -0.041643991768360145]\n",
      "action: [  0. 169. 145.]\n",
      "pick_success 1\n",
      "desired_action : [0, 169, 143] phase_loss 0.0 dis_reward -8e-05\n",
      "picked_obj 2\n",
      "84 72\n",
      "action  [0.         0.         0.         1.         0.         0.\n",
      " 0.         0.21428571 0.21428571] real action [  0. 169. 145.]\n",
      "reward -8e-05 done:  False\n",
      "observation: [0.20535714 0.30803571 0.21428571 0.69642857 0.         0.46428571\n",
      " 0.64285714 0.33482143 0.80803571 0.14732143 0.46428571 0.58482143] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[1.         0.         0.         0.         0.         0.\n",
      " 1.         0.14285714 0.5       ]\n",
      "lang goal put the Letter V on a blue bowl\n",
      "steping: place [0.06964264807907106, -0.48392842298023225, 0.019582344330847268]\n",
      "place_xyz[2] 0.019582344330847268 False\n",
      "desired_action : [1, 105, 128] phase_loss 0.0 dis_reward -0.0020200000000000005\n",
      "action  [1.         0.         0.         0.         0.         0.\n",
      " 1.         0.14285714 0.5       ] real action [  1. 106. 138.]\n",
      "reward 0.99798 done:  True\n",
      "observation: [0.20535714 0.30803571 0.21428571 0.69642857 0.45982143 0.60267857\n",
      " 0.64285714 0.33482143 0.80803571 0.14732143 0.46428571 0.58482143] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.42857143]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.010714451920928958, -0.5883926529802322, -0.060000000000000005]\n",
      "action: [  0. 145. 108.]\n",
      "pick_success 0\n",
      "desired_action : [0, 144, 104] phase_loss 0.0 dis_reward -0.00033999999999999997\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.14285714  0.42857143] real action [  0. 145. 108.]\n",
      "reward -0.00033999999999999997 done:  False\n",
      "observation: [0.1875     0.73214286 0.65625    0.45535714 0.21875    0.40178571\n",
      " 0.84821429 0.79017857 0.54017857 0.19196429 0.47767857 0.76339286] [False]\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.14285714]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping pick:  [-0.03214301192092894, -0.5723212329802323, -0.060000000000000005]\n",
      "action: [  0. 139. 100.]\n",
      "pick_success 1\n",
      "desired_action : [0, 144, 104] phase_loss 0.0 dis_reward -0.0008200000000000001\n",
      "picked_obj 1\n",
      "69 50\n",
      "action  [ 0.          0.          1.          0.          0.          0.\n",
      "  0.         -0.57142857 -0.14285714] real action [  0. 139. 100.]\n",
      "reward -0.0008200000000000001 done:  False\n",
      "observation: [0.1875     0.73214286 0.02232143 0.5        0.21875    0.40178571\n",
      " 0.84821429 0.79017857 0.54017857 0.19196429 0.47767857 0.76339286] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.21428571 -0.71428571]\n",
      "lang goal put the Letter L on a yellow bowl\n",
      "steping: place [0.14732117807907102, -0.7169640129802323, 0.017554613873362546]\n",
      "place_xyz[2] 0.017554613873362546 False\n",
      "desired_action : [1, 186, 177] phase_loss 0.0 dis_reward -0.00298\n",
      "action  [ 1.          0.          0.          0.          1.          0.\n",
      "  0.          0.21428571 -0.71428571] real action [  1. 193. 167.]\n",
      "reward 0.99702 done:  True\n",
      "observation: [0.1875     0.73214286 0.88392857 0.75892857 0.21875    0.40178571\n",
      " 0.84821429 0.79017857 0.54017857 0.19196429 0.47767857 0.76339286] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter L on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.   0.   1.   0.   0.   0.   0.  -0.5  0. ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping pick:  [-0.08303584192092897, -0.36607134298023225, -0.0453731768578291]\n",
      "action: [ 0. 62. 81.]\n",
      "pick_success 1\n",
      "desired_action : [0, 70, 82] phase_loss 0.0 dis_reward -0.0012999999999999997\n",
      "picked_obj 1\n",
      "31 40\n",
      "action  [ 0.   0.   1.   0.   0.   0.   0.  -0.5  0. ] real action [ 0. 62. 81.]\n",
      "reward -0.0012999999999999997 done:  False\n",
      "observation: [0.47321429 0.64732143 0.04910714 0.49553571 0.74553571 0.48660714\n",
      " 0.18303571 0.67857143 0.74107143 0.13839286 0.75446429 0.74553571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 1\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.42857143  0.        ]\n",
      "lang goal put the Letter L on a green bowl\n",
      "steping: place [-0.21696434192092895, -0.6285712029802322, 0.02137785136699677]\n",
      "place_xyz[2] 0.02137785136699677 False\n",
      "desired_action : [1, 167, 33] phase_loss 0.0 dis_reward -0.00106\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.42857143  0.        ] real action [  1. 160.  31.]\n",
      "reward 0.99894 done:  True\n",
      "observation: [0.47321429 0.64732143 0.73660714 0.15178571 0.74553571 0.48660714\n",
      " 0.18303571 0.67857143 0.74107143 0.13839286 0.75446429 0.74553571] [False]\n",
      "done\n",
      "init scene\n",
      "obj_ids [6, 7, 8]\n",
      "lang goal put the Letter V on a green bowl\n",
      "get_expert_demonstration\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.42857143]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping pick:  [-0.09107155192092897, -0.6687497529802322, -0.04228480130434037]\n",
      "action: [  0. 175.  78.]\n",
      "pick_success 1\n",
      "desired_action : [0, 180, 82] phase_loss 0.0 dis_reward -0.0008200000000000001\n",
      "picked_obj 2\n",
      "87 39\n",
      "action  [ 0.          0.          0.          1.          0.          0.\n",
      "  0.         -0.35714286 -0.42857143] real action [  0. 175.  78.]\n",
      "reward -0.0008200000000000001 done:  False\n",
      "observation: [0.50446429 0.63392857 0.8125     0.72321429 0.02678571 0.51785714\n",
      " 0.29464286 0.1875     0.26785714 0.76785714 0.20982143 0.46428571] [ True]\n",
      "get_expert_demonstration\n",
      "picked_obj 2\n",
      "(6, 28, 28, 4)\n",
      "[ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429  0.07142857]\n",
      "lang goal put the Letter V on a green bowl\n",
      "steping: place [0.16339259807907103, -0.34999992298023225, 0.01524061813950539]\n",
      "place_xyz[2] 0.01524061813950539 False\n",
      "desired_action : [1, 62, 168] phase_loss 0.0 dis_reward -0.00122\n",
      "action  [ 1.          0.          0.          0.          0.          1.\n",
      "  0.         -0.28571429  0.07142857] real action [  1.  56. 173.]\n",
      "reward 0.99878 done:  True\n",
      "observation: [0.50446429 0.63392857 0.8125     0.72321429 0.26785714 0.79017857\n",
      " 0.29464286 0.1875     0.26785714 0.76785714 0.20982143 0.46428571] [False]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets\n",
    "env = ResPickOrPlaceEnvWithoutLangReward(\n",
    "                                        task= PutLetterontheBowl,\n",
    "                                         image_obs=True,\n",
    "                                         residual=True,\n",
    "                                         observation_noise=5,\n",
    "                                         render=True,\n",
    "                                         multi_discrete=False,\n",
    "                                         scale_action=True,\n",
    "                                         ee=\"suction\",\n",
    "                                         scale_obs=True,\n",
    "                                         neglect_steps=False,\n",
    "                                         one_hot_action = True)\n",
    "success = 0# 97%\n",
    "trial = 100\n",
    "steps = []\n",
    "# RL_success 0.02\n",
    "# step2 0.0\n",
    "# step3 0.0\n",
    "# step4 0.01\n",
    "# step10 0.0\n",
    "# step11 0.98\n",
    "for seed in range(trial):\n",
    "    np.random.seed(seed)\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        action = env.get_expert_demonstration()\n",
    "        # action[-2:]=[0,0]\n",
    "        print(action)\n",
    "        obs, rewards, done,_, info = env.step(action)\n",
    "        step += 1\n",
    "        if done:\n",
    "            steps.append(step)\n",
    "            if rewards >= 0.95:\n",
    "                success += 1\n",
    "            print(\"done\")\n",
    "            break\n",
    "RL_success = success/trial\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL_success 0.98\n",
      "mean 2.91\n",
      "step2 0.69\n",
      "step3 0.13\n",
      "step4 0.04\n",
      "step10 0.01\n",
      "step11 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X connection to :0 broken (explicit kill or server shutdown).\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "print(\"RL_success\",RL_success)\n",
    "step2 = steps.count(2)/len(steps)\n",
    "step3 = steps.count(3)/len(steps)\n",
    "step4 = steps.count(4)/len(steps)\n",
    "step10 = steps.count(10)/len(steps)\n",
    "step11 = steps.count(11)/len(steps)\n",
    "print(\"mean\",np.mean(steps))\n",
    "print(\"step2\",step2)\n",
    "print(\"step3\",step3)\n",
    "print(\"step4\",step4)\n",
    "print(\"step10\",step10)\n",
    "print(\"step11\",step11)\n",
    "# stochastic\n",
    "# RL_success 0.98\n",
    "# mean 2.91\n",
    "# step2 0.69\n",
    "# step3 0.13\n",
    "# step4 0.04\n",
    "# step10 0.01\n",
    "# step11 0.02\n",
    "# deterministic\n",
    "# RL_success 0.79\n",
    "# mean 4.24\n",
    "# step2 0.69\n",
    "# step3 0.03\n",
    "# step4 0.01\n",
    "# step10 0.0\n",
    "# step11 0.22"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cliport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e285e3189e2c3705550e6f1561542eb0bf2036e0fba5138d48bba9b73467e388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
